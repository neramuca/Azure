{"cells":[{"cell_type":"code","source":[" %run \"../Libraries/ADP_Farmatic_Process\""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#################################################################################\n\"\"\" Main Process for Farmatic Canonize Files\n\n\"\"\"\n #Who                 When           What\n #Victor Salesa       05/11/2018     Initial Version\n #Victor Salesa       07/11/2018     Added Window function to get the latest timestamp and filter file list by it\n################################################################################\n\n\n# Create File list from Farmatic TobeProcessed Folder\nfilelist = dbutils.fs.ls(__PHARMATIC_TOBEPROCESSED_BASE_PATH__)\n\n# Process Landing Files\ntry: \n  \n  # Create Dataframe with the fields and create original_name and timestamp fields for later using\n  file_df = (\n    createDFFromList(filelist)\n      .filter(col(\"name\").substr(-20,2)=='LD')\n      .withColumn(\"timestamp\",col(\"name\").substr(-18,14))\n      .withColumn(\"original_name\",col(\"name\").substr(lit(0),(length(col(\"name\"))-21)))\n  )\n  \n  #Create a window function to get the latest timestamp of the file\n  windowSpec = Window.partitionBy(file_df['original_name']).orderBy(file_df['timestamp'].desc())\n  \n  #Filter files to have just the latest timestamp version\n  file_df = (file_df.withColumn(\"latest_timestamp\",first(\"timestamp\").over(windowSpec))\n         .filter(col(\"timestamp\")==col(\"latest_timestamp\"))\n  )\n  \n  #Process all tobeprocessed files and generate the canonical\n  #Get the column of files for the SL filetype\n  name_column_PR = file_df.rdd.filter(lambda f: 'GPR' in f.name).take(20)\n\n\n  #Convert the column to an iterator of parameters to feed the ThreadPool\n  parameter_list_PR = ((__PHARMATIC_TOBEPROCESSED_BASE_PATH__,\n                   str(row.name),\n                   __PHARMATIC_ERRORPROCESS_BASE_PATH__,\n                   __PHARMATIC_CANONICAL_BASE_PATH__,\n                   True\n                  ) \n                  for row in name_column_PR)\n\n  \n  \n  #Create thread pool to paralelize canonical generation\n  threadPool_PR = ThreadPool(32)\n  \n  #Configure spark to be optimized to paralilize\n  spark.conf.set(\"spark.scheduler.mode\",'FAIR')\n  \n  print(\"Start Canonizing Files\")\n  \n#Run thread pool with the list of files to be \n  results_PR = (\n    threadPool_PR.starmap(\n      ProcessPharmaticFilesDataSellin,\n      parameter_list_PR,\n      5\n    )\n  )\n  \n  threadPool_PR.close()\n  threadPool_PR.join()\n  \n  print(\"End Canonizing Files\")\n  \n  #Full Sellin processed files read\n  df_full_Sellin = (spark.read.format('csv')\n                  .options(header='true',charset='UTF-8')\n                  .option(\"sep\",\"|\")\n                  .option(\"inferSchema\",True)\n                  .load(__PHARMATIC_CANONICAL_BASE_PATH__+'/PR/6*_CMD.csv')\n                 )\n\n  #Full Sellout processed files write to Hive Metastore in order to be able to fectch data from Tableau / other BI\n  df_full_Sellin.write.mode('overwrite').saveAsTable(\"SELLIN_SPAIN\")\n  sqlContext.refreshTable(\"SELLIN_SPAIN\")\n  \n  \nexcept Exception as e:\n  print(e)"],"metadata":{},"outputs":[],"execution_count":2}],"metadata":{"name":"FMT_Data_TobeProcessed_Sellin","notebookId":3996791399040075},"nbformat":4,"nbformat_minor":0}
