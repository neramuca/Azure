{"cells":[{"cell_type":"code","source":["%run \"./ADP_Farmatic_Def\""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%run \"./ADP_Spain_MDM_Def\""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["%run \"../Libraries/ADP_QA\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#################################################################################\n\"\"\" Farmatic Canonize Files Library\n\n\"\"\"\n #Who                 When           What\n #Victor Salesa       18/12/2018     Initial VersionRefresh GenerateCanonicalFarmaticSelloutcanonical table:CTL_PROCESS_FILE_QA\n #Victor Salesa       19/12/2018     Added TrimiGenerateCanonicalFarmaticSelloutng to all fields\n #Victor Salesa       04/04/2019     Added RecoverTemporaryFarmaticSellout method\n #Victor Salesa       12/04/2019     cHANGED __wholeFile__ TO INCLUDE ENCODING PARAMETER\n #Victor Salesa       21/04/2019     Added Variables for paths and table names\n #Victor Salesa       29/04/2019     FieldFormatValidationsFarmaticSellout:Included new QA fields (NUM_VALIDATED_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n #Victor Salesa       29/04/2019     GenerateTemporaryFarmaticSellout:Included new QA fields (NUM_ERROR_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE) \n #Victor Salesa       29/04/2019     GenerateTemporaryFarmaticSellout:Renamed JOB_ID field with NUM_ROWS_TOTAL\n #Victor Salesa       29/04/2019     GenerateTemporaryFarmaticSellout:Drop Cols ROW_KO_PMS,ROW_KO_MDM,NUMBER_OF_VALIDATED_FIELDS_PMS,NUMBER_OF_VALIDATED_FIELDS_MDM,\"OLD\" ROW_OK, ROW_KO\n #Victor Salesa       29/04/2019     GenerateQAFarmaticSellout:Included new QA fields (NUM_VALIDATED_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n #Victor Salesa       29/04/2019     GenerateQAFarmaticSellout:Included new QA fields (NUM_ERROR_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE) \n################################################################################sa\n\n__DELETE_FILES_ENABLED__ = True\n\n####CTL JOB DEF#########################################################################################################################\n\n##Pending CTL.JOB table to be corrected to have JOB_ID as an integer with 31 digits\n__CTL_JOB__DB_TABLE_NAME__ = \"CTL.JOB_\"\n\n####FARMATIC SELLOUT DEF################################################################################################################\n\n__PHARMATIC_CANONICAL_STG_SELLOUT_TMP_H_TABLE_NAME__ = 'TMP_STG_T_SELL_OUT'\n__PHARMATIC_CANONICAL_STG_SELLOUT_TMP_FILE_PATH__  = __PHARMATIC_CANONICAL_BASE_PATH__+'SL/'+ 'TMP_STG_T_SELL_OUT'\n\n\n__PHARMATIC_CANONICAL_STG_SELLOUT_H_TABLE_NAME__ = 'ADP_STG_T_SELL_OUT' \n__PHARMATIC_CANONICAL_STG_SELLOUT_FILE_PATH__  = __PHARMATIC_CANONICAL_BASE_PATH__+'SL/'+ 'STG_T_SELL_OUT'\n\n__PHARMATIC_CANONICAL_STG_SELLOUT_DB_TABLE_NAME__ ='ADP.STG_T_SELL_OUT'\n\n####QUALITY DEF##########################################################################################################################\n\n__QUALITY_PFV_H_TABLE_NAME__ = 'CTL_PROCESS_FILE_VAL'\n__QUALITY_PFV_H_FILE_PATH__  = __QUALITY_BASE_PATH__ + 'ctl_process_file_val'\n\n__QUALITY_PFV_DB_TABLE_NAME__='CTL.STG_PROCESS_FILE_VAL' \n\n__QUALITY_PFE_H_TABLE_NAME__ = 'CTL_PROCESS_FILE_ERROR'\n__QUALITY_PFE_H_FILE_PATH__  = __QUALITY_BASE_PATH__ + 'ctl_process_file_error'\n\n__QUALITY_PFE_DB_TABLE_NAME__='CTL.STG_PROCESS_FILE_ERROR' \n\n__QUALITY_PFQ_H_TABLE_NAME__ = 'CTL_PROCESS_FILE_QA'\n__QUALITY_PFQ_H_FILE_PATH__ = __QUALITY_BASE_PATH__+'ctl_process_file_qa' + '/table'\n\n__QUALITY_PFQ_DB_TABLE_NAME__ = 'CTL.STG_PROCESS_FILE_QA'\n\n########################################################################################################################################\n\ndef __wholeFile__(wholeTextFilesLine,force_decode='ISO-8859-1'):\n  \"\"\"Converts 1 single line tuple returned from the wholeTextFilesfunction to a DataframeRow.\n\n    Parameters:\n      wholeTextFilesLine   -- 1 single line tuple returned from wholeTextFiles function with (filepath,filecontents)\n      force_decode         -- decode chasrset\n\n    Return:\n      pyspark.sql.Row      -- Dataframe Row with the following fields name,line_id,value\n                           -- FILE_PATH: name of the file\n                           -- FILE_LINE_NUM: line index inside the file\n                           -- FILE_LINE_CONTENT:    content of each single line of the file\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       18/12/2018     Initial version\n  #Victor Salesa       28/01/2019     Added .decode('ISO-8859-1') to decode latin1 files\n  #Ana Perez           27/03/2019     Included log managment and exception managment\n  #Victor Salesa       11/04/2019     Added force_decode parameter to be able to change de decoding used\n  #                                   Included chardet library to detect encoding in case the encoding is not defined (slower)\n  try:\n    #Get name of the file\n    name  = wholeTextFilesLine[0]\n    #Get the content of the file and generate a list with the lines splitted\n\n    #Take the text byte array\n    text_data_array = wholeTextFilesLine[1]\n\n    #If the encoding is left as blank it will force lookup the encoding so will take more time to decode\n    if force_decode=='':\n      charset =    chardet.detect(text_data_array)['encoding']    \n      force_decode = charset\n    #end if force_decode=='':\n    \n    #Decode data based on force_decode parameter and then split by CRLF\n    lines = text_data_array.decode(force_decode).split('\\r\\n')\n    #Add line order to the list of lines splitted\n    result_lines = [(i,s) for i, s in enumerate(lines)]\n    result = [(name,result_line) for result_line in result_lines ]\n    #Generate a Row with the name,line_id,linevalue\n    row_result = [Row(FILE_PATH=name,FILE_LINE_NUM=result_line[0],FILE_LINE_CONTENT=result_line[1]) for result_line in result_lines]\n\n    return row_result \n  except Exception as err:\n#     ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n    \n#############################################################################################################################  \n  \ndef NormalizeFarmaticSellout(files,partitions=__PARTITIONS_DEFAULT__,debug=__DEBUG_DEFAULT__,sample=__SAMPLE_DEFAULT__,sample_quantity=__SAMPLE_QUANTITY_DEFAULT__):\n  \"\"\"Normalize a folder containing a list of files containing Farmatic Sellout information to a Big Dataframe with.\n\n    Parameters:\n      files                -- Path with wildcards of the files to be read\n      partitions           -- Partitions to be used when using wholetextfiles\n      debug                -- True for enable debug verbosing or False to not enable\n      sample               -- To enable use a sample of the whole files retrieved to process them\n      sample_quantity      -- In case sample is enabled sample_quantity to be tested\n\n    Return:\n      Dataframe            -- Dataframe containing the files with splitted data and filename line num \n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       18/12/2018     Initial version\n  #Victor Salesa       19/12/2018     Completed the code and Added new parameters  \n  #Victor Salesa       08/01/2019     Added FILE_SPEC_VERSION,FILE_RELEASE_VERSION,FILE_ORIGIN,FILE_TYPE,COUNTRY to the Normalized output df\n  #Victor Salesa       11/01/2019     Added PMS_CODE to Normalized Output \n  #Victor Salesa       14/01/2019     Added Validation type field to error output\n  #Victor Salesa       15/01/2019     Added Delete old timestamps and error files\n  #Victor Salesa       28/01/2019     Substituted wholeTextFiles with binaryFiles to solve Enconding issue.\n  #Victor Salesa       30/01/2019     Added COUNTRY_CODE to CTL.PROCESS_FILE_VAL write\n  #Ana Perez           11/02/2019     Replace delete_file function to blob_delete_file_sql\n  #Ana Perez           11/02/2019     Replace yyyyMMddhhmmss pattern to yyyyMMddHHmmss \n  #Victor Salesa       21/02/2019     TZBIADP-201 ERROR CONTROL SYSTEM: VALIDATION FILE NAME PROCESS NormalizeFarmaticSellout:\n  #                                       -Include delete control for last landing date deleting\n  #Victor Salesa       27/02/2019     Change write to csv with write to parquet i\n  #Victor Salesa       27/02/2019     Include GetDataFrameAsSchema to adapt schema to parquet file and database\n  #Victor Salesa       18/03/2019     Changed START_DATE and END_DATE to be really start and end of the process when writing to CTL_PROCESS_FILE_VAL\n  #Victor Salesa       21/03/2019     Added Code to Backup deleted files information when the process fails deleting some of the files\n  #Ana Perez           29/03/2019     Included log managment and exception managment\n  try:\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    \n    # Date and Time of the begining to this process\n    start_date = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') \n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Create wholetextfiles rdd\", sys._getframe().f_code.co_name)\n\t\n    textFile = sc.binaryFiles(files,partitions)\n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Persist readed files\", sys._getframe().f_code.co_name)\n\t\n    textFile.persist(StorageLevel.MEMORY_AND_DISK)\n    textFile.count()\n    \n    #Take a sample of the files\n    if sample==True:\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Take a sample of files\", sys._getframe().f_code.co_name) \n      textFile = sc.parallelize(textFile.take(sample_quantity),partitions)\n      textFile.persist(StorageLevel.MEMORY_AND_DISK)\n      textFile.count()\n    \n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Calculate line types to get Header and Detail Split\", sys._getframe().f_code.co_name) \n\t\n    #Calculate line types to get Header and Detail Split\n    textFileLineTypesDF = (textFile.flatMap(__wholeFile__).toDF()\n                               .filter(col(\"FILE_PATH\").substr(-20,2)=='LD')\n                               .withColumn(\"RAW_NAME\",split(col(\"FILE_PATH\"),'/')[5])\n                               .withColumn(\"FILE_NAME\",concat(col(\"RAW_NAME\").substr(lit(0),(length(col(\"RAW_NAME\"))-21)),lit('.TXT') ))                            \n                               .transform(SliceDFColumn(\"FILE_NAME\",__SP_FILENAME_COLUMN_NAMES__,__SP_FILENAME_LENGHTS__))\n                               .drop('pharmacy_unique_code')\n                               .drop('data_date')\n                               .withColumnRenamed('spec_version', 'FILE_SPEC_VERSION')\n                               .withColumnRenamed('release_version', 'FILE_RELEASE_VERSION')\n                               .withColumnRenamed('origin', 'FILE_ORIGIN')\n                               .withColumnRenamed('file_type', 'FILE_TYPE')\n                               .withColumn('COUNTRY',lit('ES'))     \n                               .withColumn(\"LANDING_DATE\",col(\"FILE_PATH\").substr(-18,14))\n                               .transform(SliceDFColumn(\"FILE_LINE_CONTENT\",['RecordType'],[__RECORDTYPE_LEN__]))\n                         )\n    \t\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Persist sliced name files\", sys._getframe().f_code.co_name)\n    textFileLineTypesDF.persist(StorageLevel.MEMORY_AND_DISK)\n    textFileLineTypesDF.count()\n    \n    #Create a window function to get the latest timestamp of the file\n    windowSpec = Window.partitionBy(textFileLineTypesDF['FILE_NAME']).orderBy(textFileLineTypesDF['LANDING_DATE'].desc())\n\n    #Create a window function to get the number of lines per file to get \"empty file\"\n    windowEmptyFiles = Window.partitionBy(textFileLineTypesDF['FILE_NAME'],textFileLineTypesDF['LANDING_DATE']).orderBy(textFileLineTypesDF['FILE_NAME'].desc(),textFileLineTypesDF['LANDING_DATE'].desc())\n\n    #Filter files to have just the latest timestamp version\n    textFileLineTypesLastTimestampDF = (textFileLineTypesDF\n                                      .withColumn(\"LATEST_LANDING_DATE\",first(\"LANDING_DATE\").over(windowSpec))\n                                      .withColumn(\"FILE_LINES\",count(\"FILE_LINE_CONTENT\").over(windowEmptyFiles))\n                                      .withColumn(\"FILE_NO_DATA\",when(col(\"FILE_LINES\")<=3,1).otherwise(0)  )                      \n                                      .withColumn(\"LATEST_FILE_FLG\",when(col(\"LANDING_DATE\")==col(\"LATEST_LANDING_DATE\"),1).otherwise(0))                                   \n    )\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Persist Last timestamp files\", sys._getframe().f_code.co_name)\n    textFileLineTypesLastTimestampDF.persist(StorageLevel.MEMORY_AND_DISK)\n    textFileLineTypesLastTimestampDF.count() \n  \n    if __DELETE_FILES_ENABLED__ == True:\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Old timestamp files to be deleted: \" +\\\n               \t    str(textFileLineTypesLastTimestampDF.filter(col(\"LATEST_FILE_FLG\")==0).select(\"RAW_NAME\").distinct().count()) + \" files\", sys._getframe().f_code.co_name)\n\n      # Cache textFileLineTypesLastTimestampDF to avoid delete issues\n      textFileLineTypesLastTimestampDF = textFileLineTypesLastTimestampDF.persist(StorageLevel.MEMORY_AND_DISK) \n        \n      ## Delete old Timestamp files from folder as they are not going to be processed\n      files_deleted = (textFileLineTypesLastTimestampDF.filter(col(\"LATEST_FILE_FLG\")==0)\n                                       .select(\"RAW_NAME\")\n                                       .distinct()\n                                       .withColumn(\"deleted\",blob_delete_file_sql(concat(lit(__PHARMATIC_TOBEPROCESSED_BASE_PATH__),col(\"RAW_NAME\"))))\n                                       .collect()\n      )\n      \n      textFileLineTypesLastTimestampDF.count()\n      \n      if len(files_deleted)!=0:\n        #Mount a dataframe with deleted files result\n        result_delete_df = sc.parallelize(files_deleted).toDF()\n        result_delete_df.cache()\n\n        #Calculate Deleted Files\n        total_deleted = (result_delete_df.agg(sum(\"deleted\").alias(\"deleted_total\")).collect())[0].deleted_total\n\n        #Calculate Total Files\n        total_rows = result_delete_df.count()\n\n        #Generate Error if total_deleted < total_rows\n        if total_deleted < total_rows:\n          not_deleted = result_delete_df.filter(col(\"deleted\")==0).collect()\n          not_deleted_names = str([file.RAW_NAME for file in not_deleted]).replace(\"[\",\"\").replace(\"]\",\"\")\n          raise Exception('Fail deleting bad files: '+ not_deleted_names)\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Files Deleted: \" + str(files_deleted), sys._getframe().f_code.co_name)\n    \n\t#end if __DELETE_FILES_ENABLED__ == True\n\t\n    ## Take just files with latest timestamp version\n    textFileLineTypesLastTimestampDF = textFileLineTypesLastTimestampDF.filter(col(\"LATEST_FILE_FLG\")==1)\n  \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Cache result to avoid recalculating RecordType\" , sys._getframe().f_code.co_name)\n   \n    #Cache result to avoid recalculating RecordType\n    textFileLineTypesLastTimestampDF = textFileLineTypesLastTimestampDF.cache()\n    \n  \n    ##Add Process date to df\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Add Process Date to Dataframe\" , sys._getframe().f_code.co_name)\n        \n    processDate = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n    textFileLineTypesLastTimestampDF = (textFileLineTypesLastTimestampDF\n                         .withColumn(\"PROCESS_DATE\", to_timestamp(lit(processDate), 'yyyy-MM-dd HH:mm:ss')) \n                         .withColumn(\"PROCESS_DATE\",col(\"PROCESS_DATE\").cast(StringType()))\n                         .withColumn(\"PROCESS_DATE\",date_format(col(\"PROCESS_DATE\"),'yyyyMMddHHmmss'))\n                        )\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Calculate Header Split\" , sys._getframe().f_code.co_name)\n   \n    #Calculate Header Split\n    textFileHeaderDF   =  (textFileLineTypesLastTimestampDF.filter(col(\"RecordType\") == \"H\")\n                                .transform(SliceDFColumn(\"FILE_LINE_CONTENT\",__SP_HEADER_COLUMN_NAMES__,__SP_HEADER_LENGHTS__))\n                                .drop(\"FILE_LINE_CONTENT\",\"RecordType\")\n                                .select(\"FILE_PATH\",\"RAW_NAME\",\"FILE_NAME\",\"LANDING_DATE\",\"PharmacyID\",\"FileDate\",\"ZipCode\",\"ExternalPharmacyID\",\\\n\t\t\t\t\t\t\t\t        \"FILE_LINES\",\"FILE_NO_DATA\",\"FILE_SPEC_VERSION\",\"FILE_RELEASE_VERSION\",\"FILE_ORIGIN\",\"FILE_TYPE\",\"COUNTRY\",\"PROCESS_DATE\")\n                        )\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Cache result to avoid recalculating Header Split\" , sys._getframe().f_code.co_name)\n     \n    #Cache result to avoid recalculating Header Split\n    textFileHeaderDF   = textFileHeaderDF.cache().alias('df_header')\n\t\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Calculate Detail Split\" , sys._getframe().f_code.co_name)\n   \n    #Calculate Detail Split\n    textFileDetailDF   =  (textFileLineTypesLastTimestampDF.filter(col(\"RecordType\") == \"D\")\n                                 .transform(SliceDFColumn(\"FILE_LINE_CONTENT\",__SP_DETAIL_COLUMN_NAMES__,__SP_DETAIL_LENGHTS__))\n                                 .withColumn (\"FILE_LEN_ROW_NOT_OK\", when(length(col(\"FILE_LINE_CONTENT\")) == lit(__SP_TOTAL_LENGHTS__),0).otherwise(1).cast(IntegerType())  )      \n                                 .drop(\"FILE_PATH\",\"RAW_NAME\",\"FILE_LINE_CONTENT\",\"RecordType\",\"FILE_LINES\",\"FILE_NO_DATA\",\"FILE_SPEC_VERSION\",\"FILE_RELEASE_VERSION\",\"FILE_ORIGIN\",\"FILE_TYPE\",\"COUNTRY\",\"PROCESS_DATE\")   \n                          )\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Cache result to avoid recalculating Detail Split\" , sys._getframe().f_code.co_name)\n      \n    #Cache result to avoid recalculating Detail Split\n    textFileDetailDF   = textFileDetailDF.cache().alias('df_detail')\n  \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Define key columns to be used in the join\" , sys._getframe().f_code.co_name)\n      \n    #Define key columns to be used in the join\n    key_columns = [\"FILE_NAME\",\"LANDING_DATE\"]\n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Define join condition for the join\" , sys._getframe().f_code.co_name)\n       \n    #Define join condition for the join\n    join_cond_generated = [ (col('df_header.'+field) == col('df_detail.'+field)) for field in key_columns]\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Exclude key columns of detail select clause\" , sys._getframe().f_code.co_name)\n    \n    #Exclude key columns of detail select clause\n    detail_selected_columns = [value for value in textFileDetailDF.columns if value not in key_columns]\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Generate Select List of columns\" , sys._getframe().f_code.co_name)\n    \n    #Generate Select List of columns\n    select_generated = [col(\"df_header.*\")] + [col('df_detail.'+column) for column in detail_selected_columns]\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Join Header and Detail\" , sys._getframe().f_code.co_name)\n    \n    #Join Header and Detail \n    textFileCompleteDF = (textFileHeaderDF.repartition(partitions)\n                           .join(textFileDetailDF.repartition(partitions),join_cond_generated, how='left').select(*select_generated)\n                         )\n    \n    #Create a window function to get the number of lines per file to get \"empty file\"\n    windowFileErrors = Window.partitionBy(textFileCompleteDF['FILE_NAME'],textFileCompleteDF['LANDING_DATE'],textFileCompleteDF['PharmacyID']).orderBy(textFileLineTypesDF['FILE_NAME'].desc(),textFileLineTypesDF['LANDING_DATE'].desc(),textFileCompleteDF['PharmacyID'].desc())\n\n    #Agregate lines for FILE_NO_DATA and FILE_LEN_ROW_NOT_OK \n    textFileCompletewithErrorsDF = (textFileCompleteDF.withColumn(\"FILE_NO_DATA\",max(\"FILE_NO_DATA\").over(windowFileErrors))\n                                                   .withColumn(\"FILE_LEN_ROW_NOT_OK\",sum(coalesce(col(\"FILE_LEN_ROW_NOT_OK\"),lit(0)).cast(IntegerType())).over(windowFileErrors))\n                                 )\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Aggregate Lines Not ok Start\" , sys._getframe().f_code.co_name)\n    \n    textFileCompletewithErrorsDF.persist(StorageLevel.MEMORY_AND_DISK)\n    textFileCompletewithErrorsDF.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Aggregate Lines Not ok End\" , sys._getframe().f_code.co_name)\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Build Error DF to persist Start\" , sys._getframe().f_code.co_name)\t   \n    \n    textFileErrorsDF = (textFileCompletewithErrorsDF.select(\"FILE_NAME\",\"LANDING_DATE\",\"PharmacyID\",\"FILE_NO_DATA\",\"FILE_LEN_ROW_NOT_OK\",\"RAW_NAME\",\"FILE_PATH\").distinct()\n                         .withColumn(\"PHARMACY_CODE\",col(\"PharmacyID\"))\n                         .drop(\"PharmacyID\")\n                         .withColumn(\"PMS_CODE\",lit(\"FMT\"))\n                         .withColumn(\"COUNTRY_CODE\",lit(\"ES\"))\n                         .withColumn(\"BUSINESS_AREA\",lit(\"SL\"))\n                         .withColumn(\"LANDING_DATE\",to_timestamp(\"LANDING_DATE\", \"yyyyMMddHHmmss\"))\n                         .withColumn(\"STATUS\",lit(-2).cast(DecimalType(18,0)))\n                         .withColumn(\"VALIDATION_TYPE\",lit('I').cast(StringType()))\n                         .withColumn(\"FILE_NO_DATA_TEXT\",when(col(\"FILE_NO_DATA\")==1,'\"NO_DATA\": \"File does not have data\"').otherwise('\"NO_DATA\": \"OK\"')  )\n                         .withColumn(\"FILE_LEN_ROW_NOT_OK_TEXT\",when(col(\"FILE_LEN_ROW_NOT_OK\")==1,'\"INVALID_STRUCTURE\": \"File does not have a valid structure\"').otherwise('\"INVALID_STRUCTURE\": \"OK\"')  )\n                         .withColumn(\"MESSAGE_TEXT\"  ,  concat(lit(\"{\"),col(\"FILE_NO_DATA_TEXT\"),lit(\",\"),col(\"FILE_LEN_ROW_NOT_OK_TEXT\"),lit(\"}\"))  )\n                         .withColumn(\"ERROR_CODE\"    ,  concat(lit(\"{\"),lit('\"NO_DATA\":'),lit('\"'),col(\"FILE_NO_DATA\"),lit('\"'),lit(\",\"),lit('\"INVALID_STRUCTURE\":'),lit('\"'),col(\"FILE_LEN_ROW_NOT_OK\"),lit('\"'),lit(\"}\"))  )\n                         .filter((col(\"FILE_NO_DATA\")==1) | (col(\"FILE_LEN_ROW_NOT_OK\")==1) )\n                         .drop(\"FILE_NO_DATA\",\"FILE_LEN_ROW_NOT_OK\",\"FILE_NO_DATA_TEXT\",\"FILE_LEN_ROW_NOT_OK_TEXT\")\n                       )\n    \n    # Cache textFileErrorsDF to avoid delete issues\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Build Error DF to persist End\" , sys._getframe().f_code.co_name)\n    textFileErrorsDF = textFileErrorsDF.persist(StorageLevel.MEMORY_AND_DISK)\n    textFileErrorsDF.count()\n\t\n    if __DELETE_FILES_ENABLED__ == True:\n      deleted = (textFileErrorsDF.select(\"RAW_NAME\",\"FILE_PATH\").distinct()\n                       .withColumn(\"deleted\",blob_delete_file_sql(concat(lit(__PHARMATIC_TOBEPROCESSED_BASE_PATH__),col(\"RAW_NAME\"))))\n                       .collect()\n      )\n      \n      #Mount a dataframe with deleted files result\n      if len(deleted)!=0:\n        result_delete_df = sc.parallelize(deleted).toDF()\n        result_delete_df.cache()\n\n        #Calculate Deleted Files\n        total_deleted = (result_delete_df.agg(sum(\"deleted\").alias(\"deleted_total\")).collect())[0].deleted_total\n\n        #Calculate Total Files\n        total_rows = result_delete_df.count()\n\n        #Generate Error if total_deleted < total_rows\n        if total_deleted < total_rows:\n            not_deleted = result_delete_df.filter(col(\"deleted\")==0).collect()\n            not_deleted_names = str([file.RAW_NAME for file in not_deleted]).replace(\"[\",\"\").replace(\"]\",\"\")\n            raise Exception('Fail deleting bad files: '+ not_deleted_names)\n    \n        ADP_log_debug(process, logger_name, level_action, log_level, \"Deleted Files: \" + str(deleted), sys._getframe().f_code.co_name)\n        \n\t#end if __DELETE_FILES_ENABLED__ == True  \n    \n    ######################################################################################################################################################################## \n    #Drop Fields that will not go to disk and add Start and End date before writing to blob and db\n    textFileErrorsDF = (textFileErrorsDF.drop(\"RAW_NAME\",\"FILE_PATH\")\n                            .withColumn(\"START_DATE\", to_timestamp(lit(start_date), 'yyyy-MM-dd HH:mm:ss'))\n                            .withColumn(\"END_DATE\",from_unixtime(unix_timestamp(current_timestamp())).cast(TimestampType()))\n                       )\n\n    ############################################################################################################################################################################\n    textFileErrorsDF = GetDataFrameAsSchema(textFileErrorsDF,__CTL_PROCESS_FILE_VAL_SCHEMA__)\n    \n    #Write data to errors folder\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveAsCanonical CTL_PROCESS_FILE_VAL: \" + str(textFileErrorsDF.count()) + \" rows \", sys._getframe().f_code.co_name)\n    saveAsCanonical(textFileErrorsDF,__QUALITY_PFV_H_FILE_PATH__,table_name=__QUALITY_PFV_H_TABLE_NAME__,mode='append',debug=debug)\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After saveAsCanonical CTL_PROCESS_FILE_VAL \", sys._getframe().f_code.co_name)\n    \n  \n    ##### Save to DB process_file_error QA data ###################################################################################################################################\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveToDB CTL_PROCESS_FILE_VAL: \" + str(textFileErrorsDF.count()) + \" rows \", sys._getframe().f_code.co_name)\n    saveToDB(textFileErrorsDF,__QUALITY_PFV_DB_TABLE_NAME__,mode=\"append\",debug=debug)\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After saveToDB CTL_PROCESS_FILE_VAL\", sys._getframe().f_code.co_name)\n\t\n    #Filter files \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Remove Not Ok Lines Start\", sys._getframe().f_code.co_name)\n    textFileCompletewithErrorsDF = (textFileCompletewithErrorsDF\n                                    .filter((col(\"FILE_NO_DATA\")==0) & (col(\"FILE_LEN_ROW_NOT_OK\")==0) )\n                                    .withColumn(\"PMS_CODE\",lit(\"FMT\"))\n                                    .drop(\"FILE_LEN_ROW_NOT_OK\",\"FILE_NO_DATA\",\"LATEST_LANDING_DATE\")\n                                   )\n    \n    textFileCompletewithErrorsDF.persist(StorageLevel.MEMORY_AND_DISK)\n    textFileCompletewithErrorsDF.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Remove Not Ok Lines End\", sys._getframe().f_code.co_name)\n    \n    #Trim spaces inside fields\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Trim spaces inside fields\", sys._getframe().f_code.co_name)\n    textFileCompletewithErrorsDF = (reduce(\n                lambda textFileCompletewithErrorsDF, col_name: textFileCompletewithErrorsDF.withColumn(col_name, trim(col(col_name))),\n                textFileCompletewithErrorsDF.columns,\n                textFileCompletewithErrorsDF)\n            ).cache()\n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n    \n    return textFileCompletewithErrorsDF\n  except Exception as err:\n    if str(err).__contains__('Fail deleting bad files'):\n      ADP_log_debug(process, logger_name, level_action, log_level, \"In Exception clause: \", sys._getframe().f_code.co_name)\n      not_deleted_names = [file.RAW_NAME for file in not_deleted]\n      textFileErrorsDF = textFileErrorsDF.filter(textFileErrorsDF.RAW_NAME.isin(*not_deleted_names) == False)\n      #Drop Fields that will not go to disk and add Start and End date before writing to blob and db\n      textFileErrorsDF = (textFileErrorsDF.drop(\"RAW_NAME\",\"FILE_PATH\")\n                              .withColumn(\"START_DATE\", to_timestamp(lit(start_date), 'yyyy-MM-dd HH:mm:ss'))\n                              .withColumn(\"END_DATE\",from_unixtime(unix_timestamp(current_timestamp())).cast(TimestampType()))\n                         )\n      ############################################################################################################################################################################\n      textFileErrorsDF = GetDataFrameAsSchema(textFileErrorsDF,__CTL_PROCESS_FILE_VAL_SCHEMA__)\n      textFileErrorsDF.show(truncate=False)\n\n      #Write data to errors folder\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveAsCanonical CTL_PROCESS_FILE_VAL: \" + str(textFileErrorsDF.count()) + \" rows \", sys._getframe().f_code.co_name)\n      saveAsCanonical(textFileErrorsDF,__QUALITY_PFV_H_FILE_PATH__,table_name=__QUALITY_PFV_H_TABLE_NAME__,mode='append',debug=debug)\n      ADP_log_debug(process, logger_name, level_action, log_level, \"After saveAsCanonical CTL_PROCESS_FILE_VAL\", sys._getframe().f_code.co_name)\n      \n      ##### Save to DB process_file_error QA data ###############################################################################################################################\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveToDB CTL_PROCESS_FILE_VAL: \" + str(textFileErrorsDF.count()) + \" rows \", sys._getframe().f_code.co_name)\n      saveToDB(textFileErrorsDF,__QUALITY_PFV_DB_TABLE_NAME__,mode=\"append\",debug=debug)\n      ADP_log_debug(process, logger_name, level_action, log_level, \"After saveToDB CTL_PROCESS_FILE_VAL\", sys._getframe().f_code.co_name)\n    #endif str(e).__contains__('Fail deleting bad files')\n    \n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n  \n#############################################################################################################################\n\ndef FieldFormatValidationsFarmaticSellout(df,debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__):\n  \"\"\"Validate Sellout Columns structure and Add a Column for each field with the validation Result.\n\n    Parameters:\n      df                   -- Dataframe with the result of the Normalize Process\n      debug                -- True for enable debug verbosing or False to not enable\n      partitions           -- Partitions defined\n\n    Return:\n      Dataframe            -- Dataframe containing the files with splitted data and the new validation columns and filename and line num \n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       18/12/2018     Create Function Stub\n  #Ana Perez           20/12/2018     Validations and Initial transformations\n  #Ana Perez           11/01/2019     Calculates Negatives TotalOfReceipts\n  #Ana Perez           25/01/2019     Includes new fields calculation\n  #Ana Perez           31/01/2019     Fix Null values into PRODUCT_NET_WEIGTHED_PRICE field\n  #Ana Perez           04/02/2019     Fix DATA_TYPE validations DecreasedValTotReceipt,DATA_EMPTY ProductCode \n  #Ana Perez           10/04/2019     Included log managment and exception managment\n  #Ana Perez           15/04/2019     Included log debug managment\n  #Ana Perez           22/04/2019     Included new QA files  (NUM_ERROR_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n  #Victor Salesa       29/04/2019     Included new QA fields (NUM_VALIDATED_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n  #Victor Salesa       29/04/2019     Drop Cols ROW_KO_PMS,ROW_KO_MDM,NUMBER_OF_VALIDATED_FIELDS_PMS,NUMBER_OF_VALIDATED_FIELDS_MDM,\"OLD\" ROW_OK, ROW_KO\n  try:    \n    \n    ################################################################################################################################################\n    #  VALIDATION FORMAT DATA FIELDS\n    ################################################################################################################################################\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n\n    df_detail = (df\n       .drop(\"RecordType\")\n       .withColumn(\"OPERATION_LINE_RAW\", col(\"OperationLine\"))\n       .withColumn(\"OPERATION_DATE_RAW\", col(\"OperationDate\"))\n       .withColumn(\"CUSTOMER_CODE_RAW\", col(\"PharmacyID\")) \n       .withColumn(\"NATIONAL_CODE_RAW\", col(\"ProductCode\"))\n       .withColumn(\"PRODUCT_LINE_CODE_RAW\", col(\"ProductCode\")) \n       .withColumn(\"PRODUCT_NAME_RAW\", col(\"ProductCode\")) \n       .withColumn(\"CLASS_RAW\", col(\"ProductCode\"))\n       .withColumn(\"CATEGORY_RAW\", col(\"ProductCode\")) \n       .withColumn(\"MANUFACTURER_CODE_RAW\", col(\"ProductCode\")) \n       .withColumn(\"MANUFACTURER_NAME_RAW\", col(\"ProductCode\")) \n       .withColumn(\"BRAND_RAW\", col(\"ProductCode\"))    \n       .withColumn(\"TOT_RECEIPT_AMOUNT_RAW\", col(\"TotalOfReceipt\"))   \n       .withColumn(\"TOT_RECEIPT_DISCOUNT_AMOUNT_RAW\", col(\"DiscountValOvertTotReceipt\"))   \n       .withColumn(\"TOT_RECEIPT_DECREASE_AMOUNT_RAW\", col(\"DecreasedValTotReceipt\"))   \n       .withColumn(\"PRODUCT_QTY_RAW\", col(\"ProductPacks\"))  \n       .withColumn(\"PACK_SIZE_RAW\", col(\"ProductPackSize\")) \n       .withColumn(\"PRODUCT_PRICE_CATALOG_RAW\", col(\"ProductPriceCatalog\"))   \n       .withColumn(\"PRODUCT_PRICE_RAW\", col(\"ProductPrice\"))\n       .withColumn(\"DISCOUNT_VALUE_RAW\", col(\"DiscountValue\"))      \n       .withColumn(\"PRODUCT_TOTAL_AMOUNT_RAW\", col(\"ProductTotalPrice\")) \n       .withColumn(\"REIMBURSEMENT_AMOUNT_RAW\", col(\"ReimbursementValue\"))  \n       .withColumn(\"CONSUMER_AMOUNT_RAW\", col(\"ConsumerValue\"))    \n       .withColumn(\"PAYMENT_MODE_RAW\", col(\"PaymentMode\"))       \n       .withColumn(\"CONSUMER_GENDER_RAW\", col(\"ConsumerGender\")) \n       .withColumn(\"CONSUMER_TYPE_RAW\", col(\"ConsumerType\")) \n       .withColumn(\"OPERATION_TYPE_RAW\", col(\"OperationIdent\"))  \n       .withColumn(\"PRESCRIPTION_MODE_RAW\", col(\"PrescriptionMode\"))  \n       .withColumn(\"PRESCRIPTION_TYPE_RAW\", col(\"PrescriptionType\"))  \n       .withColumn(\"PRESCRIPTION_FLG_RAW\", col(\"PrescriptionIdent\"))   \n       .withColumn(\"REIMBURSEMENT_FLG_RAW\", col(\"Reimbursement\"))\n       .withColumn(\"ISSUED_VOUCHERS_AMOUNT_RAW\", col(\"ValueIssuedVouchers\"))\n       .withColumn(\"USED_VOUCHERS_AMOUNT_RAW\", col(\"ValueUsedVouchers\"))\n       .withColumn(\"ISSUED_VOUCHERS_NUM_RAW\", col(\"NumberIssuedVouchers\"))\n       .withColumn(\"USED_VOUCHERS_NUM_RAW\", col(\"NumberUsedVouchers\"))\n       .withColumn(\"NUM_VALIDATED_FIELDS_COMPLETENESS\",lit(__FMT_SL_NUM_VALIDATED_FIELDS_COMPLETENESS__).cast(IntegerType()))\n       .withColumn(\"NUM_VALIDATED_FIELDS_ACCURACY\",lit(__FMT_SL_NUM_VALIDATED_FIELDS_ACCURACY__).cast(IntegerType()))\n       .withColumn(\"NUM_VALIDATED_FIELDS_DUPLICATE\",lit(__FMT_SL_NUM_VALIDATED_FIELDS_DUPLICATE__).cast(IntegerType()))\n       .withColumn(\"NUM_VALIDATED_FIELDS_CONFORMITY\",lit(__FMT_SL_NUM_VALIDATED_FIELDS_CONFORMITY__).cast(IntegerType()))      \n       .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", lit(0).cast(IntegerType()))\n       .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\",  lit(0).cast(IntegerType()))\n       .withColumn(\"NUM_ERROR_FIELDS_DUPLICATE\",  lit(0).cast(IntegerType()))\n       .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\",lit(0).cast(IntegerType()))\n              )\n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"--After add raw columns\", sys._getframe().f_code.co_name)\n\t\n    df_detail = (df_detail\n      # Validate OperationLine\n      .withColumn(\"OperationLine_Err2\",  when((isDigit(\"OperationLine\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None)))         \n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"OperationLine\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n\n      .withColumn(\"OperationLine_Err2\",   \n                  when(\n                      ((length(\"OperationLine\")==__OPERATIONLINE_LEN__)==False), \n                        (when(((length(\"OperationLine_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"OperationLine_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"OperationLine_Err2\"))                       \n                 )\n      .withColumn(\"OperationLine_Err2\",  when(((length(\"OperationLine_Err2\")>0)==True),concat(lit(\"{\"),col(\"OperationLine_Err2\"),lit(\"}\"))).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((length(\"OperationLine\")==__OPERATIONLINE_LEN__)==False, col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n                 \n        # Validate OperationDate \n      .withColumn(\"OperationDate_Err2\",  when( (udf_isDate_sql(\"OperationDate\",lit(__YYYYMMDDhhmmss__)))==False, ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None))) \n      .withColumn(\"OperationDate_Err2\",  when(((length(\"OperationDate_Err2\")>0)==True),concat(lit(\"{\"),col(\"OperationDate_Err2\"),lit(\"}\"))).otherwise(lit(None)))\n                 \n       .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when(udf_isDate_sql(\"OperationDate\",lit(__YYYYMMDDhhmmss__))==False,\\\n               col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n                 \n       # Validate TotalOfReceipt           \n      .withColumn(\"TotalOfReceipt_Err2\",   when((isDigit(\"TotalOfReceipt\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None))) \n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"TotalOfReceipt\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n                 \n      .withColumn(\"TotalOfReceipt_Err2\",   \n                  when(\n                      ((length(\"TotalOfReceipt\")==0)==True),  \n                        (when(((length(\"TotalOfReceipt_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"TotalOfReceipt_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"TotalOfReceipt_Err2\"))                       \n                 )\n      .withColumn(\"TotalOfReceipt_Err2\",   when(((length(\"TotalOfReceipt_Err2\")>0)==True),concat(lit(\"{\"),col(\"TotalOfReceipt_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"TotalOfReceipt\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                 \n       # Validate DiscountValOvertTotReceipt           \n      .withColumn(\"DiscountValOvertTotReceipt_Err2\",   when((isDigit(\"DiscountValOvertTotReceipt\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None))) \n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"DiscountValOvertTotReceipt\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))          \n      .withColumn(\"DiscountValOvertTotReceipt_Err2\",   \n                  when(\n                      ((length(\"DiscountValOvertTotReceipt\")==0)==True),  \n                        (when(((length(\"DiscountValOvertTotReceipt_Err2\")==0)==True),\n                              ('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"DiscountValOvertTotReceipt_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"DiscountValOvertTotReceipt_Err2\"))                       \n                 )\n      .withColumn(\"DiscountValOvertTotReceipt_Err2\",   when(((length(\"DiscountValOvertTotReceipt_Err2\")>0)==True),concat(lit(\"{\"),col(\"DiscountValOvertTotReceipt_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"DiscountValOvertTotReceipt_Err2\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                 \n       # Validate DecreasedValTotReceipt           \n      .withColumn(\"DecreasedValTotReceipt_Err2\", when((isDigit(\"DecreasedValTotReceipt\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None))) \n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"DecreasedValTotReceipt\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n                 \n      .withColumn(\"DecreasedValTotReceipt_Err2\",   when(((length(\"DecreasedValTotReceipt_Err2\")>0)==True),concat(lit(\"{\"),col(\"DecreasedValTotReceipt_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n\n       # Validate ProductCode           \n      .withColumn(\"ProductCode_Err2\",   when(((length(\"ProductCode\")==0)==True),  ('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(lit(None)))                \n      .withColumn(\"ProductCode_Err2\",   when(((length(\"ProductCode_Err2\")>0)==True),concat(lit(\"{\"),col(\"ProductCode_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"ProductCode\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n\n       # Validate ProductPacks             \n      .withColumn(\"ProductPacks_Err2\",   when((isDigit(\"ProductPacks\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"ProductPacks\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n      .withColumn(\"ProductPacks_Err2\",   \n                  when(\n                      ((length(\"ProductPacks\")==0)==True),  \n                        (when(((length(\"ProductPacks_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"ProductPacks_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"ProductPacks_Err2\"))                       \n                 )\n      .withColumn(\"ProductPacks_Err2\",   when(((length(\"ProductPacks_Err2\")>0)==True),concat(lit(\"{\"),col(\"ProductPacks_Err2\"),lit(\"}\"))).otherwise(lit(None))) \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"ProductPacks\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))     \n\n       # Validate ProductPackSize          \n      .withColumn(\"ProductPackSize_Err2\", when((isDigit(\"ProductPackSize\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"ProductPackSize\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n      .withColumn(\"ProductPackSize_Err2\",   \n                  when(\n                      ((length(\"ProductPackSize\")==0)==True),  \n                        (when(((length(\"ProductPackSize_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"ProductPackSize_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"ProductPackSize_Err2\"))                       \n                 )\n      .withColumn(\"ProductPackSize_Err2\", when(((length(\"ProductPackSize_Err2\")>0)==True),concat(lit(\"{\"),col(\"ProductPackSize_Err2\"),lit(\"}\"))).otherwise(lit(None)))                        \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"ProductPackSize\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\"))) \n                 \n       # Validate ProductPriceCatalog  \n      .withColumn(\"ProductPriceCatalog_Err2\", when((isDigit(\"ProductPriceCatalog\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"ProductPriceCatalog\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n      .withColumn(\"ProductPriceCatalog_Err2\",   \n                  when(\n                      ((length(\"ProductPriceCatalog\")==0)==True),  \n                        (when(((length(\"ProductPriceCatalog_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"ProductPriceCatalog_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"ProductPriceCatalog_Err2\"))                       \n                 )\n      .withColumn(\"ProductPriceCatalog_Err2\",   when(((length(\"ProductPriceCatalog_Err2\")>0)==True),concat(lit(\"{\"),col(\"ProductPriceCatalog_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"ProductPriceCatalog\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                 \n       # Validate ProductPrice        \n      .withColumn(\"ProductPrice_Err2\", when((isDigit(\"ProductPrice\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None))) \n      .withColumn(\"ProductPrice_Err2\",   \n                  when(\n                      ((length(\"ProductPrice\")==0)==True),  \n                        (when(((length(\"ProductPrice_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"ProductPrice_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"ProductPrice_Err2\"))                       \n                 )\n      .withColumn(\"ProductPrice_Err2\",  when(((length(\"ProductPrice_Err2\")>0)==True),concat(lit(\"{\"),col(\"ProductPrice_Err2\"),lit(\"}\"))).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"ProductPrice\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n\n       # Validate DiscountValue\n      .withColumn(\"DiscountValue_Err2\", when((isDigit(\"DiscountValue\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"DiscountValue\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n      .withColumn(\"DiscountValue_Err2\", when(((length(\"DiscountValue_Err2\")>0)==True),concat(lit(\"{\"),col(\"DiscountValue_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n\n       # Validate ProductTotalPrice                   \n      .withColumn(\"ProductTotalPrice_Err2\", when((isDigit(\"ProductTotalPrice\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"ProductTotalPrice\")==False), col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n      .withColumn(\"ProductTotalPrice_Err2\",   \n                  when(\n                      ((length(\"ProductTotalPrice\")==0)==True),  \n                        (when(((length(\"ProductTotalPrice_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"ProductTotalPrice_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"ProductTotalPrice_Err2\"))                       \n                 )\n      .withColumn(\"ProductTotalPrice_Err2\", when(((length(\"ProductTotalPrice_Err2\")>0)==True),concat(lit(\"{\"),col(\"ProductTotalPrice_Err2\"),lit(\"}\"))).otherwise(lit(None)))             \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"ProductTotalPrice\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                 \n       # Validate ReimbursementValue \n      .withColumn(\"ReimbursementValue_Err2\", when((isDigit(\"ReimbursementValue\")==True)| (length(col(\"ReimbursementValue\"))==0), lit(None)).otherwise(('\"' + 'DATA_TYPE' + '\":' + '\"1\"')))\n      .withColumn(\"ReimbursementValue_Err2\",  when(((length(\"ReimbursementValue_Err2\")>0)==True),concat(lit(\"{\"),col(\"ReimbursementValue_Err2\"),lit(\"}\"))).otherwise(lit(None)))         \n\n       # Validate ConsumerValue                 \n      .withColumn(\"ConsumerValue_Err2\", when((isDigit(\"ConsumerValue\")==True)| (length(col(\"ConsumerValue\"))==0), lit(None)).otherwise(('\"' + 'DATA_TYPE' + '\":' + '\"1\"')))\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when((isDigit(\"ConsumerValue\")==True)| (length(col(\"ConsumerValue\"))==0),col(\"NUM_ERROR_FIELDS_CONFORMITY\")).\\\n                                                     otherwise( col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())))\n      .withColumn(\"ConsumerValue_Err2\",   \n                  when(\n                      ((length(\"ConsumerValue\")==__CONSUMERVALUE_LEN__)==False),      \n                        (when(((length(\"ConsumerValue_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"ConsumerValue_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"ConsumerValue_Err2\"))                       \n                 )\n      .withColumn(\"NUM_ERROR_FIELDS_CONFORMITY\", when(((length(\"ConsumerValue\")==__CONSUMERVALUE_LEN__)==False) & (length(col(\"ConsumerValue\"))>0),  col(\"NUM_ERROR_FIELDS_CONFORMITY\")+lit(1).cast(IntegerType())).\\\n                                                    otherwise(col(\"NUM_ERROR_FIELDS_CONFORMITY\")))\n       # Validate PaymentMode          \n      .withColumn(\"PaymentMode_Err2\", when((col(\"PaymentMode\").isin(list(lov_PAYMENT_MODE.keys()))==False),  ('\"' + 'DATA_LOV' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"PaymentMode\").isin(list(lov_PAYMENT_MODE.keys()))==False), col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())).\\\n                                                    otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")))\n      .withColumn(\"PaymentMode_Err2\",   \n                  when(\n                      ((length(\"PaymentMode\")==0)==True),  \n                        (when(((length(\"PaymentMode_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"PaymentMode_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"PaymentMode_Err2\"))\n                 )\n      .withColumn(\"PaymentMode_Err2\",  when(((length(\"PaymentMode_Err2\")>0)==True),concat(lit(\"{\"),col(\"PaymentMode_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"PaymentMode\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))               \n\n       # Validate ConsumerGender  (nullable LOV)  \n      .withColumn(\"ConsumerGender_Err2\", when(((col(\"ConsumerGender\").isin(list(lov_CONSUMER_GENDER.keys()))) | (length(col(\"ConsumerGender\"))==0)), lit(None)).otherwise(('\"' + 'DATA_LOV' + '\":' + '\"1\"')))   \n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when(((col(\"ConsumerGender\").isin(list(lov_CONSUMER_GENDER.keys()))) | (length(col(\"ConsumerGender\"))==0)), col(\"NUM_ERROR_FIELDS_ACCURACY\")).\\\n                                                     otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())))\n      .withColumn(\"ConsumerGender_Err2\", when(((length(\"ConsumerGender_Err2\")>0)==True),concat(lit(\"{\"),col(\"ConsumerGender_Err2\"),lit(\"}\"))).otherwise(lit(None)))   \n\n       # Validate ConsumerType  (nullable)         \n      .withColumn(\"ConsumerType_Err2\", when((col(\"ConsumerType\").isin(list(lov_CONSUMER_TYPE.keys())) | (length(col(\"ConsumerType\"))==0)), lit(None)).otherwise(('\"' + 'DATA_LOV' + '\":' + '\"1\"')))           \n      .withColumn(\"ConsumerType_Err2\", when(((length(\"ConsumerType_Err2\")>0)==True),concat(lit(\"{\"),col(\"ConsumerType_Err2\"),lit(\"}\"))).otherwise(lit(None)))       \n\t  .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"ConsumerType\").isin(list(lov_CONSUMER_TYPE.keys())) | (length(col(\"ConsumerType\"))==0)), col(\"NUM_ERROR_FIELDS_ACCURACY\")).\\\n                                                    otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())))\n\n       # Validate OperationIdent   (required)        \n      .withColumn(\"OperationIdent_Err2\", when((col(\"OperationIdent\").isin(list(lov_OPERATION_TYPE.keys()))==False),  ('\"' + 'DATA_LOV' + '\":' + '\"1\"')).otherwise(lit(None)))    \n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"OperationIdent\").isin(list(lov_OPERATION_TYPE.keys()))==False), col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())).\\\n                                                    otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")))\n      .withColumn(\"OperationIdent_Err2\",   \n                  when(\n                      ((length(\"OperationIdent\")==0)==True),  \n                        (when(((length(\"OperationIdent_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"OperationIdent_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"OperationIdent_Err2\"))                       \n                 )\n      .withColumn(\"OperationIdent_Err2\",  when(((length(\"OperationIdent_Err2\")>0)==True),concat(lit(\"{\"),col(\"OperationIdent_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"OperationIdent\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                 \n       # Validate PrescriptionIdent   (required)        \n      .withColumn(\"PrescriptionIdent_Err2\", when((col(\"PrescriptionIdent\").isin(list(lov_YES_NO.keys()))==False),  ('\"' + 'DATA_LOV' + '\":' + '\"1\"')).otherwise(lit(None)))\n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"PrescriptionIdent\").isin(list(lov_YES_NO.keys()))==False), col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")))\n      .withColumn(\"PrescriptionIdent_Err2\",   \n                  when(\n                      ((length(\"PrescriptionIdent\")==0)==True),  \n                        (when(((length(\"PrescriptionIdent_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"PrescriptionIdent_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"PrescriptionIdent_Err2\"))                       \n                 )\n      .withColumn(\"PrescriptionIdent_Err2\",  when(((length(\"PrescriptionIdent_Err2\")>0)==True),concat(lit(\"{\"),col(\"PrescriptionIdent_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"PrescriptionIdent\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                 \n       # Validate PrescriptionMode  (nullable)         \n      .withColumn(\"PrescriptionMode_Err2\", when((col(\"PrescriptionMode\").isin(list(lov_PRESCRIPTION_MODE.keys()))) | (length(col(\"PrescriptionMode\"))==0), lit(None)).otherwise(('\"' + 'DATA_LOV' + '\":' + '\"1\"')))  \n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"PrescriptionMode\").isin(list(lov_PRESCRIPTION_MODE.keys()))) | (length(col(\"PrescriptionMode\"))==0),col(\"NUM_ERROR_FIELDS_ACCURACY\")).\\\n                                                 otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())))\n      .withColumn(\"PrescriptionMode_Err2\", when(((length(\"PrescriptionMode_Err2\")>0)==True),concat(lit(\"{\"),col(\"PrescriptionMode_Err2\"),lit(\"}\"))).otherwise(lit(None)))   \n\n       # Validate PrescriptionType  (nullable)         \n      .withColumn(\"PrescriptionType_Err2\", when((col(\"PrescriptionType\").isin(list(lov_PRESCRIPTION_TYPE.keys()))) | (length(col(\"PrescriptionType\"))==0), lit(None)).otherwise(('\"' + 'DATA_LOV' + '\":' + '\"1\"'))) \n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"PrescriptionType\").isin(list(lov_PRESCRIPTION_TYPE.keys()))) | (length(col(\"PrescriptionType\"))==0), col(\"NUM_ERROR_FIELDS_ACCURACY\")).\\\n                                                otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())))\n\n      .withColumn(\"PrescriptionType_Err2\", when(((length(\"PrescriptionType_Err2\")>0)==True),concat(lit(\"{\"),col(\"PrescriptionType_Err2\"),lit(\"}\"))).otherwise(lit(None)))   \n\n       # Validate Reimbursement   (required)        \n      .withColumn(\"Reimbursement_Err2\", when((col(\"Reimbursement\").isin(list(lov_YES_NO.keys()))==False),  ('\"' + 'DATA_LOV' + '\":' + '\"1\"')).otherwise(lit(None)))    \n      .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col(\"Reimbursement\").isin(list(lov_YES_NO.keys()))==False), col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")))\n\n      .withColumn(\"Reimbursement_Err2\",   \n                  when(\n                      ((length(\"Reimbursement\")==0)==True),  \n                        (when(((length(\"Reimbursement_Err2\")==0)==True),('\"' + 'DATA_EMPTY' + '\":' + '\"1\"')).otherwise(concat(col(\"Reimbursement_Err2\"), lit(',\"' + 'DATA_EMPTY' + '\":' + '\"1\"'))))\n                      ).otherwise(col(\"Reimbursement_Err2\"))                       \n                 )\n      .withColumn(\"Reimbursement_Err2\",  when(((length(\"Reimbursement_Err2\")>0)==True),concat(lit(\"{\"),col(\"Reimbursement_Err2\"),lit(\"}\"))).otherwise(lit(None)))  \n      .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when((length(\"Reimbursement\")==0)==True, col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())).otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")))\n                )\n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"--After Validations\", sys._getframe().f_code.co_name)\n    ################################################################################################################################################\n    #  END VALIDATION FORMAT DATA FIELDS\n    ################################################################################################################################################\n\n    ################################################################################################################################################\n    #  TRANSFORMATION DATA FIELDS\n    ################################################################################################################################################\n\n    df_detail = (df_detail     \n                  #Numeric Required fields: when the field has a incorrect value OR a NULL value, it is replaced by the defect value -9999999\n                 .withColumn(\"FILE_LINE_NUM\", (when((isDigit(\"FILE_LINE_NUM\")==False),  lit(-999)).otherwise(col(\"FILE_LINE_NUM\").cast(DecimalType(10,0)))))\n                 .withColumn(\"OperationLine\", (when((isDigit(\"OperationLine\")==False),  lit(-999)).otherwise(col(\"OperationLine\").cast(DecimalType(10,0)))))\n                 .withColumn(\"ProductPacks\", (when((isDigit(\"ProductPacks\")==False),  lit(-999999)).otherwise(col(\"ProductPacks\").cast(DecimalType(10,0)))))\n                 .withColumn(\"TotalOfReceipt\", ((when((isDigit(\"TotalOfReceipt\")==False),  lit(-999999)).otherwise(col(\"TotalOfReceipt\").cast(IntegerType())/100))).cast(DecimalType(12,2)))    \n                 .withColumn(\"ProductPrice\", ((when((isDigit(\"ProductPrice\")==False),  lit(-999999)).otherwise(col(\"ProductPrice\").cast(IntegerType())/100))).cast(DecimalType(12,2)))          \n                 .withColumn(\"ProductTotalPrice\", ((when((isDigit(\"ProductTotalPrice\")==False),  lit(-999999)).otherwise(col(\"ProductTotalPrice\").cast(IntegerType())/100))).cast(DecimalType(12,2)))      \n\n                  #Numeric Optional fields: when the field has a incorrect value, it is replaced by the defect value -9999999; when the field has NULL value it is replaced by 0 VALUE\n                 .withColumn(\"ConsumerAge\", (when((length(col(\"ConsumerAge\"))==0), lit(0))\\\n                                                      .otherwise(when((isDigit(\"ConsumerAge\")==False),  lit(-9999)).otherwise(col(\"ConsumerAge\")))).cast(DecimalType(4,0)))\n                 .withColumn(\"ProductPackSize\", (when((length(col(\"ProductPackSize\"))==0), lit(0))\\\n                                                      .otherwise(when((isDigit(\"ProductPackSize\")==False),  lit(-999999)).otherwise(col(\"ProductPackSize\")))).cast(DecimalType(10,0)))\n                 .withColumn(\"NumberIssuedVouchers\", (when((length(col(\"NumberIssuedVouchers\"))==0), lit(0))\\\n                                                      .otherwise(when((isDigit(\"NumberIssuedVouchers\")==False),  lit(-999999)).otherwise(col(\"NumberIssuedVouchers\")))).cast(DecimalType(10,0)))\n                 .withColumn(\"NumberUsedVouchers\", (when((length(col(\"NumberUsedVouchers\"))==0), lit(0))\\\n                                                      .otherwise(when((isDigit(\"NumberUsedVouchers\")==False),  lit(-999999)).otherwise(col(\"NumberUsedVouchers\")))).cast(DecimalType(10,0)))\n                 .withColumn(\"ValueIssuedVouchers\", ((when((length(col(\"ValueIssuedVouchers\"))==0), lit(0.0)).otherwise(when((isDigit(\"ValueIssuedVouchers\")==False),  lit(-999999))\\\n                                                                                                             .otherwise(col(\"ValueIssuedVouchers\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"ValueUsedVouchers\", ((when((length(col(\"ValueUsedVouchers\"))==0), lit(0.0)).otherwise(when((isDigit(\"ValueUsedVouchers\")==False),  lit(-999999))\\\n                                                                                                         .otherwise(col(\"ValueUsedVouchers\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"ProductPriceCatalog\", ((when((length(col(\"ProductPriceCatalog\"))==0), lit(0.0)).otherwise(when((isDigit(\"ProductPriceCatalog\")==False),  lit(-999999))\\\n                                                                                                              .otherwise(col(\"ProductPriceCatalog\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"DiscountValOvertTotReceipt\", ((when((length(col(\"DiscountValOvertTotReceipt\"))==0), lit(0.0)).otherwise(when((isDigit(\"DiscountValOvertTotReceipt\")==False),  lit(-999999))\\\n                                                                                                               .otherwise(col(\"DiscountValOvertTotReceipt\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"DecreasedValTotReceipt\", ((when((length(col(\"DecreasedValTotReceipt\"))==0), lit(0.0)).otherwise(when((isDigit(\"DecreasedValTotReceipt\")==False),  lit(-999999))\\\n                                                                                                                   .otherwise(col(\"DecreasedValTotReceipt\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"DiscountValue\", ((when((length(col(\"DiscountValue\"))==0), lit(0.0)).otherwise(when((isDigit(\"DiscountValue\")==False),  lit(-999999))\\\n                                                                                                 .otherwise(col(\"DiscountValue\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"ProductFee\", ((when((length(col(\"ProductFee\"))==0), lit(0.0)).otherwise(when((isDigit(\"ProductFee\")==False),  lit(-999999))\\\n                                                                                           .otherwise(col(\"ProductFee\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"ProductMarkup\", ((when((length(col(\"ProductMarkup\"))==0), lit(0.0)).otherwise(when((isDigit(\"ProductMarkup\")==False),  lit(-999999))\\\n                                                                                                 .otherwise(col(\"ProductMarkup\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"CoPaymentValue\", ((when((length(col(\"CoPaymentValue\"))==0), lit(0.0)).otherwise(when((isDigit(\"CoPaymentValue\")==False),  lit(-999999))\\\n                                                                                                 .otherwise(col(\"CoPaymentValue\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"ReimbursementValue\", ((when((length(col(\"ReimbursementValue\"))==0),  lit(0.0)).otherwise(when((isDigit(\"ReimbursementValue\")==False),  lit(-999999))\\\n                                                                                                            .otherwise(col(\"ReimbursementValue\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n                 .withColumn(\"ConsumerValue\", ((when((length(col(\"ConsumerValue\"))==0), lit(0.0)).otherwise(when((isDigit(\"ConsumerValue\")==False),  lit(-999999))\\\n                                                                                                            .otherwise(col(\"ConsumerValue\")))).cast(IntegerType())/100).cast(DecimalType(12,2)))\n\n                  #Required (when the field has a incorrect value OR a NULL value, it is replaced by the defect value)\n                 .withColumn(\"OperationDate\",  when((udf_isDate_sql(\"OperationDate\",lit(__YYYYMMDDhhmmss__))==True), col(\"OperationDate\")).otherwise(\"00010101000000\"))              \n                 .withColumn(\"PaymentMode\", when((col(\"PaymentMode\").isin(list(lov_PAYMENT_MODE.keys()))==True), col(\"PaymentMode\")).otherwise(\"-1\"))\n                 .withColumn(\"OperationIdent\", when((col(\"OperationIdent\").isin(list(lov_OPERATION_TYPE.keys()))==True), col(\"OperationIdent\")).otherwise(\"-1\"))                 \n                 .withColumn(\"ProductCode\",  when(((length(\"ProductCode\")==0)==False), col(\"ProductCode\")).otherwise(\"-9\"))\n\n                  #Optional (when the field has a Null value it does not replaced; when the field has a incorrect value it is replaced by the defect value)\n                 .withColumn(\"ConsumerGender\", when(((col(\"ConsumerGender\").isin(list(lov_CONSUMER_GENDER.keys()))==True) | (length(col(\"ConsumerGender\"))==0)), col(\"ConsumerGender\")).otherwise(\"-1\"))\n                 .withColumn(\"ConsumerType\", when(((col(\"ConsumerType\").isin(list(lov_CONSUMER_TYPE.keys()))==True) | (length(col(\"ConsumerType\"))==0)), col(\"ConsumerType\")).otherwise(\"-1\"))\n                 .withColumn(\"PrescriptionMode\", when(((col(\"PrescriptionMode\").isin(list(lov_PRESCRIPTION_MODE.keys()))==True) | (length(col(\"PrescriptionMode\"))==0)), col(\"PrescriptionMode\")).otherwise(\"-1\"))\n                 .withColumn(\"PrescriptionType\", when(((col(\"PrescriptionType\").isin(list(lov_PRESCRIPTION_TYPE.keys()))==True) | (length(col(\"PrescriptionType\"))==0)), col(\"PrescriptionType\")).otherwise(\"-1\"))\n                 .withColumn(\"PrescriptionIdent\", when(((col(\"PrescriptionIdent\").isin(list(lov_YES_NO.keys()))==True) | (length(col(\"PrescriptionIdent\"))==0)), col(\"PrescriptionIdent\")).otherwise(\"-\"))\n                 .withColumn(\"Reimbursement\", when(((col(\"Reimbursement\").isin(list(lov_YES_NO.keys()))==True) | (length(col(\"Reimbursement\"))==0)), col(\"Reimbursement\")).otherwise(\"-\"))\n\n                   #Transform to TimeStamp or Date \n                 .withColumn(\"FileDate\",   to_timestamp(\"FileDate\", \"yyyyMMddHHmmss\"))\n                 .withColumn(\"LANDING_DATE\",   to_timestamp(\"LANDING_DATE\", \"yyyyMMddHHmmss\"))\n                 .withColumn(\"PROCESS_DATE\",   to_timestamp(\"PROCESS_DATE\", \"yyyyMMddHHmmss\"))\n                 .withColumn(\"OperationDate\",   to_timestamp(\"OperationDate\", \"yyyyMMddHHmmss\"))\n\n                  #Transform the negative TotalOfReceipt\n                 .withColumn(\"TotalOfReceipt\", (when(col('TotalReceiptSignal')==lit('N'),  (col(\"TotalOfReceipt\")*-1)).otherwise(col(\"TotalOfReceipt\"))).cast(DecimalType(12,2)) ) \n              ).alias('df_detail')\n    ADP_log_debug(process, logger_name, level_action, log_level, \"--After Transformations - Default values\", sys._getframe().f_code.co_name)\n   \n    #Define window to aggregate amounts at operation level\n    windowSpec = Window.partitionBy(df_detail['FILE_NAME'], df_detail['PharmacyID'], df_detail['OperationDate'], df_detail['OperationID'])\n\n    df_detail = (df_detail\n                 .withColumn(\"SUM_ProductTotalPrice\",sum(\"ProductTotalPrice\").over(windowSpec))\n                 .withColumn(\"SUM_ProductTotalPrice\", when((col('SUM_ProductTotalPrice').isNull()==True), lit(0.0)).otherwise(col('SUM_ProductTotalPrice')))\n                 \n                 .withColumn(\"PRODUCT_NET_PRICE\",(col('ProductTotalPrice') / col('ProductPacks')))\n                 .withColumn(\"PRODUCT_NET_PRICE\", when((col('PRODUCT_NET_PRICE').isNull()==True), lit(0.0)).otherwise(col('PRODUCT_NET_PRICE')))\n                 .withColumn(\"DISCOUNT_WEIGTHED_AMOUNT\",((col('DiscountValOvertTotReceipt') / col('SUM_ProductTotalPrice')) * col('ProductTotalPrice')))\n                 .withColumn(\"DISCOUNT_WEIGTHED_AMOUNT\", when((col('DISCOUNT_WEIGTHED_AMOUNT').isNull()==True), lit(0.0)).otherwise(col('DISCOUNT_WEIGTHED_AMOUNT')))\n                 .withColumn(\"PRODUCT_NET_WEIGTHED_PRICE\",(col('PRODUCT_NET_PRICE')-col('DISCOUNT_WEIGTHED_AMOUNT')/col('ProductPacks')))\n                 .withColumn(\"PRODUCT_NET_WEIGTHED_PRICE\", when((col('PRODUCT_NET_WEIGTHED_PRICE').isNull()==True), lit(0.0)).otherwise(col('PRODUCT_NET_WEIGTHED_PRICE')))\n\n                 .withColumn(\"PRODUCT_NET_PRICE\",(col('PRODUCT_NET_PRICE')).cast(DecimalType(12,2)))\n                 .withColumn(\"DISCOUNT_WEIGTHED_AMOUNT\",(col('DISCOUNT_WEIGTHED_AMOUNT')).cast(DecimalType(12,2)))\n                 .withColumn(\"PRODUCT_NET_WEIGTHED_PRICE\",(col('PRODUCT_NET_WEIGTHED_PRICE')).cast(DecimalType(12,2)))        \n                ).alias('df_detail')\n    ADP_log_debug(process, logger_name, level_action, log_level, \"--After Transformations - Calculation of amounts\", sys._getframe().f_code.co_name)\n\n    ################################################################################################################################################\n    #  END - TRANSFORMATION DATA FIELDS\n    ################################################################################################################################################\n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n\t\n    return df_detail\n  \n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n\n#############################################################################################################################\n\ndef EnrichmentFarmaticSellout(df,debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__):\n  \"\"\"Enrich Sellout Columns structure and Add a Column for each field with the validation Result\n\n    Parameters:\n      df                   -- Dataframe with the result of the FieldFormatValidations Process\n      debug                -- True for enable debug verbosing or False to not enable\n      partitions           -- Partitions defined\n\n    Return:\n      Dataframe            -- Dataframe containing output columns from FieldFormatValidations and the new enrichment columns\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       18/12/2018     Create Function Stub\n  #Ana Perez           21/12/2018     Enrichment from Master Data\n  #Ana Perez           25/01/2019     Using the new canonical masterdata format\n  #Ana Perez           05/02/2019     Takes the first row by PRODUCT_INTERNAL_CODE and EAN13 (without duplicated rows) from m_product_cat\n  #Ana Perez           14/02/2019     Add new persist and print lines\n  #Ana Perez           19/02/2019     Fix error in categorization enrichment process\n  #Ana Perez           04/03/2019     Unpersist dataframes doesent used\n  #Ana Perez           10/04/2019     Included log managment and exception managment\n  try:    \n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    df_detail= df.alias('df_detail')\n\n    ################################################################################################################################################\n    #  ENRICHMENT DATA FIELDS\n    #                  this process uses alias so that the fields maintain compatibility with previous versions\n    ################################################################################################################################################\n\n     #Enrichment with PRODUCT MASTER DATA\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[EnrichmentFarmaticSellout: Begin Enrichment PRODUCT Categories]. \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)  \n    df_product_cat = (spark.table(__CATEGORIES_TABLE_NAME__)    \n                      .withColumn(\"NATIONAL_CODE\", col('PRODUCT_INTERNAL_CODE').substr(0,6))\n                      .filter((col('NATIONAL_CODE')> \"149999\"))\n                      .select(col('PRODUCT_INTERNAL_CODE')\n                          , col('NATIONAL_CODE')\n                          , col('BAR_CODE').alias('EAN13')\n                          , col('LEGAL_CATEGORY').alias('CLASS')\n                          , col('COMMERCIAL_CATEGORY_L1').alias('CATEGORY')\n                          , col('COMMERCIAL_CATEGORY_L2').alias('FAMILY')\n                          , col('COMMERCIAL_CATEGORY_L3').alias('SUBFAMILY')\n                          , col('BRAND').alias('BRAND')\n                          , col('MANUFACTURER_CODE').alias('LABORATORY_CODE')\n                          , col('MANUFACTURER_NAME').alias('LABORATORY_NAME')))\n\n     #takes the first row by PRODUCT_INTERNAL_CODE and EAN13 (without duplicated rows)\n    windowSpec = Window.partitionBy(df_product_cat['PRODUCT_INTERNAL_CODE']).orderBy(col('EAN13').desc())\n    \n    df_product_cat = (df_product_cat\n                      .withColumn(\"EAN13_filter\", when(col('EAN13').isNull()==True, lit('x')).otherwise(col('EAN13')))\n                      .withColumn(\"First_EAN13\", first(\"EAN13_filter\").over(windowSpec) )\n                      .filter(col('EAN13_filter')==col('First_EAN13'))\n                      .withColumn(\"CLASS\", when(((col('CLASS')=='PENDIENTE ASIGNAR') | (col('CLASS')=='SIN CLASE')),lit(None)).otherwise(col('CLASS')))\n                      .withColumn(\"CATEGORY\", when(((col('CATEGORY')=='PENDIENTE ASIGNAR') | (col('CATEGORY')=='SIN CATEGORÍA') | (col('CATEGORY')=='SIN CATEGORIA')),lit(None)).otherwise(col('CATEGORY')))\n                      .withColumn(\"FAMILY\", when(((col('FAMILY')=='PENDIENTE ASIGNAR') | (col('FAMILY')=='SIN FAMILIA')),lit(None)).otherwise(col('FAMILY')))\t\t\t\n                      .withColumn(\"SUBFAMILY\", when(((col('SUBFAMILY')=='PENDIENTE ASIGNAR') | (col('SUBFAMILY')=='SIN SUBFAMILIA')),lit(None)).otherwise(col('SUBFAMILY')))\n                      .withColumn(\"BRAND\", when(((col('BRAND')=='PENDIENTE ASIGNAR') | (col('BRAND')=='SIN TIPO')),lit(None)).otherwise(col('BRAND')))\n                      .withColumn(\"LABORATORY_NAME\", when(((col('LABORATORY_NAME')=='PENDIENTE ASIGNAR') | (col('LABORATORY_NAME')=='SIN TIPO')),lit(None)).otherwise(col('LABORATORY_NAME')))\n                      .drop(\"First_EAN13\")\n                      .distinct()\n                     ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_product_cat')\n    df_product_cat.count()\n\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Readed Product Cat Unique row by PRODUCT_INTERNAL_CODE and EAN]\", sys._getframe().f_code.co_name)  \n    \n    #Products with EAN and NATIONAL CODE  \n    df_product = (df_product_cat\n                    .filter((df_product_cat.EAN13.isNull() == False))\n                    .distinct()\n                 ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_product')\n    df_product.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Filtered if National and EAN Not null]\", sys._getframe().f_code.co_name)\n    \n    #Joing Products with EAN and NATIONAL CODE with Sell Out \n    df_detail = (df_detail.repartition(partitions)\n                   .join(df_product.repartition(partitions), ((col('df_detail.EANCode')==col('df_product.EAN13'))\n                                                     & (col('df_detail.ProductCode')==col('df_product.NATIONAL_CODE')) ), how='left')\n                   .select('df_detail.*'\n                          , 'df_product.NATIONAL_CODE'\n                          , 'df_product.EAN13'\n                          , 'df_product.CLASS'\n                          , 'df_product.CATEGORY'\n                          , 'df_product.FAMILY'\n                          , 'df_product.SUBFAMILY'\n                          , 'df_product.BRAND'\n                          , 'df_product.LABORATORY_NAME'\n                          , 'df_product.LABORATORY_CODE'\n                          )\n                ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_detail')\n    df_detail.count()\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Joined PMS and product_cat filtered by EAN not null] Rows: \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)  \n\t\n     #Select Product Cat, unique row and  Without EAN \n    df_product2 = (df_product_cat\n                  .select( col('NATIONAL_CODE')\n                          , col('CLASS')\n                          , col('CATEGORY')\n                          , col('FAMILY')\n                          , col('SUBFAMILY')\n                          , col('BRAND')\n                          , col('LABORATORY_NAME')\n                          , col('LABORATORY_CODE')\n                          )\n                  .distinct())\n    \n    df_product2 = df_product2.persist(StorageLevel.MEMORY_AND_DISK).alias('df_product2')\n    df_product2.count()\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Selected Product Cat, unique row and  Without EAN ] Rows: \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)  \n      \n    df_detail = (df_detail.repartition(partitions).join(df_product2.repartition(partitions), col('df_detail.ProductCode')==col('df_product2.NATIONAL_CODE'), how='left')\n                  .select('df_detail.*'\n                          , col('df_product2.NATIONAL_CODE').alias('dp_NATIONAL_CODE')\n                          , col('df_product2.CLASS').alias('dp_CLASS')\n                          , col('df_product2.CATEGORY').alias('dp_CATEGORY')\n                          , col('df_product2.FAMILY').alias('dp_FAMILY')\n                          , col('df_product2.SUBFAMILY').alias('dp_SUBFAMILY')\n                          , col('df_product2.BRAND').alias('dp_BRAND')\n                          , col('df_product2.LABORATORY_NAME').alias('dp_LABORATORY_NAME')\n                          , col('df_product2.LABORATORY_CODE').alias('dp_LABORATORY_CODE')\n                          )\n                  .withColumn(\"NATIONAL_CODE\",\n                              when((col('df_detail.NATIONAL_CODE').isNull()==True)  & (col('dp_NATIONAL_CODE').isNull()==False), col('dp_NATIONAL_CODE')).otherwise(col('df_detail.NATIONAL_CODE')))              \n                  .withColumn(\"CLASS\",\n                              when((col('df_detail.CLASS').isNull()==True) & (col('dp_CLASS').isNull()==False) , col('dp_CLASS')).otherwise(col('df_detail.CLASS')))         \n                  .withColumn(\"CATEGORY\",       \n                         when((col('df_detail.CATEGORY').isNull()==True) & (col('dp_CATEGORY').isNull()==False) , col('dp_CATEGORY')).otherwise(col('df_detail.CATEGORY')))               \n                  .withColumn(\"FAMILY\",    \n                       when((col('df_detail.FAMILY').isNull()==True) & (col('dp_FAMILY').isNull()==False) , col('dp_FAMILY')).otherwise(col('df_detail.FAMILY'))) \n                  .withColumn(\"SUBFAMILY\",    \n                       when((col('df_detail.SUBFAMILY').isNull()==True) & (col('dp_SUBFAMILY').isNull()==False) , col('dp_SUBFAMILY')).otherwise(col('df_detail.SUBFAMILY')))   \n                  .withColumn(\"BRAND\",    \n                       when((col('df_detail.BRAND').isNull()==True) & (col('dp_BRAND').isNull()==False) , col('dp_BRAND')).otherwise(col('df_detail.BRAND'))) \n                  .withColumn(\"LABORATORY_NAME\",    \n                       when((col('df_detail.LABORATORY_NAME').isNull()==True) & (col('dp_LABORATORY_NAME').isNull()==False) , col('dp_LABORATORY_NAME')).otherwise(col('df_detail.LABORATORY_NAME')))\n                  .withColumn(\"LABORATORY_CODE\",    \n                       when((col('df_detail.LABORATORY_CODE').isNull()==True) & (col('dp_LABORATORY_CODE').isNull()==False) , col('dp_LABORATORY_CODE')).otherwise(col('df_detail.LABORATORY_CODE')))\n                  .drop(col('dp_NATIONAL_CODE'))\n                  .drop(col('dp_EAN13'))\n                  .drop(col('dp_CLASS'))\n                  .drop(col('dp_CATEGORY'))\n                  .drop(col('dp_FAMILY'))\n                  .drop(col('dp_SUBFAMILY'))\n                  .drop(col('dp_BRAND'))\n                  .drop(col('dp_LABORATORY_NAME'))\n                  .drop(col('dp_LABORATORY_CODE'))\n              ).alias('df_detail')\n\n\n    #Assign Free products (NATIONAL_CODE -9), NATIONAL_CODE -1\n    df_detail= (df_detail\n                   .withColumn(\"NATIONAL_CODE\", \n                           when((col('ProductCode')< \"150000\") & (col('NATIONAL_CODE').isNull()==True),\"-9\").otherwise( col('NATIONAL_CODE')))              \n                   .withColumn(\"NATIONAL_CODE\",\n                           when((col('NATIONAL_CODE').isNull()==False), col('NATIONAL_CODE')).otherwise(\"-1\"))\n                 ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_detail')\n    df_detail.count()\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Joined Sell Out with product cat without relation by EAN] Rows:  \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)\n      \n    ########################### ENRICH PHARMACIES\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Begin Enrichment PHARMACIES]\", sys._getframe().f_code.co_name)\n        \n    df_pharmacy = (   spark.table(__PHARMACY_TABLE_NAME__)\n                      .select(col('PHARMACY_ADHERED_CODE').alias('PH_AH_PHARMACY_CODE')\n                           ,col('PHARMACY_CUSTOMER_CODE'))\n                      .filter(length(col('PHARMACY_ADHERED_CODE'))!=0)\n                      .distinct()\n                     ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_pharmacy')\n    df_pharmacy.count()\n\n    df_detail = (df_detail\n                 .join(broadcast(df_pharmacy), (col('df_detail.PharmacyID')==col('df_pharmacy.PH_AH_PHARMACY_CODE')), how='left')\n                 .select ('df_detail.*'\n                          , col('df_pharmacy.PHARMACY_CUSTOMER_CODE').alias('CUSTOMER_CODE'))\n                 .withColumn(\"CUSTOMER_CODE\",\n                           when((col('CUSTOMER_CODE').isNull()==False), col('CUSTOMER_CODE')).otherwise(\"-1\"))\n                 ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_detail')\n\n    df_detail.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Read Pharmacies and Join Sell-out] Rows:  \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)\n\t\n    ########################### ENRICH PRODUCT-MANUFACTURER and PRODUCT_NAME\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Begin Enrich MANUFACTURERS]\", sys._getframe().f_code.co_name)\n\t\n     #Pharmacies with MANUFACTURER_CODE\n    df_product_mdm = (spark.table(__PRODUCT_TABLE_NAME__)\n                      .select(col('PRODUCT_INTERNAL_CODE').alias('PRODUCT_CODE')\n                               ,col('MANUFACTURER_CODE')\n                               ,col('PRODUCT_NAME'))\n                      .withColumn(\"mdm_PRODUCT_CODE\",  col('PRODUCT_CODE').substr(0,6))   #it takes the manufacturer_code finished  at \"0\"\n                      .distinct()\n                      .filter((col('mdm_PRODUCT_CODE')> \"149999\"))\n                     ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_product_mdm')\n    df_product_mdm.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Read master data product and filter it the NOT free codes]\", sys._getframe().f_code.co_name)\n\t\n    df_detail = (df_detail\n                 .join(broadcast(df_product_mdm), (col('df_detail.ProductCode')==df_product_mdm.mdm_PRODUCT_CODE), how='left')\n                 .select ('df_detail.*'\n                          , col('df_product_mdm.mdm_PRODUCT_CODE')\n                          , col('df_product_mdm.MANUFACTURER_CODE')\n                          , col('df_product_mdm.PRODUCT_NAME')\n                          )\n                 . withColumn(\"MANUFACTURER_CODE\",                         \n                           when((col('MANUFACTURER_CODE').isNull()==False), concat((col('MANUFACTURER_CODE').substr(0,5)),lit(\"0\"))).otherwise(\"-1\")) \n                 . withColumn(\"NATIONAL_CODE\",                  #if national_code is not at mdm_categories file, and it is at mdm_item fields, it takes the mdm_item value      \n                           when(((col('mdm_PRODUCT_CODE').isNull()==False) & (col('NATIONAL_CODE')==\"-1\")), col('mdm_PRODUCT_CODE')).otherwise(col('NATIONAL_CODE')))\n                 ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_detail')\n    df_detail.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Joined Sell out with Master data product] Rows:  \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)\n\t\n    df_manufacturers_mdm = (spark.table(__MANUFACTURERS_TABLE_NAME__)\n                          .select(col('MANUFACTURER_CODE')\n                                 ,col('MANUFACTURER_NAME')\n                                 )\n                           ).persist(StorageLevel.MEMORY_AND_DISK).alias ('df_manufacturers_mdm')  \n    df_manufacturers_mdm.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Read master data manufacturers]\", sys._getframe().f_code.co_name)\n\t\n    df_detail = (df_detail\n                 .join(broadcast(df_manufacturers_mdm), (col('df_detail.MANUFACTURER_CODE')== df_manufacturers_mdm.MANUFACTURER_CODE), how='left')\n                 .select ('df_detail.*'\n                          , col('df_manufacturers_mdm.MANUFACTURER_NAME'))\n                 ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_detail') \n    df_detail.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[Joined Sell-Out with Manufacturs ] Rows:  \" + str(df_detail.count()) + \" rows\", sys._getframe().f_code.co_name)\n    \n    df_detail = (df_detail\n                 \n                   .withColumn(\"MANUFACTURER_NAME\",         #if the product mdm has not the manufacturer it take this data from categorization file\n                             when((col('MANUFACTURER_NAME').isNull()==True), col('LABORATORY_NAME')).otherwise(col('MANUFACTURER_NAME')))\n                   .withColumn(\"MANUFACTURER_CODE\",         #if the product mdm has not the manufacturer it take this data from categorization file \n                             when((col('MANUFACTURER_CODE')==\"-1\"), col('LABORATORY_CODE')).otherwise(col('MANUFACTURER_CODE')))\n                 ).alias('df_detail')   \n    \n    #################### DEFAULT VALUES ##########################################################################################################\n    #Assign Free products (NATIONAL_CODE -9), NATIONAL_CODE -1, and default categorization values\n    df_detail = (df_detail\n\n                   .withColumn(\"PRODUCT_NAME\",   \n                           when(((col('PRODUCT_NAME').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")), lit('UNKNOWN PRODUCT')).otherwise(col('PRODUCT_NAME')))\n                   .withColumn(\"PRODUCT_NAME\",   \n                           when(((col('PRODUCT_NAME').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")), lit('NA-FREE CODE')).otherwise(col('PRODUCT_NAME')))\n                   .withColumn(\"PRODUCT_NAME\",   \n                           when(((col('PRODUCT_NAME').isNull()==True) & (col('NATIONAL_CODE')!=\"-9\") & (col('NATIONAL_CODE')!=\"-1\")), lit('UNKNOWN')).otherwise(col('PRODUCT_NAME')))\n\n                   .withColumn(\"CLASS\", when(((col('CLASS').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PRODUCT')).otherwise(col('CLASS')))\n                   .withColumn(\"CLASS\", when(((col('CLASS').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('CLASS')))\n                   .withColumn(\"CLASS\", when(((col('CLASS').isNull()==True) & (col('NATIONAL_CODE')>\"0\")),lit('UNKNOWN')).otherwise(col('CLASS')))\n\n                   .withColumn(\"CATEGORY\", when(((col('CATEGORY').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PRODUCT')).otherwise(col('CATEGORY')))\n                   .withColumn(\"CATEGORY\", when(((col('CATEGORY').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('CATEGORY')))\n                   .withColumn(\"CATEGORY\", when(((col('CATEGORY').isNull()==True) & (col('NATIONAL_CODE')>\"0\")),lit('UNKNOWN')).otherwise(col('CATEGORY')))\n\n                   .withColumn(\"FAMILY\", when(((col('FAMILY').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PRODUCT')).otherwise(col('FAMILY')))\n                   .withColumn(\"FAMILY\", when(((col('FAMILY').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('FAMILY')))\n\n                   .withColumn(\"SUBFAMILY\", when(((col('SUBFAMILY').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PRODUCT')).otherwise(col('SUBFAMILY')))\n                   .withColumn(\"SUBFAMILY\", when(((col('SUBFAMILY').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('SUBFAMILY')))\n\n                   .withColumn(\"BRAND\", when(((col('BRAND').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PRODUCT')).otherwise(col('BRAND')))\n                   .withColumn(\"BRAND\", when(((col('BRAND').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('BRAND')))\n                   .withColumn(\"BRAND\", when(((col('BRAND').isNull()==True) & (col('NATIONAL_CODE')>\"0\")),lit('UNKNOWN')).otherwise(col('BRAND')))\n                   .withColumn(\"BRAND\", (col('BRAND').substr(0,50)))\n\n                   .withColumn(\"MANUFACTURER_NAME\",\n                           when(((col('MANUFACTURER_NAME').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PRODUCT')).otherwise(col('MANUFACTURER_NAME')))\n                   .withColumn(\"MANUFACTURER_NAME\",\n                           when(((col('MANUFACTURER_NAME').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('MANUFACTURER_NAME')))\n                   .withColumn(\"MANUFACTURER_NAME\", when(((col('MANUFACTURER_NAME').isNull()==True) & (col('NATIONAL_CODE')>\"0\")),lit('UNKNOWN')).otherwise(col('MANUFACTURER_NAME')))\n\n                   .withColumn(\"MANUFACTURER_CODE\", when(((col('MANUFACTURER_CODE').isNull()==True) & (col('NATIONAL_CODE')==\"-1\")),lit('UNKNOWN PROD')).otherwise(col('MANUFACTURER_CODE')))\n                   .withColumn(\"MANUFACTURER_CODE\", when(((col('MANUFACTURER_CODE').isNull()==True) & (col('NATIONAL_CODE')==\"-9\")),lit('NA-FREE CODE')).otherwise(col('MANUFACTURER_CODE')))\n                   .withColumn(\"MANUFACTURER_CODE\", when(((col('MANUFACTURER_CODE').isNull()==True) & (col('NATIONAL_CODE')>\"0\")),lit('-1')).otherwise(col('MANUFACTURER_CODE')))\n                ).alias('df_detail') \n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"[ Assigned -9, -1 default values]  \", sys._getframe().f_code.co_name)\n\t\n    # Unpersist Dataframes\n    df_product2.unpersist()\n    df_product.unpersist()\n    df_product_cat.unpersist()\n    df_pharmacy.unpersist()\n    df_manufacturers_mdm.unpersist()\n    df_product_mdm.unpersist()\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)  \n    return df_detail\n  \n  except Exception as err:\n      ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n      raise Exception(err)\n\n\n\n\n#############################################################################################################################\n\ndef EnrichmentValidationsFarmaticSellout(df,debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__):\n  \"\"\"Validate Sellout Enriched Columns Values and Add a Column for each field with the validation Result\n\n    Parameters:\n      df                   -- Dataframe with the result of the Enrichment Process\n      debug                -- True for enable debug verbosing or False to not enable\n      partitions           -- Partitions defined\n\n    Return:\n      Dataframe            -- Dataframe containing output columns from Enrichment and the new enrichment validation columns\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       18/12/2018     Create Function Stub\n  #Ana Perez           24/12/2018     Validations Enrichment Process\n  #Ana Perez           24/04/2019     Included new QA files (NUM_ERROR_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n  \n  try:\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    df_detail= df.alias('df_detail')\n    \n    ################################################################################################################################################\n    #  BEGIN QA ENRICHMENT DATA FIELDS\n    ################################################################################################################################################\n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"--Calculate EnrichResult fields\", sys._getframe().f_code.co_name)\n    \n    #Assign EnrichNationalCodeResult, EnrichCategoryResult, EnrichManufacturerResult AND EnrichErrorRow\n    df_detail = (df_detail\n                    #Validate NATIONAL_CODE\n                   .withColumn(\"EnrichNationalCodeResult\",\n                           when((col('NATIONAL_CODE')==lit(\"-9\")) | (col('NATIONAL_CODE')!=lit(\"-1\")), lit(\"OK\")))\n                   .withColumn(\"EnrichNationalCodeResult\",\n                           when(\n                             (col('NATIONAL_CODE')==lit(\"-1\")) & \n                             (col('ProductCode')> \"599999\"),lit(\"NF1\")).otherwise(col('EnrichNationalCodeResult')))\n                   .withColumn(\"EnrichNationalCodeResult\",\n                           when(\n                             (col('NATIONAL_CODE')==lit(\"-1\")) & \n                             (col('ProductCode')> \"149999\") &\n                             (col('ProductCode')< \"600000\")\n                             ,lit(\"NF2\")).otherwise(col('EnrichNationalCodeResult')))\n                    # Validate NATIONAL_CODE\n                   .withColumn(\"NATIONAL_CODE_ERR\",  when(((col('EnrichNationalCodeResult')==\"OK\") | (col('NATIONAL_CODE')==lit(\"-9\"))), lit(None)) \\\n                                .otherwise(concat(lit('{\"ENR_UNK:\"'), col('EnrichNationalCodeResult') ,lit('\"}') )))\n                   .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when(((col('EnrichNationalCodeResult')==\"OK\") | (col('NATIONAL_CODE')==lit(\"-9\"))),col(\"NUM_ERROR_FIELDS_ACCURACY\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())))\n\n                    #Validate PRODUCT_NAME\n                   .withColumn(\"PRODUCT_NAME_ERR\",  when(((col('PRODUCT_NAME').isNull()==False) | (col('NATIONAL_CODE')<lit(\"0\"))), lit(None)).otherwise('{\"' + 'ENR_EMPTY' + '\":' + '\"1\"}') )\n                   .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when(((col('PRODUCT_NAME').isNull()==False) | (col('NATIONAL_CODE')<lit(\"0\"))),col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())))\n                    # Validate CLASS\n                   .withColumn(\"CLASS_ERR\",  when(((col('CLASS')!=lit('UNKNOWN')) | (col('NATIONAL_CODE')<lit(\"0\"))), lit(None)).otherwise('{\"' + 'ENR_EMPTY' + '\":' + '\"1\"}') ) \n                   .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when(((col('CLASS')!=lit('UNKNOWN')) | (col('NATIONAL_CODE')<lit(\"0\"))),col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())))\n\n                    #Validate CATEGORY\n                   .withColumn(\"EnrichCategoryResult\",\n                             when((col('CATEGORY')!=lit('UNKNOWN')), lit(\"OK\")))\n                   .withColumn(\"EnrichCategoryResult\",\n                             when(\n                               ((col('CATEGORY')==lit('UNKNOWN'))) & \n                               (col('ProductCode')> \"599999\")\n                               ,lit(\"NF1\")).otherwise(col('EnrichCategoryResult')))\n                    .withColumn(\"EnrichCategoryResult\",\n                             when(\n                               ((col('CATEGORY')==lit('UNKNOWN'))) & \n                               (col('ProductCode')> \"149999\") &\n                               (col('ProductCode')< \"600000\")\n                               ,lit(\"NF2\")).otherwise(col('EnrichCategoryResult')))\n                    .withColumn(\"EnrichCategoryResult\",\n                             when((col('ProductCode')< \"150000\")\n                               ,lit(\"NF3\")).otherwise(col('EnrichCategoryResult')))\n                     # Validate CATEGORY\n                    .withColumn(\"CATEGORY_ERR\",  when(((col('EnrichCategoryResult')==\"OK\") | (col('NATIONAL_CODE')==lit(\"-9\"))), lit(None)).otherwise(concat(lit('{\"ENR_EMPTY:\"'), col('EnrichCategoryResult') ,lit('\"}') )))\n                    .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when(((col('EnrichCategoryResult')==\"OK\") | (col('NATIONAL_CODE')==lit(\"-9\"))),col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())))\n                     # Validate MANUFACTURER\n                    .withColumn(\"MANUFACTURER_NAME_ERR\",  when(((col('MANUFACTURER_NAME'))!=lit('UNKNOWN')) | (col('NATIONAL_CODE')<lit(\"0\")), lit(None)).otherwise('{\"' + 'ENR_EMPTY' + '\":' + '\"1\"}') )\n                    .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when(((col('MANUFACTURER_NAME'))!=lit('UNKNOWN')) | (col('NATIONAL_CODE')<lit(\"0\")),col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())))\n                 \n                    .withColumn(\"MANUFACTURER_CODE_ERR\",  when(((col('MANUFACTURER_CODE')!=\"-1\") | (col('NATIONAL_CODE')<lit(\"0\"))), lit(None)).otherwise('{\"' + 'ENR_EMPTY' + '\":' + '\"1\"}') )\n                    .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when(((col('MANUFACTURER_CODE')!=\"-1\") | (col('NATIONAL_CODE')<lit(\"0\"))),col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())))\n                 \n                     # Validate BRAND\n                    .withColumn(\"BRAND_ERR\",  when(((col('BRAND')!=lit('UNKNOWN')) | (col('NATIONAL_CODE')<lit(\"0\"))), lit(None)).otherwise('{\"' + 'ENR_EMPTY' + '\":' + '\"1\"}') )  \n                    .withColumn(\"NUM_ERROR_FIELDS_COMPLETENESS\", when(((col('BRAND')!=lit('UNKNOWN')) | (col('NATIONAL_CODE')<lit(\"0\"))),col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")+lit(1).cast(IntegerType())))\n                 \n                     # Validate CUSTOMER_CODE(PHARMACY_CODE from pharmacies)\n                    .withColumn(\"CUSTOMER_CODE_ERR\",  when((col('CUSTOMER_CODE')!=\"-1\"), lit(None)).otherwise('{\"' + 'ENR_UNK' + '\":' + '\"1\"}') )\n                    .withColumn(\"NUM_ERROR_FIELDS_ACCURACY\", when((col('CUSTOMER_CODE')!=\"-1\"),col(\"NUM_ERROR_FIELDS_ACCURACY\")).\\\n                                                                 otherwise(col(\"NUM_ERROR_FIELDS_ACCURACY\")+lit(1).cast(IntegerType())))\n                     # Validate NUMBER_VALIDATED_FIELDS\n                     .withColumn(\"ROW_OK\"\n                               , when((col('NUM_ERROR_FIELDS_COMPLETENESS') +\n                                 col('NUM_ERROR_FIELDS_ACCURACY') +\n                                 col('NUM_ERROR_FIELDS_DUPLICATE') +\n                                 col('NUM_ERROR_FIELDS_CONFORMITY')\n                                     )>0, lit(1)\n                                     ).otherwise(lit(0))\n                               )\n                 ).alias('df_detail') \n    \n    #end if enrichErrorRow\n    ################################################################################################################################################\n    #  END - QA ENRICHMENT DATA FIELDS\n    ################################################################################################################################################\n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n    return df_detail\n  \n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n\n#############################################################################################################################\n\ndef GenerateTemporaryFarmaticSellout(df,debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__):\n  \"\"\"From the EnrichmentValidations Process output, generate a Dataframe with Sellout Canonical final structure to save to a temporary File just in case\n      the process fails and we need to recovery the information\n      \n  Parameters:\n    df                   -- Dataframe with the result of the EnrichmentValidation Process\n    debug                -- True for enable debug verbosing or False to not enable\n    partitions           -- Partitions defined\n\n  Return:\n    Dataframe            -- Sell-Out canonized data and QA fields as _RAW and _ERR fields \n  \"\"\"\n  #Who                 When           What\n  #Ana Perez           22/02/2018     Create Function Stub\n  #Ana Perez           15/04/2019     Included debug log managment and exception\n  #Victor Salesa       29/04/2019     Included new QA fields (NUM_VALIDATED_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n  #Victor Salesa       29/04/2019     Included new QA fields (NUM_ERROR_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n  #Victor Salesa       29/04/2019     Renamed JOB_ID field with NUM_ROWS_TOTAL\n  try:\n\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    df_detail= df.alias('df_detail')\n    \n\t\n    ################################################################################################################################################\n    #  RENAME FIELDS FOR CANONICAL DATA FILE\n    ################################################################################################################################################\n    num_files_tot = df_detail.count()\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Files Selected: \" + str(num_files_tot), sys._getframe().f_code.co_name)\n\t\n    df_CMD = (df_detail\n                  .select(\n                        lit(num_files_tot).alias('NUM_ROWS_TOTAL')\n                        ,col('FILE_SPEC_VERSION')\n                        ,col('FILE_RELEASE_VERSION')\n                        ,col('FILE_ORIGIN')\n                        ,col('PMS_CODE')\n                        ,col('FILE_TYPE')               \n                        ,col('FILE_NAME')\n                        ,col('RAW_NAME')\n                        ,col('FileDate').alias(\"FILE_DATE\")\n                        ,col('LANDING_DATE')\n                        ,col('PROCESS_DATE')         \n                        ,col('FILE_LINE_NUM') \n                        ,col('PharmacyID').alias('PHARMACY_CODE') \n                        ,col('ExternalPharmacyID').alias('EXTERNAL_PHARMACY_CODE')\n                        ,col('CUSTOMER_CODE')\n                        ,col('ZIPCode').alias('POSTAL_CODE')\n                        ,col('COUNTRY').alias('COUNTRY_CODE')               \n                        ,col('OperationIdent').alias('OPERATION_TYPE')\n                        ,col('OperationID').alias('OPERATION_CODE')\n                        ,col('OperationLine').alias('OPERATION_LINE')\n                        ,col('OperationDate').alias('OPERATION_DATE')\n                        ,col('POSIdent').alias('SALES_POINT_CODE')\n                        ,col('SalesChannel').alias('SALES_CHANNEL')\n                        ,col('ProductCode').alias('PRODUCT_LINE_CODE')\n                        ,col('ProductName').alias('PRODUCT_LINE_NAME') \n                        ,col('EANCode').alias('PRODUCT_LINE_BAR_CODE') \n                        ,col('NATIONAL_CODE').alias('PRODUCT_NATIONAL_CODE')                \n                        ,col('PRODUCT_NAME')        \n                        ,lit('').alias('PRODUCT_INTERNAL_CODE') # It will be an Global MDM product code in the future\n                        ,col('BRAND')\n                        ,col('MANUFACTURER_CODE') \n                        ,col('MANUFACTURER_NAME')\n                        ,col('CLASS').alias('LEGAL_CATEGORY')\n                        ,col('CATEGORY').alias('COMMERCIAL_CATEGORY_L1')\n                        ,col('FAMILY').alias('COMMERCIAL_CATEGORY_L2')\n                        ,col('SUBFAMILY').alias('COMMERCIAL_CATEGORY_L3')\n                        ,col('ProductPacks').alias('PRODUCT_QTY')\n                        ,lit(0).cast(DecimalType(10,0)).alias('PRODUCT_FREE_QTY') # Is not used by Farmatic\n                        ,col('ProductPackSize').alias('PACK_SIZE')   \n                        ,col('ProductPriceCatalog').alias('PRODUCT_PRICE_CATALOG') \n                        ,col('ProductPrice').alias('PRODUCT_PRICE') \n                        ,col('DiscountType').alias('DISCOUNT_TYPE') \n                        ,col('DiscountValue').alias('DISCOUNT_VALUE') \n                        ,col('DISCOUNT_WEIGTHED_AMOUNT').alias('DISCOUNT_WEIGTHED_AMOUNT') \n                        ,col('ProductFee').alias('PRODUCT_FEE_VALUE') \n                        ,col('ProductMarkup').alias('PRODUCT_MARKUP_VALUE')  \n                        ,col('PRODUCT_NET_PRICE').alias('PRODUCT_NET_PRICE') \n                        ,col('PRODUCT_NET_WEIGTHED_PRICE').alias('PRODUCT_NET_WEIGTHED_PRICE') \n                        ,col('ProductTotalPrice').alias('PRODUCT_TOTAL_AMOUNT')  \n                        ,col('CoPaymentValue').alias('CONSUMER_PAYMENT_AMOUNT') \n                        ,col('ReimbursementValue').alias('REIMBURSEMENT_AMOUNT') \n                        ,col('ConsumerValue').alias('CONSUMER_AMOUNT') \n                        ,col('DiscountValOvertTotReceipt').alias('TOT_RECEIPT_DISCOUNT_AMOUNT') \n                        ,col('DecreasedValTotReceipt').alias('TOT_RECEIPT_DECREASE_AMOUNT') \n                        ,col('TotalOfReceipt').alias('TOT_RECEIPT_AMOUNT') \n                        ,col('PaymentMode').alias('PAYMENT_MODE') \n                        ,col('ConsumerType').alias('CONSUMER_TYPE') \n                        ,col('ConsumerAnonymousID').alias('CONSUMER_ANONYMOUS_CODE') \n                        ,col('ConsumerGender').alias('CONSUMER_GENDER') \n                        ,col('ConsumerAge').alias('CONSUMER_BIRTH_YEAR') \n                        ,col('ConsumerLocation').alias('CONSUMER_LOCATION_CODE') \n                        ,col('ConsumerZipCode').alias('CONSUMER_POSTAL_CODE')                  \n                        ,col('PrescriptionIdent').alias('PRESCRIPTION_FLG') \n                        ,col('PrescriptionMode').alias('PRESCRIPTION_MODE') \n                        ,col('PrescriptionType').alias('PRESCRIPTION_TYPE') \n                        ,col('PrescriptionID').alias('PRESCRIPTION_CODE') \n                        ,col('PrescriptionOrigin').alias('PRESCRIPTION_ORIGIN') \n                        ,col('PrescriptionSpecialtyDoc').alias('PRESCRIPTION_SPECIALITY') \n                        ,col('PrescribedProductCode').alias('PRESCRIPTION_PRODUCT_CODE') \n                        ,col('PrescribedProductName').alias('PRESCRIPTION_PRODUCT_NAME') \n                        ,col('Reimbursement').alias('REIMBURSEMENT_FLG') \n                        ,col('ReimbursementEntityCode').alias('REIMBURSEMENT_ENTITY_CODE') \n                        ,col('ReimbursementEntityName').alias('REIMBURSEMENT_ENTITY_NAME') \n                        ,col('ReimbursementType').alias('REIMBURSEMENT_TYPE') \n                        ,col('ReimbursementCategory').alias('REIMBURSEMENT_CATEGORY') \n                        ,col('Promotion').alias('PROMOTION_FLG') \n                        ,col('PromotionType').alias('PROMOTION_TYPE') \n                        ,col('PromotionID').alias('PROMOTION_CODE') \n                        ,col('PromotionDescription').alias('PROMOTION_DESC') \n                        ,col('IssuedVouchersIdent').alias('ISSUED_VOUCHERS_FLG') \n                        ,col('NumberIssuedVouchers').alias('ISSUED_VOUCHERS_NUM') \n                        ,col('ValueIssuedVouchers').alias('ISSUED_VOUCHERS_AMOUNT') \n                        ,col('UsedVouchersIdent').alias('USED_VOUCHERS_FLG') \n                        ,col('NumberUsedVouchers').alias('USED_VOUCHERS_NUM') \n                        ,col('ValueUsedVouchers').alias('USED_VOUCHERS_AMOUNT') \n                        ,col('LoyaltyProgramUsed').alias('LOYALTY_PROGRAM_FLG') \n                        ,col('LoyaltyProgramName').alias('LOYALTY_PROGRAM_NAME') \n                        ,col('LoyaltyRebate').alias('LOYALTY_REBATE_FLG') \n                        ,lit(\"SL\").alias(\"BUSINESS_AREA\")\n                        ,col('FILE_LINES').cast(IntegerType()).alias('FILE_LINES')\n                        ,col('OperationLine_Err2').alias('OPERATION_LINE_ERR') \n                        ,col('OperationDate_Err2').alias('OPERATION_DATE_ERR') \n                        ,col('TotalOfReceipt_Err2').alias('TOT_RECEIPT_AMOUNT_ERR') \n                        ,col('DiscountValOvertTotReceipt_Err2').alias('TOT_RECEIPT_DISCOUNT_AMOUNT_ERR') \n                        ,col('DecreasedValTotReceipt_Err2').alias('TOT_RECEIPT_DECREASE_AMOUNT_ERR') \n                        ,col('ProductCode_Err2').alias('PRODUCT_LINE_CODE_ERR') \n                        ,col('ProductPacks_Err2').alias('PRODUCT_QTY_ERR') \n                        ,col('ProductPackSize_Err2').alias('PACK_SIZE_ERR') \n                        ,col('ProductPriceCatalog_Err2').alias('PRODUCT_PRICE_CATALOG_ERR') \n                        ,col('ProductPrice_Err2').alias('PRODUCT_PRICE_ERR') \n                        ,col('DiscountValue_Err2').alias('DISCOUNT_VALUE_ERR') \n                        ,col('ProductTotalPrice_Err2').alias('PRODUCT_TOTAL_AMOUNT_ERR') \n                        ,col('ReimbursementValue_Err2').alias('REIMBURSEMENT_AMOUNT_ERR') \n                        ,col('ConsumerValue_Err2').alias('CONSUMER_AMOUNT_ERR') \n                        ,col('PaymentMode_Err2').alias('PAYMENT_MODE_ERR') \n                        ,col('ConsumerGender_Err2').alias('CONSUMER_GENDER_ERR') \n                        ,col('OperationIdent_Err2').alias('OPERATION_TYPE_ERR') \n                        ,col('PrescriptionIdent_Err2').alias('PRESCRIPTION_FLG_ERR')  \n                        ,col('PrescriptionMode_Err2').alias('PRESCRIPTION_MODE_ERR')  \n                        ,col('PrescriptionType_Err2').alias('PRESCRIPTION_TYPE_ERR') \n                        ,col('Reimbursement_Err2').alias('REIMBURSEMENT_FLG_ERR') \n                        ,col('NATIONAL_CODE_ERR').alias('NATIONAL_CODE_ERR')\n                        ,col('PRODUCT_NAME_ERR').alias('PRODUCT_NAME_ERR') \n                        ,col('CLASS_ERR').alias('LEGAL_CATEGORY_ERR')\n                        ,col('CATEGORY_ERR').alias('COMMERCIAL_CATEGORY_L1_ERR')\n                        ,col('MANUFACTURER_CODE_ERR')\n                        ,col('ConsumerType_Err2').alias('CONSUMER_TYPE_ERR')\n                        ,col('MANUFACTURER_NAME_ERR').alias('MANUFACTURER_NAME_ERR') \n                        ,col('BRAND_ERR').alias('BRAND_ERR') \n                        ,col('CUSTOMER_CODE_ERR').alias('CUSTOMER_CODE_ERR') \n                        ,col('OPERATION_LINE_RAW')\n                        ,col('OPERATION_DATE_RAW')\n                        ,col('CUSTOMER_CODE_RAW')\n                        ,col('NATIONAL_CODE_RAW')\n                        ,col('PRODUCT_LINE_CODE_RAW')\n                        ,col('PRODUCT_NAME_RAW')\n                        ,col('CLASS_RAW').alias('LEGAL_CATEGORY_RAW')\n                        ,col('CATEGORY_RAW').alias('COMMERCIAL_CATEGORY_L1_RAW')\n                        ,col('MANUFACTURER_CODE_RAW')\n                        ,col('CONSUMER_TYPE_RAW')\n                        ,col('MANUFACTURER_NAME_RAW')\n                        ,col('BRAND_RAW')\n                        ,col('TOT_RECEIPT_AMOUNT_RAW')\n                        ,col('TOT_RECEIPT_DISCOUNT_AMOUNT_RAW')\n                        ,col('TOT_RECEIPT_DECREASE_AMOUNT_RAW')\n                        ,col('PRODUCT_QTY_RAW')\n                        ,col('PACK_SIZE_RAW')\n                        ,col('PRODUCT_PRICE_CATALOG_RAW')\n                        ,col('PRODUCT_PRICE_RAW')\n                        ,col('DISCOUNT_VALUE_RAW')\n                        ,col('PRODUCT_TOTAL_AMOUNT_RAW')\n                        ,col('REIMBURSEMENT_AMOUNT_RAW')\n                        ,col('CONSUMER_AMOUNT_RAW')\n                        ,col('PAYMENT_MODE_RAW')\n                        ,col('CONSUMER_GENDER_RAW')\n                        ,col('OPERATION_TYPE_RAW')\n                        ,col('PRESCRIPTION_MODE_RAW')\n                        ,col('PRESCRIPTION_TYPE_RAW')\n                        ,col('PRESCRIPTION_FLG_RAW')\n                        ,col('REIMBURSEMENT_FLG_RAW')\n                        ,col('ROW_OK')\n                        ,col(\"NUM_VALIDATED_FIELDS_COMPLETENESS\")\n                        ,col(\"NUM_VALIDATED_FIELDS_ACCURACY\")\n                        ,col(\"NUM_VALIDATED_FIELDS_DUPLICATE\")\n                        ,col(\"NUM_VALIDATED_FIELDS_CONFORMITY\")\n                        ,col(\"NUM_ERROR_FIELDS_COMPLETENESS\")\n                        ,col(\"NUM_ERROR_FIELDS_ACCURACY\")\n                        ,col(\"NUM_ERROR_FIELDS_DUPLICATE\")\n                        ,col(\"NUM_ERROR_FIELDS_CONFORMITY\")\n                        )\n             ).alias('df_CMD')\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After select fields for CMD\", sys._getframe().f_code.co_name)\n    df_CMD = (df_CMD\n                .withColumn('FILE_SPEC_VERSION', (col('FILE_SPEC_VERSION').substr(0,__CMD_FILE_SPEC_VERSION__)))\n                .withColumn('FILE_RELEASE_VERSION', (col('FILE_RELEASE_VERSION').substr(0,__CMD_FILE_RELEASE_VERSION__)))\n                .withColumn('FILE_ORIGIN', (col('FILE_ORIGIN').substr(0,__CMD_FILE_ORIGIN__)))\n                .withColumn('PMS_CODE', (col('PMS_CODE').substr(0,__CMD_PMS_CODE__)))\n                .withColumn('FILE_TYPE', (col('FILE_TYPE').substr(0,__CMD_FILE_TYPE__)))\n                .withColumn('FILE_NAME', (col('FILE_NAME').substr(0,__CMD_FILE_NAME__)))\n                .withColumn('PHARMACY_CODE', (col('PHARMACY_CODE').substr(0,__CMD_PHARMACY_CODE__)))\n                .withColumn('EXTERNAL_PHARMACY_CODE', (col('EXTERNAL_PHARMACY_CODE').substr(0,__CMD_EXTERNAL_PHARMACY_CODE__)))\n                .withColumn('CUSTOMER_CODE', (col('CUSTOMER_CODE').substr(0,__CMD_CUSTOMER_CODE__)))\n                .withColumn('POSTAL_CODE', (col('POSTAL_CODE').substr(0,__CMD_POSTAL_CODE__)))\n                .withColumn('COUNTRY_CODE', (col('COUNTRY_CODE').substr(0,__CMD_COUNTRY_CODE__)))\n                .withColumn('OPERATION_TYPE', (col('OPERATION_TYPE').substr(0,__CMD_OPERATION_TYPE__)))\n                .withColumn('OPERATION_CODE', (col('OPERATION_CODE').substr(0,__CMD_OPERATION_CODE__)))\n                .withColumn('SALES_POINT_CODE', (col('SALES_POINT_CODE').substr(0,__CMD_SALES_POINT_CODE__)))\n                .withColumn('SALES_CHANNEL', (col('SALES_CHANNEL').substr(0,__CMD_SALES_CHANNEL__)))\n                .withColumn('PRODUCT_LINE_CODE', (col('PRODUCT_LINE_CODE').substr(0,__CMD_PRODUCT_LINE_CODE__)))\n                .withColumn('PRODUCT_LINE_NAME', (col('PRODUCT_LINE_NAME').substr(0,__CMD_PRODUCT_LINE_NAME__)))\n                .withColumn('PRODUCT_LINE_BAR_CODE', (col('PRODUCT_LINE_BAR_CODE').substr(0,__CMD_PRODUCT_LINE_BAR_CODE__)))\n                .withColumn('PRODUCT_NATIONAL_CODE', (col('PRODUCT_NATIONAL_CODE').substr(0,__CMD_PRODUCT_NATIONAL_CODE__)))\n                .withColumn('PRODUCT_NAME', (col('PRODUCT_NAME').substr(0,__CMD_PRODUCT_NAME__)))\n                .withColumn('PRODUCT_INTERNAL_CODE', (col('PRODUCT_INTERNAL_CODE').substr(0,__CMD_PRODUCT_INTERNAL_CODE__)))\n                .withColumn('BRAND', (col('BRAND').substr(0,__CMD_BRAND__)))\n                .withColumn('MANUFACTURER_CODE', (col('MANUFACTURER_CODE').substr(0,__CMD_MANUFACTURER_CODE__)))\n                .withColumn('MANUFACTURER_NAME', (col('MANUFACTURER_NAME').substr(0,__CMD_MANUFACTURER_NAME__)))\n                .withColumn('LEGAL_CATEGORY', (col('LEGAL_CATEGORY').substr(0,__CMD_LEGAL_CATEGORY__)))\n                .withColumn('COMMERCIAL_CATEGORY_L1', (col('COMMERCIAL_CATEGORY_L1').substr(0,__CMD_COMMERCIAL_CATEGORY_L1__)))\n                .withColumn('COMMERCIAL_CATEGORY_L2', (col('COMMERCIAL_CATEGORY_L2').substr(0,__CMD_COMMERCIAL_CATEGORY_L2__)))\n                .withColumn('COMMERCIAL_CATEGORY_L3', (col('COMMERCIAL_CATEGORY_L3').substr(0,__CMD_COMMERCIAL_CATEGORY_L3__)))\n                .withColumn('DISCOUNT_TYPE', (col('DISCOUNT_TYPE').substr(0,__CMD_DISCOUNT_TYPE__)))\n                .withColumn('PAYMENT_MODE', (col('PAYMENT_MODE').substr(0,__CMD_PAYMENT_MODE__)))\n                .withColumn('CONSUMER_TYPE', (col('CONSUMER_TYPE').substr(0,__CMD_CONSUMER_TYPE__)))\n                .withColumn('CONSUMER_ANONYMOUS_CODE', (col('CONSUMER_ANONYMOUS_CODE').substr(0,__CMD_CONSUMER_ANONYMOUS_CODE__)))\n                .withColumn('CONSUMER_GENDER', (col('CONSUMER_GENDER').substr(0,__CMD_CONSUMER_GENDER__)))\n                .withColumn('CONSUMER_LOCATION_CODE', (col('CONSUMER_LOCATION_CODE').substr(0,__CMD_CONSUMER_LOCATION_CODE__)))\n                .withColumn('CONSUMER_POSTAL_CODE', (col('CONSUMER_POSTAL_CODE').substr(0,__CMD_CONSUMER_POSTAL_CODE__)))\n                .withColumn('PRESCRIPTION_FLG', (col('PRESCRIPTION_FLG').substr(0,__CMD_PRESCRIPTION_FLG__)))\n                .withColumn('PRESCRIPTION_MODE', (col('PRESCRIPTION_MODE').substr(0,__CMD_PRESCRIPTION_MODE__)))\n                .withColumn('PRESCRIPTION_TYPE', (col('PRESCRIPTION_TYPE').substr(0,__CMD_PRESCRIPTION_TYPE__)))\n                .withColumn('PRESCRIPTION_CODE', (col('PRESCRIPTION_CODE').substr(0,__CMD_PRESCRIPTION_CODE__)))\n                .withColumn('PRESCRIPTION_ORIGIN', (col('PRESCRIPTION_ORIGIN').substr(0,__CMD_PRESCRIPTION_ORIGIN__)))\n                .withColumn('PRESCRIPTION_SPECIALITY', (col('PRESCRIPTION_SPECIALITY').substr(0,__CMD_PRESCRIPTION_SPECIALITY__)))\n                .withColumn('PRESCRIPTION_PRODUCT_CODE', (col('PRESCRIPTION_PRODUCT_CODE').substr(0,__CMD_PRESCRIPTION_PRODUCT_CODE__)))\n                .withColumn('PRESCRIPTION_PRODUCT_NAME', (col('PRESCRIPTION_PRODUCT_NAME').substr(0,__CMD_PRESCRIPTION_PRODUCT_NAME__)))\n                .withColumn('REIMBURSEMENT_FLG', (col('REIMBURSEMENT_FLG').substr(0,__CMD_REIMBURSEMENT_FLG__)))\n                .withColumn('REIMBURSEMENT_ENTITY_CODE', (col('REIMBURSEMENT_ENTITY_CODE').substr(0,__CMD_REIMBURSEMENT_ENTITY_CODE__)))\n                .withColumn('REIMBURSEMENT_ENTITY_NAME', (col('REIMBURSEMENT_ENTITY_NAME').substr(0,__CMD_REIMBURSEMENT_ENTITY_NAME__)))\n                .withColumn('REIMBURSEMENT_TYPE', (col('REIMBURSEMENT_TYPE').substr(0,__CMD_REIMBURSEMENT_TYPE__)))\n                .withColumn('REIMBURSEMENT_CATEGORY', (col('REIMBURSEMENT_CATEGORY').substr(0,__CMD_REIMBURSEMENT_CATEGORY__)))\n                .withColumn('PROMOTION_FLG', (col('PROMOTION_FLG').substr(0,__CMD_PROMOTION_FLG__)))\n                .withColumn('PROMOTION_TYPE', (col('PROMOTION_TYPE').substr(0,__CMD_PROMOTION_TYPE__)))\n                .withColumn('PROMOTION_CODE', (col('PROMOTION_CODE').substr(0,__CMD_PROMOTION_CODE__)))\n                .withColumn('PROMOTION_DESC', (col('PROMOTION_DESC').substr(0,__CMD_PROMOTION_DESC__)))\n                .withColumn('ISSUED_VOUCHERS_FLG', (col('ISSUED_VOUCHERS_FLG').substr(0,__CMD_ISSUED_VOUCHERS_FLG__)))\n                .withColumn('USED_VOUCHERS_FLG', (col('USED_VOUCHERS_FLG').substr(0,__CMD_USED_VOUCHERS_FLG__)))\n                .withColumn('LOYALTY_PROGRAM_FLG', (col('LOYALTY_PROGRAM_FLG').substr(0,__CMD_LOYALTY_PROGRAM_FLG__)))\n                .withColumn('LOYALTY_PROGRAM_NAME', (col('LOYALTY_PROGRAM_NAME').substr(0,__CMD_LOYALTY_PROGRAM_NAME__)))\n                .withColumn('LOYALTY_REBATE_FLG', (col('LOYALTY_REBATE_FLG').substr(0,__CMD_LOYALTY_REBATE_FLG__)))\n                .withColumn('LOAD_DATE', to_timestamp(current_timestamp(), \"yyyyMMddHHmmss\")) \n             )\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After cut fields\", sys._getframe().f_code.co_name)\n    df_CMD = df_CMD.persist(StorageLevel.MEMORY_AND_DISK).alias('df_CMD')\n    df_CMD.count()\n    \n    # ###############################################################################################################################################\n    #  END - RENAME FIELDS FOR CANONICAL DATA FILE\n    # ###############################################################################################################################################\n\n    ################################################################################################################################################\n    #  SAVE TEMPORARY DATA FILE\n    ################################################################################################################################################\n\t#Save the datraframe as a file\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveAsCanonical TMP_STG_T_SELL_OUT: \" + str(df_CMD.count()) + \" rows \", sys._getframe().f_code.co_name)\n    saveAsCanonical(df_CMD,__PHARMATIC_CANONICAL_STG_SELLOUT_TMP_FILE_PATH__,table_name=__PHARMATIC_CANONICAL_STG_SELLOUT_TMP_H_TABLE_NAME__,mode='overwrite',debug=debug)\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After saveAsCanonical TMP_STG_T_SELL_OUT\", sys._getframe().f_code.co_name)\n\t\n      ##############################################################################################################################################\n    #  END - SAVE TEMPORARY DATA FILE \n    ##############################################################################################################################################\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n    return df_CMD\n  \n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n    \n##############################################################################################################################################\ndef RecoverTemporaryFarmaticSellout(debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__):\n  \"\"\"Recover output datafrom\n      \n  Parameters:\n    debug                -- True for enable debug verbosing or False to not enable\n    partitions           -- Partitions defined\n\n  Return:\n    Dataframe            -- Sell-Out canonized data and QA fields as _RAW and _ERR fields \n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       04/04/2019     Initial Version\n  #Ana Perez           15/04/2019     Included debug log managment and exception\n  \n  try:\n\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    \n    tmp_stg_t_sell_out_df = spark.table(__PHARMATIC_CANONICAL_STG_SELLOUT_TMP_H_TABLE_NAME__)\n    \n    if callSafe(tmp_stg_t_sell_out_df,\"count\",0) != 0:\n        return tmp_stg_t_sell_out_df\n    else:\n        ADP_log_exception(process, logger_name, level_action, log_level,  \"Table TMP_STG_T_SELL_OUT is empty or Not Found\", sys._getframe().f_code.co_name,  sys.exc_info())\n        raise Exception('Table TMP_STG_T_SELL_OUT is empty or Not Found')\n    #end if callSafe(tmp_stg_t_sell_out_df,\"count\",0) != 0\n\n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n  \n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"END Fail reading TMP_STG_T_SELL_OUT\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n\n\ndef GenerateQAFarmaticSellout(df,debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__,job_id=''):\n    \"\"\"From the EnrichmentValidations Process output generate Dataframes with QA final structure to save to DDBB and File\n\n      Parameters:\n        df                   -- Dataframe with the result of the EnrichmentValidation Process\n        debug                -- True for enable debug verbosing or False to not enable\n        partitions           -- Partitions defined\n        \n      Return:\n        Boolean              -- Process Succed or Not\n    \"\"\"\n    #Who                 When           What\n    #Victor Salesa       18/12/2018     Create Function Stub\n    #Victor Salesa       18/01/2019      \n    #Victor Salesa       18/01/2019  \n    #Victor Salesa       30/01/2019     Added MANUFACTURER_CODE_ERR,MANUFACTURER_CODE_RAW,CONSUMER_TYPE_ERR,CONSUMER_TYPE_RAW\n    #                                   Renamed CLASS TO LEGAL_CATEGORY _RAW & _ERR and CATEGORY to COMMERCIAL_CATEGORY_L1 _RAW & _ERR         \n    #                                   Added \"PMS_CODE\",\"COUNTRY_CODE\",\"PHARMACY_CODE\",\"BUSINESS_AREA\" to output\n    #Victor Salesa       30/01/2019     Change \"ProcessFileErrorDF = ProcessFileErrorDF.distinct()\" before write file\n    #Ana Pérez           26/02/2019     Adapted to new Temporary source Dataframe \n    #Victor Salesa       17/04/2019     Added job_id logic and Rollback Logic and moved all to STG tables\n    #Victor Salesa       29/04/2019     Included new QA fields (NUM_ERROR_FIELDS_COMPLETENESS, CONFORMITY, ACCURACY, DUPLICATE)\n    #Victor Salesa       29/04/2019     Renamed JOB_ID field with NUM_ROWS_TOTAL\n    #Victor Salesa       29/04/2019     Drop Cols ROW_KO_PMS,ROW_KO_MDM,NUMBER_OF_VALIDATED_FIELDS_PMS,NUMBER_OF_VALIDATED_FIELDS_MDM,\"OLD\" ROW_OK, ROW_KO\n    \n    ##### Prepare fields for processfileerror ###########################################################################################################################################################################\n    try:\n      ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n      exception_status=''\n      ProcessFileQADF= (df\n                         .select(\n                           col('FILE_NAME')\n                          ,col(\"PMS_CODE\")\n                          ,col(\"COUNTRY_CODE\")\n                          ,col(\"PHARMACY_CODE\")\n                          ,col(\"BUSINESS_AREA\")\n                          ,col(\"LANDING_DATE\")\n                          ,col(\"PROCESS_DATE\")\n                          ,col('FILE_LINE_NUM')\n                          ,col('FILE_LINES').cast(IntegerType()).alias('FILE_LINES')\n                          ,col('OPERATION_LINE_ERR') \n                          ,col('OPERATION_DATE_ERR') \n                          ,col('TOT_RECEIPT_AMOUNT_ERR') \n                          ,col('TOT_RECEIPT_DISCOUNT_AMOUNT_ERR') \n                          ,col('TOT_RECEIPT_DECREASE_AMOUNT_ERR') \n                          ,col('PRODUCT_LINE_CODE_ERR') \n                          ,col('PRODUCT_QTY_ERR') \n                          ,col('PACK_SIZE_ERR') \n                          ,col('PRODUCT_PRICE_CATALOG_ERR') \n                          ,col('PRODUCT_PRICE_ERR') \n                          ,col('DISCOUNT_VALUE_ERR') \n                          ,col('PRODUCT_TOTAL_AMOUNT_ERR') \n                          ,col('REIMBURSEMENT_AMOUNT_ERR') \n                          ,col('CONSUMER_AMOUNT_ERR') \n                          ,col('PAYMENT_MODE_ERR') \n                          ,col('CONSUMER_GENDER_ERR') \n                          ,col('OPERATION_TYPE_ERR') \n                          ,col('PRESCRIPTION_FLG_ERR')  \n                          ,col('PRESCRIPTION_MODE_ERR')  \n                          ,col('PRESCRIPTION_TYPE_ERR') \n                          ,col('REIMBURSEMENT_FLG_ERR') \n                          ,col('NATIONAL_CODE_ERR')\n                          ,col('PRODUCT_NAME_ERR') \n                          ,col('LEGAL_CATEGORY_ERR')\n                          ,col('COMMERCIAL_CATEGORY_L1_ERR')\n                          ,col('MANUFACTURER_CODE_ERR')\n                          ,col('CONSUMER_TYPE_ERR')\n                          ,col('MANUFACTURER_NAME_ERR') \n                          ,col('BRAND_ERR') \n                          ,col('CUSTOMER_CODE_ERR') \n                          ,col('OPERATION_LINE_RAW')\n                          ,col('OPERATION_DATE_RAW')\n                          ,col('CUSTOMER_CODE_RAW')\n                          ,col('NATIONAL_CODE_RAW')\n                          ,col('PRODUCT_LINE_CODE_RAW')\n                          ,col('PRODUCT_NAME_RAW')\n                          ,col('LEGAL_CATEGORY_RAW')\n                          ,col('COMMERCIAL_CATEGORY_L1_RAW')\n                          ,col('MANUFACTURER_CODE_RAW')\n                          ,col('CONSUMER_TYPE_RAW')\n                          ,col('MANUFACTURER_NAME_RAW')\n                          ,col('BRAND_RAW')\n                          ,col('TOT_RECEIPT_AMOUNT_RAW')\n                          ,col('TOT_RECEIPT_DISCOUNT_AMOUNT_RAW')\n                          ,col('TOT_RECEIPT_DECREASE_AMOUNT_RAW')\n                          ,col('PRODUCT_QTY_RAW')\n                          ,col('PACK_SIZE_RAW')\n                          ,col('PRODUCT_PRICE_CATALOG_RAW')\n                          ,col('PRODUCT_PRICE_RAW')\n                          ,col('DISCOUNT_VALUE_RAW')\n                          ,col('PRODUCT_TOTAL_AMOUNT_RAW')\n                          ,col('REIMBURSEMENT_AMOUNT_RAW')\n                          ,col('CONSUMER_AMOUNT_RAW')\n                          ,col('PAYMENT_MODE_RAW')\n                          ,col('CONSUMER_GENDER_RAW')\n                          ,col('OPERATION_TYPE_RAW')\n                          ,col('PRESCRIPTION_MODE_RAW')\n                          ,col('PRESCRIPTION_TYPE_RAW')\n                          ,col('PRESCRIPTION_FLG_RAW')\n                          ,col('REIMBURSEMENT_FLG_RAW')\n                          ,col('NUM_ROWS_TOTAL')\n                          ,col('ROW_OK')\n                          ,col(\"NUM_VALIDATED_FIELDS_COMPLETENESS\")\n                          ,col(\"NUM_VALIDATED_FIELDS_ACCURACY\")\n                          ,col(\"NUM_VALIDATED_FIELDS_DUPLICATE\")\n                          ,col(\"NUM_VALIDATED_FIELDS_CONFORMITY\")\n                          ,col(\"NUM_ERROR_FIELDS_COMPLETENESS\")\n                          ,col(\"NUM_ERROR_FIELDS_ACCURACY\")\n                          ,col(\"NUM_ERROR_FIELDS_DUPLICATE\")\n                          ,col(\"NUM_ERROR_FIELDS_CONFORMITY\")\n                   )                \n                  ).persist(StorageLevel.MEMORY_AND_DISK)\n      ProcessFileQADF.count()\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Prepare fields for process_file_error\", sys._getframe().f_code.co_name)\n\t  \n      ##### Drop fields with no errors inside ###########################################################################################################################################################################\n\n      def qa_drop_empty_columns(df):\n        \"\"\"\n        This function drops all columns which contain null values.\n        :param df: A PySpark DataFrame\n        \"\"\"\n        not_null_counts = df.select([count(when(col(c).isNotNull(), c)).alias(c) for c in df.columns if '_ERR' in c]).collect()[0].asDict()\n        to_drop_err = [k for k, v in not_null_counts.items() if v == 0 and '_ERR' in k]\n        to_drop_raw = [column.replace('_ERR', '_RAW') for column in to_drop_err]\n        to_drop = to_drop_err + to_drop_raw\n        df = df.drop(*to_drop)\n        return df\n\n      ProcessFileErrorDataDF = (qa_drop_empty_columns(ProcessFileQADF)\n                                 .drop(\"NUM_ROWS_TOTAL\"\n                                      ,\"ROW_OK\"\n                                      ,\"NUM_VALIDATED_FIELDS_COMPLETENESS\"\n                                      ,\"NUM_VALIDATED_FIELDS_ACCURACY\"\n                                      ,\"NUM_VALIDATED_FIELDS_DUPLICATE\"\n                                      ,\"NUM_VALIDATED_FIELDS_CONFORMITY\"\n                                      ,\"NUM_ERROR_FIELDS_COMPLETENESS\"\n                                      ,\"NUM_ERROR_FIELDS_ACCURACY\"\n                                      ,\"NUM_ERROR_FIELDS_DUPLICATE\"\n                                      ,\"NUM_ERROR_FIELDS_CONFORMITY\"\n                                      ,\"FILE_LINES\"\n                                 )\n                                 .persist(StorageLevel.MEMORY_AND_DISK)\n                             )\n\n      ProcessFileErrorDataDF.count()\n      \n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Drop Unwanted Err fields\", sys._getframe().f_code.co_name)\n\t  \n      ##### Generate process_file_error QA data ###########################################################################################################################################################################\n      ProcessFileErrorDF= QA_CTL_PROCESS_FILE_ERROR_DATA(ProcessFileErrorDataDF,debug=True).persist(StorageLevel.MEMORY_AND_DISK)\n      ProcessFileErrorDF.count()\n    \n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Generate process_file_error QA data\", sys._getframe().f_code.co_name)\n      \n\t  ##### Save to file process_file_error QA data #######################################################################################################################################################################\n      ProcessFileErrorDF = ProcessFileErrorDF.distinct() \n      \n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Before Save to file process_file_error QA data \" + str(ProcessFileErrorDF.count()) + \" rows\", sys._getframe().f_code.co_name)\n      saveAsCanonical(ProcessFileErrorDF,__QUALITY_PFE_H_FILE_PATH__,table_name=__QUALITY_PFE_H_TABLE_NAME__,mode='append',debug=debug,job_id=job_id)\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---After Save to file process_file_error QA data\", sys._getframe().f_code.co_name)\n\n      exception_status = \"GenerateQAFarmaticSellout.CTL_PROCESS_FILE_ERROR_CANONICAL\"\n      \n      ##### Save to DB process_file_error QA data #########################################################################################################################################################################\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Before Save to DB process_file_error QA data \" + str(ProcessFileErrorDF.count()) + \" rows\", sys._getframe().f_code.co_name)\n      saveToDB(ProcessFileErrorDF,table_name=__QUALITY_PFE_DB_TABLE_NAME__,mode=\"append\",debug=debug,job_id=job_id)  \n      ADP_log_debug(process, logger_name, level_action, log_level, \"---After Save to DB process_file_error QA data\", sys._getframe().f_code.co_name)\n\t \n      exception_status = \"GenerateQAFarmaticSellout.CTL_PROCESS_FILE_ERROR_DB\"\n      \n      #####Generate process_file_qa QA data##############################################################################################################################################################################\n      ProcessFileQADF = (ProcessFileQADF\n      \n        .groupBy(\"FILE_NAME\", \"LANDING_DATE\", \"PROCESS_DATE\", \"PMS_CODE\", \"COUNTRY_CODE\", \"PHARMACY_CODE\", \"BUSINESS_AREA\"\n          ,\"NUM_ROWS_TOTAL\"\n          ,\"NUM_VALIDATED_FIELDS_COMPLETENESS\"\n          ,\"NUM_VALIDATED_FIELDS_ACCURACY\"\n          ,\"NUM_VALIDATED_FIELDS_DUPLICATE\"\n          ,\"NUM_VALIDATED_FIELDS_CONFORMITY\"\n        )\n        .agg(\n          sum(col(\"ROW_OK\")).alias(\"NUM_ROWS_OK\"),\n          sum(col(\"NUM_ERROR_FIELDS_COMPLETENESS\")).alias(\"NUM_ERROR_FIELDS_COMPLETENESS\"),\n          sum(col(\"NUM_ERROR_FIELDS_ACCURACY\")).alias(\"NUM_ERROR_FIELDS_ACCURACY\"),\n          sum(col(\"NUM_ERROR_FIELDS_DUPLICATE\")).alias(\"NUM_ERROR_FIELDS_DUPLICATE\"),\n          sum(col(\"NUM_ERROR_FIELDS_CONFORMITY\")).alias(\"NUM_ERROR_FIELDS_CONFORMITY\")\n\n        )\n        .withColumn(\"STATUS\", lit(1))\n        .distinct()\n      ).persist(StorageLevel.MEMORY_AND_DISK)\n\n      ProcessFileQADF.count()\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Generate ProcessFileQADF\", sys._getframe().f_code.co_name)\n      \n      ##### Save to file process_file_qa QA data #######################################################################################################################################################################\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Before Save to file process_file_qa QA data: \" + str(ProcessFileQADF.count()) + \" rows\", sys._getframe().f_code.co_name)    \n      saveAsCanonical(ProcessFileQADF,__QUALITY_PFQ_H_FILE_PATH__,table_name=__QUALITY_PFQ_H_TABLE_NAME__,mode='append',debug=debug,job_id=job_id)\n      \n      exception_status = \"GenerateQAFarmaticSellout.CTL_PROCESS_FILE_QA_CANONICAL\"\n     \n      ADP_log_debug(process, logger_name, level_action, log_level, \"---After Save to file process_file_qa QA data\", sys._getframe().f_code.co_name)    \n        \n     ##### Save to DB process_file_qa QA data ########################################################################################################################################################################\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---Before Save to DB process_file_qa QA data: \" + str(ProcessFileQADF.count()) + \" rows\", sys._getframe().f_code.co_name)   \n      saveToDB(ProcessFileQADF,table_name=__QUALITY_PFQ_DB_TABLE_NAME__,mode=\"append\",debug=debug,job_id=job_id)\n      ADP_log_debug(process, logger_name, level_action, log_level, \"---After Save to DB process_file_qa QA data\", sys._getframe().f_code.co_name)    \n  \n      exception_status = \"GenerateQAFarmaticSellout.CTL_PROCESS_FILE_QA_DB\"\n\n      ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n      return True\n\t  \n    except Exception as err:\n      ADP_log_debug(process, logger_name, level_action, log_level, \"EXCEPTION_STATUS:\"+exception_status, sys._getframe().f_code.co_name)\n      if exception_status == 'GenerateQAFarmaticSellout.CTL_PROCESS_FILE_ERROR_DB':\n        RollbackCanonicalTable(__QUALITY_PFE_H_TABLE_NAME__,rollback_id=job_id)\n      elif exception_status == 'GenerateQAFarmaticSellout.CTL_PROCESS_FILE_QA_CANONICAL':\n        RollbackCanonicalTable(__QUALITY_PFE_H_TABLE_NAME__,rollback_id=job_id)\n        RollbackDBTable(__QUALITY_PFE_DB_TABLE_NAME__,rollback_id=job_id)\n      elif exception_status == 'GenerateQAFarmaticSellout.CTL_PROCESS_FILE_QA_DB':\n        RollbackCanonicalTable(__QUALITY_PFE_H_TABLE_NAME__,rollback_id=job_id)\n        RollbackDBTable(__QUALITY_PFE_DB_TABLE_NAME__,rollback_id=job_id)\n        RollbackCanonicalTable(__QUALITY_PFQ_H_TABLE_NAME__,rollback_id=job_id)\n      #end if exception_status == 'CTL_PROCESS_FILE_ERROR_DB':\n      \n      ADP_log_exception(process, logger_name, level_action, log_level, \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n      raise Exception(err)\n    \n\n#############################################################################################################################\n\ndef GenerateCanonicalFarmaticSellout(df,debug=__DEBUG_DEFAULT__,partitions=__PARTITIONS_DEFAULT__,job_id=''):\n  \"\"\"From the EnrichmentValidations Process output generate Dataframes with Sellout Canonical final structure to save to DDBB and File\n\n  Parameters:\n    df                   -- Dataframe with the result of the EnrichmentValidation Process\n    debug                -- True for enable debug verbosing or False to not enable\n    partitions           -- Partitions defined\n\n  Return:\n    Boolean              -- Process Succed or Not \n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       18/12/2018     Create Function Stub\n  #Ana Perez           10/01/2019     Save Canonical File and Database\n  #Victor Salesa       16/01/2019     Delete Processed Files \n  #Ana Perez           25/01/2019     Including new calculated fields \n  #Ana Perez           28/01/2019     Extract from string fields the length allowed in the table \n  #Victor Salesa       28/01/2019     Corrected delete function\n  #Ana Perez           11/02/2019     Replace delete_file function to blob_delete_file_sql\n  #Ana Perez           13/02/2019     Add LOAD_DATE to T_SELL_OUT file and STG_T_SELL_OUT table\n  #Ana Perez           25/02/2019     Including new GenerateTemporaryFarmaticSellout-output as source data\n  #Ana Perez           11/04/2019     Included log managment and exception managment\n  #Ana Perez           15/04/2019     Included Debug log managment\n  #Victor Salesa       22/04/2019     Added Job Id parameter and moved files and table names to variables and removed old JOB_id\n  try:\n    exception_status = \"GenerateCanonicalFarmaticSellout.START_PROCESS\"\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    \n    df_detail= df.alias('df_detail')\n    \n    ################################################################################################################################################\n    #  RENAME FIELDS FOR CANONICAL DATA FILE\n    ################################################################################################################################################\n    \n    df_CMD = (df_detail\n              .select(\n                      col('FILE_SPEC_VERSION')\n                     ,col('FILE_RELEASE_VERSION')\n                     ,col('FILE_ORIGIN')\n                     ,col('PMS_CODE')\n                     ,col('FILE_TYPE')               \n                     ,col('FILE_NAME')\n                     ,col('FILE_DATE')\n                     ,col('LANDING_DATE')\n                     ,col('PROCESS_DATE')         \n                     ,col('FILE_LINE_NUM') \n                     ,col('PHARMACY_CODE')\n                     ,col('EXTERNAL_PHARMACY_CODE')\n                     ,col('CUSTOMER_CODE')\n                     ,col('POSTAL_CODE')\n                     ,col('COUNTRY_CODE')             \n                     ,col('OPERATION_TYPE')\n                     ,col('OPERATION_CODE')\n                     ,col('OPERATION_LINE')\n                     ,col('OPERATION_DATE')\n                     ,col('SALES_POINT_CODE')\n                     ,col('SALES_CHANNEL')\n                     ,col('PRODUCT_LINE_CODE')\n                     ,col('PRODUCT_LINE_NAME') \n                     ,col('PRODUCT_LINE_BAR_CODE') \n                     ,col('PRODUCT_NATIONAL_CODE')                \n                     ,col('PRODUCT_NAME')        \n                     ,col('PRODUCT_INTERNAL_CODE') \n                     ,col('BRAND')\n                     ,col('MANUFACTURER_CODE') \n                     ,col('MANUFACTURER_NAME')\n                     ,col('LEGAL_CATEGORY')\n                     ,col('COMMERCIAL_CATEGORY_L1')\n                     ,col('COMMERCIAL_CATEGORY_L2')\n                     ,col('COMMERCIAL_CATEGORY_L3')\n                     ,col('PRODUCT_QTY')\n                     ,col('PRODUCT_FREE_QTY') \n                     ,col('PACK_SIZE')   \n                     ,col('PRODUCT_PRICE_CATALOG') \n                     ,col('PRODUCT_PRICE') \n                     ,col('DISCOUNT_TYPE') \n                     ,col('DISCOUNT_VALUE') \n                     ,col('DISCOUNT_WEIGTHED_AMOUNT') \n                     ,col('PRODUCT_FEE_VALUE') \n                     ,col('PRODUCT_MARKUP_VALUE')  \n                     ,col('PRODUCT_NET_PRICE') \n                     ,col('PRODUCT_NET_WEIGTHED_PRICE') \n                     ,col('PRODUCT_TOTAL_AMOUNT')  \n                     ,col('CONSUMER_PAYMENT_AMOUNT') \n                     ,col('REIMBURSEMENT_AMOUNT') \n                     ,col('CONSUMER_AMOUNT') \n                     ,col('TOT_RECEIPT_DISCOUNT_AMOUNT') \n                     ,col('TOT_RECEIPT_DECREASE_AMOUNT') \n                     ,col('TOT_RECEIPT_AMOUNT') \n                     ,col('PAYMENT_MODE') \n                     ,col('CONSUMER_TYPE') \n                     ,col('CONSUMER_ANONYMOUS_CODE') \n                     ,col('CONSUMER_GENDER') \n                     ,col('CONSUMER_BIRTH_YEAR') \n                     ,col('CONSUMER_LOCATION_CODE') \n                     ,col('CONSUMER_POSTAL_CODE')                  \n                     ,col('PRESCRIPTION_FLG') \n                     ,col('PRESCRIPTION_MODE') \n                     ,col('PRESCRIPTION_TYPE') \n                     ,col('PRESCRIPTION_CODE') \n                     ,col('PRESCRIPTION_ORIGIN') \n                     ,col('PRESCRIPTION_SPECIALITY') \n                     ,col('PRESCRIPTION_PRODUCT_CODE') \n                     ,col('PRESCRIPTION_PRODUCT_NAME') \n                     ,col('REIMBURSEMENT_FLG') \n                     ,col('REIMBURSEMENT_ENTITY_CODE') \n                     ,col('REIMBURSEMENT_ENTITY_NAME') \n                     ,col('REIMBURSEMENT_TYPE') \n                     ,col('REIMBURSEMENT_CATEGORY') \n                     ,col('PROMOTION_FLG') \n                     ,col('PROMOTION_TYPE') \n                     ,col('PROMOTION_CODE') \n                     ,col('PROMOTION_DESC') \n                     ,col('ISSUED_VOUCHERS_FLG') \n                     ,col('ISSUED_VOUCHERS_NUM') \n                     ,col('ISSUED_VOUCHERS_AMOUNT') \n                     ,col('USED_VOUCHERS_FLG') \n                     ,col('USED_VOUCHERS_NUM') \n                     ,col('USED_VOUCHERS_AMOUNT') \n                     ,col('LOYALTY_PROGRAM_FLG') \n                     ,col('LOYALTY_PROGRAM_NAME') \n                     ,col('LOYALTY_REBATE_FLG') \n                     )\n              .withColumn('LOAD_DATE', to_timestamp(current_timestamp(), \"yyyyMMddHHmmss\")) \n             ).persist(StorageLevel.MEMORY_AND_DISK).alias('df_CMD')\n    df_CMD.count()\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Data Selected\", sys._getframe().f_code.co_name)\n    # ###############################################################################################################################################\n    #  END - RENAME FIELDS FOR CANONICAL DATA FILE\n    # ###############################################################################################################################################\n\n    ################################################################################################################################################\n    #  SAVE CANONICAL DATA FILE\n    ################################################################################################################################################\n    \n    #Save the datraframe as a file\n    ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveAsCanonical STG_T_SELL_OUT: \" + str(df_CMD.count()) + \" rows \", sys._getframe().f_code.co_name)\n    saveAsCanonical(df_CMD,__PHARMATIC_CANONICAL_STG_SELLOUT_FILE_PATH__,table_name=__PHARMATIC_CANONICAL_STG_SELLOUT_H_TABLE_NAME__,mode='append',debug=True,job_id=job_id)\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After saveAsCanonical STG_T_SELL_OUT\", sys._getframe().f_code.co_name)\n\t\n    exception_status = \"GenerateCanonicalFarmaticSellout.STG_T_SELLOUT_CANONICAL\"\n    \n    #refresh LOAD_DATE to Database \n    df_CMD = df_CMD.withColumn('LOAD_DATE', to_timestamp(current_timestamp(), \"yyyyMMddHHmmss\")) \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Before saveToDB STG_T_SELL_OUT: \" + str(df_CMD.count()) + \" rows \", sys._getframe().f_code.co_name)\t\n    saveToDB(df_CMD,__PHARMATIC_CANONICAL_STG_SELLOUT_DB_TABLE_NAME__,mode=\"append\",debug=True,job_id=job_id)\n    ADP_log_debug(process, logger_name, level_action, log_level, \"After saveToDB STG_T_SELL_OUT\", sys._getframe().f_code.co_name)\n    \n    exception_status = \"GenerateCanonicalFarmaticSellout.STG_T_SELLOUT_DB\"\n\t\n    ##############################################################################################################################################\n    #  END - SAVE CANONICAL DATA FILE AND DATABASE\n    ##############################################################################################################################################\n    \n    if __DELETE_FILES_ENABLED__ == True:\n      #Delete processed files\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Before delete processed files\", sys._getframe().f_code.co_name)\t\n      delete_selected = df_detail.select(col('RAW_NAME')).distinct().withColumn(\"deleted\",blob_delete_file_sql(concat(lit(__PHARMATIC_TOBEPROCESSED_BASE_PATH__),col(\"RAW_NAME\"))))\n      deleted         = delete_selected.collect()\n      ADP_log_debug(process, logger_name, level_action, log_level, \"After delete processed files\", sys._getframe().f_code.co_name)\n\n    ################################################################################################################################################\n    #  END DELETE FILES\n    ################################################################################################################################################\n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n    \n    return True\n  \n  except Exception as err:\n    if exception_status == \"GenerateCanonicalFarmaticSellout.STG_T_SELLOUT_CANONICAL\":\n      RollbackCanonicalTable(__PHARMATIC_CANONICAL_STG_SELLOUT_H_TABLE_NAME__,rollback_id=job_id)\n    #end if exception_status == \"GenerateCanonicalFarmaticSellout.STG_T_SELLOUT_CANONICAL\"\n    \n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n    "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4}],"metadata":{"name":"ADP_Farmatic_Sellout_Process","notebookId":4470134901802163},"nbformat":4,"nbformat_minor":0}
