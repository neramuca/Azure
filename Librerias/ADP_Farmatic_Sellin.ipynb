{"cells":[{"cell_type":"code","source":["%run \"./ADP_Farmatic_Def\""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%run \"../Libraries/ADP_Spain_MDM_Def_Sellin\""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#################################################################################\n\"\"\"Process Sell Out file data and converts it into canonical format\n\n\"\"\"\n #Who                 When           What\n #Ana Perez           05/12/2018     Initial version\n #Victor Salesa       25/01/2019     Commented out call to QA_UPDATE_CTL_PROCESS_FILE_DATA as no longer exists\n #Victor Salesa       25/01/2019     Removed  %run \"../Libraries/ADP_QA\"\n################################################################################\ndef ProcessPharmaticFilesDataSellin (filepath,filename,errorpath,processedpath,debug=False):\n\n  \"\"\"Process Sell Out file data and converts it into canonical format\n\n      Parameters:\n      filepath                      -- path of file to be processed\n      filename                      -- file name of file to be processed\n      errorpath                     -- path where the file must be saved if it has number of fields incorrect or the process generates an exception\n      processedpath                 -- path where the file must be saved after validation and enrichment\n      debug                         -- Optional parameter. Default value=False. When this parameter is True, it prints some trace messages\n\n      Return:\n        fileProcessedStatus: OK, OK FMT     (processed with format field errorneous), \n                                 OK ENR     (processed with enrichment fields errorneous)\n                                 OK FMT ENR (processed with format and enrichment fields errorneous)\n                                 STR        (moved to errorpath because it has number of fields incorrect)\n                                 EX         (the process generates an exception; the file continues in tobeprocessed path)\n                                 EX: error saving Canonical File (the process cannot save the canonical file; the file continues in tobeprocessed path)\n\n      Example 1:\n        ProcessPharmaticFilesDataSellIn(\n          \"dbfs:/mnt/ds/tobeprocessed/pharmatic/605522930120171106GPR.txt\",\n          \"dbfs:/mnt/ds/errorprocess/pharmatic/\",\n          \"dbfs:/mnt/ds/canonical/pharmatic/\"\n          )\n\n  \"\"\"\n  #Who                 When           What\n  try:\n    \n    \n      processDate = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S') # Date and Time of the begining to this process\n      fileProcessedStatus = \"EX\"                                    # Status of process To be returned\n      path_fact = \"PR/\"                                             # Folder fo this business area\n      business_area = \"PR\"                                          # Business area\n      landingTimeStamp = filename[-18:-4]                           # Landing date extracted from File Name received as parameter\n      fileNameExtract = filename[0:21]                              # Original file name extracted from File Name received as parameter\n      pharmacyCodeEx = filename[0:4]                                      # parmacyCode extracted from File Name received as parameter\n      origExtension = filename[len(filename)-4:len(filename)]       # Original extension extracted from File Name received as parameter \n      lenSpecRow = __SP_PR_TOTAL_LENGHTS__                             # Length of detail at Spec \n\n      \n      #Initialize df_QA_PROCESS_file: General information about this file processing\n      rdd = sc.parallelize([(fileNameExtract+origExtension\n                       ,landingTimeStamp\n                       ,__PMS_FARMATIC_CODE__\n                       ,__PMS_FARMATIC_COUNTRY__\n                       ,pharmacyCodeEx\n                       ,business_area\n                       ,processDate\n                       ,processDate\n                       ,0\n                       ,\"\"\n                       ,\"\")])\n      df_QA_PROCESS_file = rdd.toDF([\"FILE_NAME\",\"LANDING_DATE\",\"PMS_CODE\",\"COUNTRY_CODE\",\"PHARMACY_CODE\",\"BUSINESS_AREA\",\"START_DATE\",\"END_DATE\",\"STATUS\",\"MESSAGE_TEXT\",\"ERROR_CODE\"])  \n      df_QA_PROCESS_file = (df_QA_PROCESS_file\n                 .withColumn (\"LANDING_DATE\", unix_timestamp(lit(landingTimeStamp), \"yyyyMMddHHmmss\").cast(TimestampType()))\n                 .withColumn (\"START_DATE\", to_timestamp(lit(processDate), 'yyyy-MM-dd HH:mm:ss')) \n                 .withColumn (\"END_DATE\",col(\"START_DATE\")) \n                )\n        \n      #Read the File Content\n      df = spark.read.text(filepath+filename)\n      \n      ################################################################################################################################################\n      #  FILE CONTENT MANAGEMENT\n      ################################################################################################################################################\n      if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[1][Start Process and Read Header]\")\n      \n      # DataFrame Filtering only the Header row\n      df_header = (df\n       .transform(SliceDFColumn(\"value\",['RecordType'],[__RECORDTYPE_LEN__])).filter(col(\"RecordType\") == \"H\").drop(\"RecordType\") \n       .transform(SliceDFColumn(\"value\",__SP_HEADER_COLUMN_NAMES__,__SP_HEADER_LENGHTS__))\n       .drop(\"value\")\n      )\n      \n      df_QA_PROCESS_file = (df_QA_PROCESS_file.withColumn (\"PHARMACY_CODE\", lit(df_header.rdd.first().PharmacyID)))\n      \n      if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[2][Read Detail]\")\n     \n      # DataFrame Detail: filtering the detail rows, adding some general file data\n      df_detail = (df\n       .transform(SliceDFColumn(\"value\",['RecordType'],[__RECORDTYPE_LEN__])).filter(col(\"RecordType\") == \"D\").drop(\"RecordType\")\n       .withColumn (\"FILE_NAME\", lit(fileNameExtract+\".TXT\"))\n       .withColumn (\"LANDING_DATE\", lit(landingTimeStamp))\n       .withColumn (\"PharmacyID\", lit(df_header.rdd.first().PharmacyID))\n       .withColumn (\"FileDate\", lit(df_header.rdd.first().FileDate))\n       .withColumn (\"ZIPCode\", lit(df_header.rdd.first().ZIPCode))\n       .withColumn (\"ExternalPharmacyID\", lit(df_header.rdd.first().ExternalPharmacyID))\n       .withColumn(\"FILE_LINE_NUM\",monotonically_increasing_id()+1)\n       .transform(SliceDFColumn(\"value\",__SP_PR_DETAIL_COLUMN_NAMES__,__SP_PR_DETAIL_LENGHTS__))\n       .withColumn (\"lenRow_ok\", (length(col(\"value\"))) == lit(lenSpecRow))\n       .drop(\"value\")\n      )\n      \n      if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[3][Check if lenrow errors]\")\n      \n      #if some row has not the correct length, move to ErrorProcessed Folder\n      if df_detail.filter(df_detail.lenRow_ok == False).count() > 0:\n        ################################################################################################################################################\n        #  VALIDATION NUMBER OF FIELDS\n        ################################################################################################################################################\n        processDateEnd = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n        # DataFrame Error df_QA_PROCESS_file\n        df_QA_PROCESS_file = (df_QA_PROCESS_file\n                             .withColumn (\"END_DATE\", to_timestamp(lit(processDateEnd), 'yyyy-MM-dd HH:mm:ss')) \n                             .withColumn (\"STATUS\", lit(-1))\n                             .withColumn (\"MESSAGE_TEXT\", lit('{\"INVALID_STRUCTURE\":\"File does not have a valid structure\"}'))\n                             .withColumn (\"ERROR_CODE\", lit('{\"INVALID_STRUCTURE\":\"-1\"}'))\n                            )\n#         if (QA_UPDATE_CTL_PROCESS_FILE_DATA(df_QA_PROCESS_file, debug=debug) == True):\n#           distributeFile_Def(filepath+filename, \"\", errorpath+path_fact+filename, False) #Copy File to error folder\n#           fileProcessedStatus = \"EX:STR\"\n#         else:\n#           fileProcessedStatus = \"EX:STR FAILED\"\n        #end if (QA_UPDATE_CTL_PROCESS_FILE_DATA\n        \n        ################################################################################################################################################\n        #  END - VALIDATION NUMBER OF FIELDS\n        ################################################################################################################################################\n      else:\n        ################################################################################################################################################\n        #  VALIDATION DATA FIELDS AND CREATE CANONICAL DATA FILE\n        ################################################################################################################################################\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[4][Content field process]\")\n        \n        spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n        \n        ################################################################################################################################################\n        #  VALIDATION FORMAT DATA FIELDS\n        ################################################################################################################################################\n        \n        df_detail = (df_detail\n                      .drop(\"lenRow_ok\")\n                       # Validate OperationLine\n                      .withColumn(\"OperationLine_Err\",   when(((udf_isDigit_sql(\"OperationLine\")==True) & (length(\"OperationLine\")==__PR_OPERATIONLINE_LEN__)) == True , 0).otherwise(-1))\n#                       .withColumn(\"OperationLine_Err2\",  when((isDigit(\"OperationLine\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\")) \n#                       .withColumn(\"OperationLine_Err2\",   \n#                                   when(\n#                                       ((length(\"OperationLine\")==__PR_OPERATIONLINE_LEN__)==False), \n#                                         (when(((length(\"OperationLine_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"OperationLine_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n#                                       ).otherwise(col(\"OperationLine_Err2\"))                       \n#                                  )\n#                       .withColumn(\"OperationLine_Err2\",  when(((length(\"OperationLine_Err2\")>0)==True),concat(lit(\"{\"),col(\"OperationLine_Err2\"),lit(\"}\"))).otherwise(\"\"))\n\n                        # Validate OperationDate \n                      .withColumn(\"OperationDate_Err\",   when( (udf_isDate_sql(\"OperationDate\",lit(__YYYYMMDDhhmmss__)))==True, 0).otherwise(-1)) \n#                       .withColumn(\"OperationDate_Err2\",  when( (udf_isDate_sql(\"OperationDate\",lit(__YYYYMMDDhhmmss__)))==False, ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\")) \n#                       .withColumn(\"OperationDate_Err2\",  when(((length(\"OperationDate_Err2\")>0)==True),concat(lit(\"{\"),col(\"OperationDate_Err2\"),lit(\"}\"))).otherwise(\"\"))\n\n#                        # Validate CostPricewithoutTaxes_Err           \n                      .withColumn(\"CostPricewithoutTaxes_Err\",    when(((udf_isDigit_sql(\"CostPricewithoutTaxes\")==True) & (length(\"CostPricewithoutTaxes\")==__PR_COSTPRICEWITHOUTTAXES_LEN__)) == True , 0).otherwise(-1))\n#                       .withColumn(\"CostPricewithoutTaxes_Err2\",   when((isDigit(\"CostPricewithoutTaxes\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\")) \n#                       .withColumn(\"CostPricewithoutTaxes_Err2\",   \n#                                   when(\n#                                       ((length(\"CostPricewithoutTaxes\")==__PR_COSTPRICEWITHOUTTAXES_LEN__)==False),  \n#                                         (when(((length(\"CostPricewithoutTaxes_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(\n#                                                   concat(col(\"CostPricewithoutTaxes_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"')))\n#                                         )\n#                                       ).otherwise(col(\"CostPricewithoutTaxes_Err2\"))                       \n#                                  )\n#                       .withColumn(\"CostPricewithoutTaxes_Err2\",   when(((length(\"CostPricewithoutTaxes_Err2\")>0)==True),concat(lit(\"{\"),col(\"CostPricewithoutTaxes_Err2\"),lit(\"}\"))).otherwise(\"\"))  \n\n                       # Validate Percentage             \n                      .withColumn(\"Percentage_Err\",    when(((udf_isDigit_sql(\"Percentage\")==True) & (length(\"Percentage\")==__PR_PERCENTAGE_LEN__)) == True , 0).otherwise(-1)       )\n#                       .withColumn(\"Percentage_Err2\",   when((isDigit(\"Percentage\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\"))\n#                       .withColumn(\"Percentage_Err2\",   \n#                                   when(\n#                                       ((length(\"Percentage\")==__PR_PERCENTAGE_LEN__)==False),   \n#                                         (when(((length(\"Percentage_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"Percentage_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n#                                       ).otherwise(col(\"Percentage_Err2\"))                       \n#                                  )\n#                       .withColumn(\"Percentage_Err2\",   when(((length(\"Percentage_Err2\")>0)==True),concat(lit(\"{\"),col(\"Percentage_Err2\"),lit(\"}\"))).otherwise(\"\")) \n\n                       # Validate TaxesPercentage          \n                      .withColumn(\"TaxesPercentage_Err\",  when(((udf_isDigit_sql(\"TaxesPercentage\")==True) & (length(\"TaxesPercentage\")==__PR_TAXESPERCENTAGE_LEN__)) == True , 0).otherwise(-1) )\n#                       .withColumn(\"TaxesPercentage_Err2\", when((isDigit(\"TaxesPercentage\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\"))  \n#                       .withColumn(\"TaxesPercentage_Err2\",   \n#                                   when(\n#                                       ((length(\"TaxesPercentage\")==__PR_TAXESPERCENTAGE_LEN__)==False), \n#                                         (when(((length(\"TaxesPercentage_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"TaxesPercentage_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n#                                       ).otherwise(col(\"TaxesPercentage_Err2\"))                       \n#                                  )\n#                       .withColumn(\"TaxesPercentage_Err2\", when(((length(\"TaxesPercentage_Err2\")>0)==True),concat(lit(\"{\"),col(\"TaxesPercentage_Err2\"),lit(\"}\"))).otherwise(\"\"))                        \n\n                       # Validate Quantity  \n                      .withColumn(\"Quantity_Err\",  when(((udf_isDigit_sql(\"Quantity\")==True) & (length(\"Quantity\")==__PR_QUANTITY_LEN__)) == True , 0).otherwise(-1) )\n#                       .withColumn(\"Quantity_Err2\", when((isDigit(\"Quantity\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\"))\n#                       .withColumn(\"Quantity_Err2\",   \n#                                   when(\n#                                       ((length(\"Quantity\")==__PR_QUANTITY_LEN__)==False), \n#                                         (when(((length(\"Quantity_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"Quantity_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n#                                       ).otherwise(col(\"Quantity_Err2\"))                       \n#                                  )\n#                       .withColumn(\"Quantity_Err2\",   when(((length(\"Quantity_Err2\")>0)==True),concat(lit(\"{\"),col(\"Quantity_Err2\"),lit(\"}\"))).otherwise(\"\"))  \n\n                       # Validate QuantityOffered        \n                      .withColumn(\"QuantityOffered_Err\",  when(((udf_isDigit_sql(\"QuantityOffered\")==True) & (length(\"QuantityOffered\")==__PR_QUANTITYOFFERED_LEN__)) == True , 0).otherwise(-1))\n#                       .withColumn(\"QuantityOffered_Err2\", when((isDigit(\"QuantityOffered\")==False),  ('\"' + 'DATA_TYPE' + '\":' + '\"1\"')).otherwise(\"\")) \n#                       .withColumn(\"QuantityOffered_Err2\",   \n#                                   when(\n#                                       ((length(\"QuantityOffered\")==__PR_QUANTITYOFFERED_LEN__)==False),    \n#                                         (when(((length(\"QuantityOffered_Err2\")==0)==True),('\"' + 'DATA_LENGTH' + '\":' + '\"1\"')).otherwise(concat(col(\"QuantityOffered_Err2\"), lit(',\"' + 'DATA_LENGTH' + '\":' + '\"1\"'))))\n#                                       ).otherwise(col(\"QuantityOffered_Err2\"))                       \n#                                  )\n#                       .withColumn(\"QuantityOffered_Err2\",  when(((length(\"QuantityOffered_Err2\")>0)==True),concat(lit(\"{\"),col(\"QuantityOffered_Err2\"),lit(\"}\"))).otherwise(\"\"))              \n                    )\n        \n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[5 validations end]\")\n        ################################################################################################################################################\n        #  END VALIDATION FORMAT DATA FIELDS\n        ################################################################################################################################################\n        \n        \n        ################################################################################################################################################\n        #  TRANSFORMATION DATA FIELDS\n        ################################################################################################################################################\n        df_detail = (df_detail\n             .drop(\"RecordType\")\n#              .withColumn(\"OPERATION_LINE_RAW\", col(\"OperationLine\"))\n#              .withColumn(\"OPERATION_DATE_RAW\", col(\"OperationDate\"))\n#              .withColumn(\"NATIONAL_CODE_RAW\", col(\"ProductCode\")) \n#              .withColumn(\"CATEGORY_RAW\", col(\"ProductCode\")) \n#              .withColumn(\"MANUFACTURER_CODE_RAW\", col(\"ProductCode\")) \n#              .withColumn(\"PRODUCT_QTY_RAW\", col(\"ProductUnits\"))  \n#              .withColumn(\"PACK_SIZE_RAW\", col(\"ProductPackSize\")) \n#              .withColumn(\"PRODUCT_PRICE_CATALOG_RAW\", col(\"ProductPriceCatalog\"))   \n#              .withColumn(\"PRODUCT_PRICE_RAW\", col(\"ProductPrice\"))\n#              .withColumn(\"DISCOUNT_VALUE_RAW\", col(\"DiscountValue\"))      \n#              .withColumn(\"PRODUCT_NET_RAW\", col(\"ProductTotalPrice\")) \n#              .withColumn(\"REIMBURSEMENT_VALUE_RAW\", col(\"ReimbursementValue\"))  \n#              .withColumn(\"CONSUMER_VALUE_RAW\", col(\"ConsumerValue\"))    \n#              .withColumn(\"PAYMENT_MODE_RAW\", col(\"PaymentMode\"))       \n#              .withColumn(\"CONSUMER_GENDER_RAW\", col(\"ConsumerGender\"))  \n#              .withColumn(\"PHARMACY_CODE_RAW\", col(\"PharmacyID\"))          \n             .withColumn(\"OperationLine\", col(\"OperationLine\").cast(IntegerType()))\n             .withColumn(\"Quantity\", col(\"Quantity\").cast(IntegerType()))\n             .withColumn(\"QuantityOffered\", col(\"QuantityOffered\").cast(IntegerType()))\n             .withColumn(\"CostPricewithoutTaxes\", col(\"CostPricewithoutTaxes\").cast(DoubleType())/100)                 \n             .withColumn(\"Percentage\", col(\"Percentage\").cast(DoubleType())/100)\n             .withColumn(\"TaxesPercentage\", col(\"TaxesPercentage\").cast(DoubleType())/100)\n             .withColumn(\"formatErrorRow\",   \n                      col(\"OperationLine_Err\").cast(IntegerType()) + \n                      col(\"OperationDate_Err\").cast(IntegerType()) +\n                      col(\"CostPricewithoutTaxes_Err\").cast(IntegerType()) + \n                      col(\"Percentage_Err\").cast(IntegerType()) + \n                      col(\"TaxesPercentage_Err\").cast(IntegerType()) + \n                      col(\"Quantity_Err\").cast(IntegerType()) + \n                      col(\"QuantityOffered_Err\").cast(IntegerType()))\n        )\n\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[Number data type processed]\")\n                \n        #Delete spaces into fields   \n        df_detail = (reduce(\n                        lambda df_detail, col_name: df_detail.withColumn(col_name, trim(col(col_name))),\n                        df_detail.columns,\n                        df_detail)\n                    )\n\n        df_detail = df_detail.alias('df_detail')\n        ################################################################################################################################################\n        #  END - TRANSFORMATION DATA FIELDS\n        ################################################################################################################################################\n        \n\n        ################################################################################################################################################\n        #  ENRICHMENT DATA FIELDS\n        ################################################################################################################################################\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[[Begin Enrichment PRODUCT]\")\n\n        #Enrichment with PRODUCT MASTER DATA\n        df_product_cat = (spark.read.format('csv')\n                          .options(header='true',charset='UTF-8')\n                          .option(\"sep\",\"|\")\n                          .load(__PHARMATIC_MASTER_DATA_CANONICAL_CATEGORIES_PATH__,schema=__SP_CATEGORIES_CANONICAL_DATA_SCHEMA__)\n                         )\n\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[9][Filter if National and EAN Not null]\")\n        #Products with EAN and NATIONAL CODE  \n        df_product = df_product_cat.filter((df_product_cat.EAN13.isNull() == False)\n                                         & (df_product_cat.NATIONAL_CODE.isNull() == False)).distinct().alias('df_product')\n                \n        df_detail = (df_detail.repartition(200)\n                       .join(df_product.repartition(200), ((col('df_detail.EANCode')==col('df_product.EAN13'))\n                                                         & (col('df_detail.ProductCode')==col('df_product.NATIONAL_CODE')) ), how='left')\n                       .select('df_detail.*'\n                              , 'df_product.NATIONAL_CODE'\n                              , 'df_product.EAN13'\n                              , 'df_product.CLASS'\n                              , 'df_product.CATEGORY'\n                              , 'df_product.FAMILY'\n                              , 'df_product.SUBFAMILY'\n                              , 'df_product.BRAND'\n                              , 'df_product.LABORATORY'\n                              , 'df_product.PRODUCT_NAME'\n                              )\n                    ).alias('df_detail')\n\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[10][Filter > 149999]\")\n        \n        #Product with NATIONAL_CODE - pharmaceutical and parapharmacy products\n        df_product = (df_product_cat\n                      .filter(df_product_cat.NATIONAL_CODE> \"149999\")\n                      .select( col('NATIONAL_CODE')\n                              , col('CLASS')\n                              , col('CATEGORY')\n                              , col('FAMILY')\n                              , col('SUBFAMILY')\n                              , col('BRAND')\n                              , col('LABORATORY')\n                              , col('PRODUCT_NAME')\n                              )\n                      .distinct()\n                      .alias('df_product'))\n\n        df_detail = (df_detail.repartition(200).join(df_product.repartition(200), col('df_detail.ProductCode')==col('df_product.NATIONAL_CODE'), how='left')\n                      .select('df_detail.*'\n                              , col('df_product.NATIONAL_CODE').alias('dp_NATIONAL_CODE')\n                              , col('df_product.CLASS').alias('dp_CLASS')\n                              , col('df_product.CATEGORY').alias('dp_CATEGORY')\n                              , col('df_product.FAMILY').alias('dp_FAMILY')\n                              , col('df_product.SUBFAMILY').alias('dp_SUBFAMILY')\n                              , col('df_product.BRAND').alias('dp_BRAND')\n                              , col('df_product.LABORATORY').alias('dp_LABORATORY')\n                              , col('df_product.PRODUCT_NAME').alias('dp_PRODUCT_NAME')\n                              )\n                      .withColumn(\"NATIONAL_CODE\",\n                                  when((col('df_detail.NATIONAL_CODE').isNull()==True)  & (col('dp_NATIONAL_CODE').isNull()==False), col('dp_NATIONAL_CODE')).otherwise(col('df_detail.NATIONAL_CODE')))              \n                      .withColumn(\"CLASS\",\n                                  when((col('df_detail.CLASS').isNull()==True) & (col('dp_CLASS').isNull()==False) , col('dp_CLASS')).otherwise(col('df_detail.CLASS')))      \n                      .withColumn(\"CATEGORY\",       \n                             when((col('df_detail.CATEGORY').isNull()==True) & (col('dp_CATEGORY').isNull()==False) , col('dp_CATEGORY')).otherwise(col('df_detail.CATEGORY')))               \n                      .withColumn(\"FAMILY\",    \n                           when((col('df_detail.FAMILY').isNull()==True) & (col('dp_FAMILY').isNull()==False) , col('dp_FAMILY')).otherwise(col('df_detail.FAMILY'))) \n                      .withColumn(\"SUBFAMILY\",    \n                           when((col('df_detail.SUBFAMILY').isNull()==True) & (col('dp_SUBFAMILY').isNull()==False) , col('dp_SUBFAMILY')).otherwise(col('df_detail.SUBFAMILY')))   \n                      .withColumn(\"BRAND\",    \n                           when((col('df_detail.BRAND').isNull()==True) & (col('dp_BRAND').isNull()==False) , col('dp_BRAND')).otherwise(col('df_detail.BRAND'))) \n                      .withColumn(\"LABORATORY\",    \n                           when((col('df_detail.LABORATORY').isNull()==True) & (col('dp_LABORATORY').isNull()==False) , col('dp_LABORATORY')).otherwise(col('df_detail.LABORATORY')))         \n                      .withColumn(\"PRODUCT_NAME\",    \n                           when((col('df_detail.PRODUCT_NAME').isNull()==True)  & (col('dp_PRODUCT_NAME').isNull()==False) , col('dp_PRODUCT_NAME')).otherwise(col('df_detail.PRODUCT_NAME')))   \n                      .drop(col('dp_NATIONAL_CODE'))\n                      .drop(col('dp_EAN13'))\n                      .drop(col('dp_CLASS'))\n                      .drop(col('dp_CATEGORY'))\n                      .drop(col('dp_FAMILY'))\n                      .drop(col('dp_SUBFAMILY'))\n                      .drop(col('dp_BRAND'))\n                      .drop(col('dp_LABORATORY'))\n                      .drop(col('dp_PRODUCT_NAME'))  \n                  ).alias('df_detail')\n\n        #Assign Free products (NATIONAL_CODE -9), NATIONAL_CODE -1, EnrichNationalCodeResult and EnrichCategoryResult\n        df_detail = (df_detail\n                       .withColumn(\"NATIONAL_CODE\", \n                               when((col('ProductCode')< \"150000\") & (col('NATIONAL_CODE').isNull()==True),-9).otherwise( col('NATIONAL_CODE')))              \n                       .withColumn(\"NATIONAL_CODE\",\n                               when((col('NATIONAL_CODE').isNull()==False), col('NATIONAL_CODE')).otherwise(-1))\n                     ).alias('df_detail')\n        \n        \n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[11][Begin Enrichment PHARMACIES]\")\n        ########################### ENRICH PHARMACIES\n        df_pharmacy = (spark.read.format('csv')\n                          .options(header='true',charset='UTF-8')\n                          .option(\"sep\",\"|\")\n                          .load(__PHARMATIC_MASTER_DATA_CANONICAL_PHARMACIES_PATH__,schema=__SP_PHARMACIES_MASTER_DATA_SCHEMA__)\n                         )\n\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[12][Filter PHARMACIES]\")\n        \n        #Pharmacies with AH_PHARMACY_CODE  \n        df_pharmacy = (df_pharmacy\n                        .filter((df_pharmacy.AH_PHARMACY_CODE.isNull() == False))\n                        .select(col('AH_PHARMACY_CODE').alias('PH_AH_PHARMACY_CODE')\n                               ,col('PHARMACY_CODE'))\n                        .distinct()\n                      ).alias('df_pharmacy')\n\n        df_detail = (df_detail\n                     .join(broadcast(df_pharmacy), (col('df_detail.PharmacyID')==col('df_pharmacy.PH_AH_PHARMACY_CODE')), how='left')\n                     . select ('df_detail.*'\n                              , col('df_pharmacy.PHARMACY_CODE').alias('PHARMACY_CODE'))\n                     . withColumn(\"PHARMACY_CODE\",\n                               when((col('PHARMACY_CODE').isNull()==False), col('PHARMACY_CODE')).otherwise(-1))\n                     ).alias('df_detail')\n        \n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[13][Enrich MANUFACTURERS]\")\n        ########################### ENRICH PRODUCT-MANUFACTURER\n        df_product_new = (spark.read.format('csv')\n                          .options(header='true',charset='UTF-8')\n                          .option(\"sep\",\"|\")\n                          .load(\"/mnt/ds/canonical/masterdata/product_master_new_CDM.csv\")\n                         )\n        #Pharmacies with MANUFACTURER_CODE\n        df_product_new = (df_product_new\n                            .filter((df_product_new.MANUFACTURER_CODE.isNull() == False))\n                            .select(col('PRODUCT_CODE')\n                                   ,col('MANUFACTURER_CODE'))\n                            .distinct()\n                          ).alias('df_product_new')\n\n        df_detail = (df_detail\n                     .join(broadcast(df_product_new), (col('df_detail.NATIONAL_CODE')== df_product_new.PRODUCT_CODE.substr(0,6)), how='left')\n                     . select ('df_detail.*'\n                              , col('df_product_new.MANUFACTURER_CODE'))\n                      . withColumn(\"MANUFACTURER_CODE\",\n                               when((col('MANUFACTURER_CODE').isNull()==False), col('MANUFACTURER_CODE')).otherwise(-1))\n                     ).alias('df_detail')\n\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[14][Calculate EnrichResult fields ]\")\n                \n        #Assign EnrichNationalCodeResult, EnrichCategoryResult, EnrichManufacturerResult AND EnrichErrorRow\n        df_detail = (df_detail\n                       .withColumn(\"EnrichNationalCodeResult\",\n                               when((col('NATIONAL_CODE')==lit(\"-9\")) | (col('NATIONAL_CODE')!=lit(\"-1\")), lit(\"OK\")))\n                       .withColumn(\"EnrichNationalCodeResult\",\n                               when(\n                                 (col('NATIONAL_CODE')==lit(\"-1\")) & \n                                 (col('ProductCode')> \"599999\"),lit(\"NF1\")).otherwise(col('EnrichNationalCodeResult')))\n                       .withColumn(\"EnrichNationalCodeResult\",\n                               when(\n                                 (col('NATIONAL_CODE')==lit(\"-1\")) & \n                                 (col('ProductCode')> \"149999\") &\n                                 (col('ProductCode')< \"600000\")\n                                 ,lit(\"NF2\")).otherwise(col('EnrichNationalCodeResult')))\n                       .withColumn(\"EnrichCategoryResult\",\n                                 when((col('CATEGORY').isNull()==False), lit(\"OK\")))\n                       .withColumn(\"EnrichCategoryResult\",\n                                 when(\n                                   ((col('CATEGORY').isNull()==True)) & \n                                   (col('ProductCode')> \"599999\")\n                                   ,lit(\"NF1\")).otherwise(col('EnrichCategoryResult')))\n                        .withColumn(\"EnrichCategoryResult\",\n                                 when(\n                                   ((col('CATEGORY').isNull()==True)) & \n                                   (col('ProductCode')> \"149999\") &\n                                   (col('ProductCode')< \"600000\")\n                                   ,lit(\"NF2\")).otherwise(col('EnrichCategoryResult')))\n                        .withColumn(\"EnrichCategoryResult\",\n                                 when(\n                                   ((col('CATEGORY').isNull()==True)) & \n                                   (col('ProductCode')< \"150000\")\n                                   ,lit(\"NF3\")).otherwise(col('EnrichCategoryResult')))\n                        .withColumn(\"EnrichManufacturerResult\",\n                                 when((col('MANUFACTURER_CODE')!=\"-1\"), lit(\"OK\")).otherwise(\"NF\"))\n                        .withColumn(\"EnrichPharmacyResult\",\n                                 when((col('PHARMACY_CODE')!=\"-1\"), lit(\"OK\")).otherwise(\"NF\"))\n                        .withColumn(\"EnrichErrorRow\", lit(\"0\"))\n                        .withColumn(\"EnrichErrorRow\",\n                                    (when((col('EnrichNationalCodeResult')==\"OK\"), 0).otherwise(-1)) +\n                                    (when((col('EnrichCategoryResult')==\"OK\"), 0).otherwise(-1)) +\n                                    (when((col('EnrichManufacturerResult')==\"OK\"), 0).otherwise(-1)) +\n                                    (when((col('EnrichPharmacyResult')==\"OK\"), 0).otherwise(-1))\n                                   )\n                         # Validate NATIONAL_CODE\n                        .withColumn(\"NATIONAL_CODE_ERR\",  when((col('EnrichNationalCodeResult')==\"OK\"), \"\").otherwise('{\"' + 'ENRICHMENT' + '\":' + '\"1\"}') )\n                         # Validate CATEGORY\n                        .withColumn(\"CATEGORY_ERR\",  when((col('EnrichCategoryResult')==\"OK\"), \"\").otherwise('{\"' + 'ENRICHMENT' + '\":' + '\"1\"}') )\n                         # Validate MANUFACTURER\n                        .withColumn(\"MANUFACTURER_CODE_ERR\",  when((col('EnrichManufacturerResult')==\"OK\"), \"\").otherwise('{\"' + 'ENRICHMENT' + '\":' + '\"1\"}') )\n                         # Validate PHARMACY_CODE\n                        .withColumn(\"PHARMACY_CODE_ERR\",  when((col('EnrichPharmacyResult')==\"OK\"), \"\").otherwise('{\"' + 'ENRICHMENT' + '\":' + '\"1\"}') )\n                     ).alias('df_detail')\n\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[15][Count Errors]\")\n        \n        #Status to be returned\n        fileProcessedStatus = \"OK:\"\n        if df_detail.filter(df_detail.formatErrorRow <0).count() > 0:\n          fileProcessedStatus = fileProcessedStatus + \" FMT\" #some Format Error had been detected\n        #end if formatErrorRow\n        \n        if df_detail.filter(df_detail.EnrichErrorRow <0).count() > 0:\n            fileProcessedStatus = fileProcessedStatus + \" ENR\" #some Enrichment Error had been detected\n        #end if enrichErrorRow\n        ################################################################################################################################################\n        #  END - ENRICHMENT DATA FIELDS\n        ################################################################################################################################################\n        \n        \n#         ################################################################################################################################################\n#         #  QA MANAGMENT ERROS \n#         ################################################################################################################################################\n#         df_errors = (df_detail\n#                       .withColumn(\"PROCESS_DATE\", to_timestamp(lit(processDate), 'yyyy-MM-dd HH:mm:ss') )\n#                       .select(col('PROCESS_DATE')\n#                             , col('FILE_NAME')\n#                             , col('LANDING_DATE')\n#                             , col('FILE_LINE_NUM')\n#                             , col('OperationLine_Err2').alias(\"OPERATION_LINE_ERR\")\n#                             , col('OPERATION_LINE_RAW')\n#                             , col('OperationDate_Err2').alias(\"OPERATION_DATE_ERR\")\n#                             , col('OPERATION_DATE_RAW')\n#                             , col('ProductUnits_Err2').alias(\"PRODUCT_QTY_ERR\")\n#                             , col('PRODUCT_QTY_RAW')\n#                             , col('ProductPackSize_Err2').alias(\"PACK_SIZE_ERR\")\n#                             , col('PACK_SIZE_RAW')\n#                             , col('ProductPriceCatalog_Err2').alias(\"PRODUCT_PRICE_CATALOG_ERR\")\n#                             , col('PRODUCT_PRICE_CATALOG_RAW')\n#                             , col('ProductPrice_Err2').alias(\"PRODUCT_PRICE_ERR\")\n#                             , col('PRODUCT_PRICE_RAW')\n#                             , col('DiscountValue_Err2').alias(\"DISCOUNT_VALUE_ERR\")\n#                             , col('DISCOUNT_VALUE_RAW')  \n#                             , col('ProductTotalPrice_Err2').alias(\"PRODUCT_NET_ERR\")\n#                             , col('PRODUCT_NET_RAW')  \n#                             , col('ReimbursementValue_Err2').alias(\"REIMBURSEMENT_VALUE_ERR\")\n#                             , col('REIMBURSEMENT_VALUE_RAW')\n#                             , col('ConsumerValue_Err2').alias(\"CONSUMER_VALUE_ERR\")\n#                             , col('CONSUMER_VALUE_RAW')\n#                             , col('PaymentMode_Err2').alias(\"PAYMENT_MODE_ERR\")\n#                             , col('PAYMENT_MODE_RAW')  \n#                             , col('ConsumerGender_Err2').alias(\"CONSUMER_GENDER_ERR\")\n#                             , col('CONSUMER_GENDER_RAW') \n#                             , col('NATIONAL_CODE_ERR')\n#                             , col('NATIONAL_CODE_RAW')\n#                             , col('CATEGORY_ERR')\n#                             , col('CATEGORY_RAW') \n#                             , col('MANUFACTURER_CODE_ERR')\n#                             , col('MANUFACTURER_CODE_RAW') \n#                             , col('PHARMACY_CODE_ERR')\n#                             , col('PHARMACY_CODE_RAW') \n#                             )\n#                       .withColumn('PROCESS_DATE', to_timestamp(col(\"PROCESS_DATE\"), 'yyyy-MM-dd HH:mm:ss'))\n#                       .withColumn('LANDING_DATE', unix_timestamp(\"LANDING_DATE\", \"yyyyMMddHHmmss\").cast(TimestampType()))\n#                       .withColumn(\"formatErrorRow\",   \n#                                 (when ((length(\"OPERATION_LINE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"OPERATION_DATE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PRODUCT_QTY_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PACK_SIZE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PRODUCT_PRICE_CATALOG_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PRODUCT_PRICE_ERR\")==0)==True, 0).otherwise(1)) +    \n#                                 (when ((length(\"DISCOUNT_VALUE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PRODUCT_NET_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"REIMBURSEMENT_VALUE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"CONSUMER_VALUE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PAYMENT_MODE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"CONSUMER_GENDER_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"NATIONAL_CODE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"CATEGORY_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"MANUFACTURER_CODE_ERR\")==0)==True, 0).otherwise(1)) +\n#                                 (when ((length(\"PHARMACY_CODE_ERR\")==0)==True, 0).otherwise(1))  \n#                                  )\n#                       .filter(col(\"formatErrorRow\")> 0)\n#                       .drop(\"formatErrorRow\")\n#                     )\n\n#         if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[16][QA_GENERATE_DATA]\")\n#         rows_count = df_detail.count()\n#         OK_rows_count = rows_count-df_errors.count()\n        \n#         qa_result = QA_GENERATE_DATA(df_errors, rows_count, OK_rows_count,debug=debug)\n\n#         if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[17][ END QA_GENERATE_DATA]\")\n\n#         df_detail = (df_detail\n#                       .drop('OperationLine_Err2')\n#                       .drop('OperationDate_Err2')\n#                       .drop('PRODUCT_QTY_ERR')\n#                       .drop('ProductPackSize_Err2')\n#                       .drop('ProductPriceCatalog_Err2')\n#                       .drop('ProductPrice_Err2')\n#                       .drop('DiscountValue_Err2')\n#                       .drop('ProductTotalPrice_Err2')\n#                       .drop('ReimbursementValue_Err2')\n#                       .drop('ConsumerValue_Err2')\n#                       .drop('PaymentMode_Err2')\n#                       .drop('ConsumerGender_Err2')\n#                     )\n#         ################################################################################################################################################\n#         #  END - QA MANAGMENT ERRORS \n#         ################################################################################################################################################\n\n        \n        ################################################################################################################################################\n        #  RENAME FIELDS FOR CANONICAL DATA FILE\n        ################################################################################################################################################\n        df_detail = (df_detail\n                     .withColumnRenamed('PharmacyID', 'PHARMACY_PMS_CODE')\n                     .withColumnRenamed('FileDate', 'FILE_DATE')\n                     .withColumnRenamed('ZIPCode', 'ZIP_CODE')\n                     .withColumnRenamed('ExternalPharmacyID', 'EXTERNAL_PHARMACY_CODE')\n                     .withColumnRenamed('OperationIdentification', 'OPERATION_TYPE')\n                     .withColumnRenamed('OperationID', 'OPERATION_CODE')\n                     .withColumnRenamed('OperationLine', 'OPERATION_LINE')\n                     .withColumnRenamed('OperationDate', 'OPERATION_DATE')\n                     .withColumnRenamed('SupplierType', 'SUPPLIER_TYPE')\n                     .withColumnRenamed('SupplierIdentification', 'SUPPLIER_CODE')\n                     .withColumnRenamed('ProductCode', 'PRODUCT_LINE_CODE')\n                     .withColumnRenamed('ProductName', 'PRODUCT_LINE_NAME')\n                     .withColumnRenamed('EANCode', 'EAN_CODE')\n                     .withColumnRenamed('AlternativeProductCode', 'ALTERNATIVE_PRODUCT_CODE')\n                     .withColumnRenamed('CostPricewithoutTaxes', 'PRODUCT_NET_PRICE')\n                     .withColumnRenamed('PercentageSignal', 'PERCENTAGE_TYPE')\n                     .withColumnRenamed('Percentage', 'PERCENTAGE_VALUE')\n                     .withColumnRenamed('TaxesPercentage', 'TAXES_PERCENTAGE_VALUE')\n                     .withColumnRenamed('Quantity', 'PRODUCT_QTY')\n                     .withColumnRenamed('QuantityOffered', 'PRODUCT_OFFERED_QTY')\n                    )\n        \n        ################################################################################################################################################\n        #  END - RENAME FIELDS FOR CANONICAL DATA FILE\n        ################################################################################################################################################\n        \n        ################################################################################################################################################\n        #  SAVE CANONICAL DATA FILE\n        ################################################################################################################################################\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[18][ BEGIN Save CMD]\")\n        \n        #Save the datraframe as a file\n        result = saveAsCanonical(df_detail,processedpath+path_fact+fileNameExtract+ \"_CMD.csv\")\n        if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[19][ END Save CMD]\")\n          \n        processDateEnd = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n        if result == False:\n            distributeFile_Def(filepath+filename, \"\", errorpath+path_fact+filename, False) #Copy File to error folder\n                        \n            if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[20][MOVE TO errorpath  CMD ]\")\n#             # Return information for CTL.PROCESS_FILE entity\n#             df_QA_PROCESS_file = (df_QA_PROCESS_file\n#                                  .withColumn (\"END_DATE\", to_timestamp(lit(processDateEnd), 'yyyy-MM-dd HH:mm:ss')) \n#                                  .withColumn (\"STATUS\", lit(-1))\n#                                  .withColumn (\"MESSAGE_TEXT\", lit('{\"CDM_NOT_SAVED\":\"CMD File saved function unsuccessfully\"}'))\n#                                  .withColumn (\"ERROR_CODE\", lit('{\"CDM_NOT_SAVED\":\"-1\"}'))\n#                                 )\n#             if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[20][DDBB QA saved CMD KO]\")\n#             if (QA_UPDATE_CTL_PROCESS_FILE_DATA(df_QA_PROCESS_file, debug=debug) == True):\n#               fileProcessedStatus = \"EX: CMD File saved function unsuccessfully\" \n#             else:\n#               fileProcessedStatus = \"EX QA FAILED: CMD File saved function unsuccessfully\"\n#             #end if (QA_UPDATE_CTL_PROCESS_FILE_DATA \n        else:\n            (deleteFile_Def(filepath,filename))   #Delete the tobreprocessed file\n#             # Return information for CTL.PROCESS_FILE entity\n#             df_QA_PROCESS_file = (df_QA_PROCESS_file\n#                                  .withColumn (\"END_DATE\", to_timestamp(lit(processDateEnd), 'yyyy-MM-dd HH:mm:ss')) \n#                                  .withColumn (\"STATUS\", lit(1))\n#                                 )\n#              if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[20][DDBB QA saved CMD OK]\")\n#             if (QA_UPDATE_CTL_PROCESS_FILE_DATA(df_QA_PROCESS_file, debug=debug) == False):\n#               fileProcessedStatus = \"QA FAILED \" + fileProcessedStatus\n#             #end if (QA_UPDATE_CTL_PROCESS_FILE_DATA\n        #end if result == False\n        ##############################################################################################################################################\n        #  END - SAVE CANONICAL DATA FILE\n        ##############################################################################################################################################\n        \n      ################################################################################################################################################\n      #  END VALIDATION DATA FIELDS AND CREATE CANONICAL DATA FILE\n      ################################################################################################################################################        \n      #end if df_detail.filter\n          \n      ################################################################################################################################################\n      #  END FILE CONTENT MANAGEMENT\n      ################################################################################################################################################\n      \n      return fileProcessedStatus\n    \n  except Exception as e:\n      processDateEnd = datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n      errorException= str(e).replace(\"'\",\"\")\n      \n      if debug==True: print(\"[\"+datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')+\"]\"+\"[\"+filename+\"]\"+\"[ EXCEPTION]\")\n        \n#       # DataFrame Error df_QA_PROCESS_file\n#       df_QA_PROCESS_file = (df_QA_PROCESS_file\n#            .withColumn (\"END_DATE\", to_timestamp(lit(processDateEnd), 'yyyy-MM-dd HH:mm:ss')) \n#            .withColumn (\"STATUS\", lit(-2))\n#            .withColumn (\"MESSAGE_TEXT\", lit('{\"EXCEPTION_ERROR\":\"File does not have a valid structure\"}'))\n#            .withColumn (\"ERROR_CODE\", lit('{\"EXCEPTION_ERROR\":\"-2\"}'))\n#           )\n#       if (QA_UPDATE_CTL_PROCESS_FILE_DATA(df_QA_PROCESS_file, debug=debug) == True):\n#         fileProcessedStatus= \"EX:\" + errorException\n#       else:\n#         fileProcessedStatus= \"EX: FAILED \" + errorException\n      \n      fileProcessedStatus= \"EX:\" + errorException # ELIMINAR AL QUITAR COMENTARIOS DE QA\n      \n      \n      #end if (QA_UPDATE_CTL_PROCESS_FILE_DATA\n      \n      return fileProcessedStatus  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3}],"metadata":{"name":"ADP_Farmatic_Sellin","notebookId":3996791399039813},"nbformat":4,"nbformat_minor":0}
