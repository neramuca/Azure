{"cells":[{"cell_type":"code","source":["%run \"./ADP_Farmatic_Def\""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#################################################################################\n\"\"\" FTP Files Process Functions\n\n\"\"\"\n #Who                 When           What\n #Victor Salesa       12/12/2018     Initial Version\n #Victor Salesa       21/01/2019     Moved patch - depatch ftp lib to functions\n #Victor Salesa       19/02/2019     Change code to retrieve zip password as a parameter\n #Victor Salesa       04/03/2019     Added GPR & GST Housekeeping function to delete all files not GSL\n #Victor Salesa       12/03/2019     udf_unzip: Change unzip process to include ZIP file suffix\n #Victor Salesa       13/03/2019     DeleteAllButSelloutFilesFromLanding: Fix function to select files to delete locating 'GSL' string\n #Victor Salesa       22/03/2019     FMT_FTPTriggerFilesDownload: Initial Version\n #Ana Perez           26/03/2019     Included log managment and exception managment\n #Victor Salesa       04/03/2019     created UnzipPharmaticFilesFromIngestion,MoveUncompressedFilesToArchive,StoreUnzipResultsToCSV \n #                                   for better code understanding and isolated Exception and Error control of the different blocks.\n #Ana Perez           03/05/2019     Split ADP_Farmatic_Ingestion_Process in ADP_FTP and ADP_UNZIP \n #Victor Salesa       07/05/2019     Rename DeleteAllButSelloutFilesFromLanding to  DeleteFilesFromLandingExcludingPattern and add patterns parameter\n #Victor Salesa       07/05/2019     Moved DeleteFilesFromLandingExcludingPattern to ADP_Unzip\n################################################################################\n\nimport socket\nfrom pyspark.sql import Row\nfrom dateutil import parser\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom shutil import copyfile\nfrom datetime import datetime\n\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom shutil import *\n#import zipfile\n\nfrom ftplib import FTP_TLS\nfrom ftplib import FTP\nimport os\nfrom multiprocessing.pool import ThreadPool\nimport inspect\n\n###################################################################################  \ndef __patch_ftp_lib__():\n  #Who                 When           What\n  #Victor Salesa       xx/xx/2018     Initial version\n  #Ana Perez           27/03/2019     Included log managment and exception managment\n  #Ana Perez           06/05/2019     Change parameters of ADP_log functions by generic variables\n  try:\n    _old_makepasv = FTP_TLS.makepasv\n\n    def _new_makepasv(self):\n      try:\n          host,port = _old_makepasv(self)\n          host = self.sock.getpeername()[0]\n          return host,port\n      except Exception as err:\n          ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n          raise Exception(err)\n\n    FTP_TLS.makepasv = _new_makepasv\n    return _old_makepasv\n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n\n###################################################################################  \n  \n#Patch FTP lib to avoid cross-network issue (uses peer ip instead of \"internal ip\")\nif not ('__ftplibpatched__' in locals() or '__ftplibpatched__' in globals()): \n  ADP_log_info(\"ADP\", \"ADP_FTP\", \"DEFAULT\", \"INFO\", \"patching ftplib\", sys._getframe().f_code.co_name)\n  __patch_ftp_lib__()\n  __ftplibpatched__ = 1\nelse:\n  ADP_log_info(\"ADP\", \"ADP_FTP\", \"DEFAULT\", \"INFO\", \"ftplib already patched\", sys._getframe().f_code.co_name)  \n  \n  \n###################################################################################  \n\ndef FMT_GenerateFilesDownloadResultCsvAndUpload(results_download_df,debug=False, suffix_file_name=\"FMT\"):\n  \"\"\"Trigger start download of Farmatic Files\n\n    Return:\n       Dataframe: Dataframe with the download results\n    Example:\n\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       xx/xx/2018     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  #Ana Perez           06/05/2019     Included suffix_file_name to be used by several process (FMT, MDM_SP, ...)\n  \n  try:\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)  \n          \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Save results to csv\", sys._getframe().f_code.co_name)\n    \n    (results_download_df\n       .withColumn(\"size\",column(\"size\").cast(LongType()))\n       .withColumn(\"pending_size\",column(\"size\")-column(\"downloaded_size\"))\n       .coalesce(1)\n       .write\n       .option(\"sep\",\"|\")\n       .option(\"sep\",\"|\")\n       .option(\"header\", True)\n       .option(\"QuoteMode\", \"NONE\")\n       .option(\"charset\", \"utf-8\")\n       .mode('overwrite')\n       .csv(__INGESTION_BASE_PATH__+'files_downloaded_' +suffix_file_name+ '.csv')\n    )\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"List raw csv inside spark csv folder\", sys._getframe().f_code.co_name)\n    \n    src = list(filter(lambda x: 'csv' in x.name,dbutils.fs.ls(__INGESTION_BASE_PATH__+'files_downloaded_' +suffix_file_name+ '.csv/')))[0]\n\n    src_path = src.path.replace('dbfs:/','/dbfs/')\n    src_name = src.name\n\n    filename_tst = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n\n    ADP_log_debug(process, logger_name, level_action, log_level, \"filename_tst is: \" + suffix_file_name + '_' + filename_tst, sys._getframe().f_code.co_name)\n    \n    file_path = '/dbfs'+__INGESTION_BASE_PATH__+'files_log/files_downloaded_' + suffix_file_name + '_' + filename_tst+'.csv'\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"file_path is: \" + file_path, sys._getframe().f_code.co_name)\n    \n    filename = 'files_downloaded_' + suffix_file_name+ '_' + filename_tst+'.csv'\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"filename is: \" + filename, sys._getframe().f_code.co_name)\n    \n    # src_file\n    copyfile(src_path, file_path)\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"src_path is: \" + src_path, sys._getframe().f_code.co_name)\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Timestamp csv file: \", sys._getframe().f_code.co_name)\n    \n    file_upload=filename\n    uploaded = upload_ftp_raw(__FARMATIC_FTP_HOST__,__FARMATIC_FTP_USER__,__FARMATIC_FTP_PASSWD__,file_upload,file_path)\n\n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)  \n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"Generate Download Result Csv has failed with Error Message:\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n  \n###################################################################################  \n  \ndef FMT_FTPTriggerFilesDownload(debug=False):\n  \"\"\"Trigger start download of Farmatic Files\n\n    Return:\n       Dataframe: Dataframe with the download results\n    Example:\n\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       22/03/2019     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  #Victor Salesa       02/04/2019     Added total files downloaded control\n  try:\n    results_download = None\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Get List of Files\", sys._getframe().f_code.co_name)\n    \n    #Get Listing of files in ftp\n    files = list_ftp_raw(__FARMATIC_FTP_HOST__,__FARMATIC_FTP_PORT__,__FARMATIC_FTP_USER__,__FARMATIC_FTP_PASSWD__)\n    \n    if len(files)!=0:\n      #Convert Listing to pyspark rows\n      files_rows = list(map(lambda file: file_listing_to_row(file),files))\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Build the destination path\", sys._getframe().f_code.co_name)\n\n      #Build file destination path\n      ftp_files_df = (spark.createDataFrame(files_rows)\n                      .withColumn(\"path\",concat(lit('/dbfs'+__PHARMATIC_INGESTION_BASE_PATH__),col(\"name\")))\n      )\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Create DF\", sys._getframe().f_code.co_name)\n\n      #Collect Filese\n      files = ftp_files_df.collect()\n\n      # Just take zip files (this is the original format the)\n      files = list(filter(lambda fr: '.ZIP' in fr.name or '.zip' in fr.name,files))\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Filter ZIP Files\", sys._getframe().f_code.co_name)\n\n      parameter_list = ((__FARMATIC_FTP_HOST__,__FARMATIC_FTP_PORT__,__FARMATIC_FTP_USER__,__FARMATIC_FTP_PASSWD__,file.size,file.time,file.name,file.path) for file in files)\n\n      #Create thread pool to paralelize canonical generation\n      threadPool = ThreadPool(32)\n\n      #Configure spark to be optimized to paralilize\n      spark.conf.set(\"spark.scheduler.mode\",'FAIR')\n\n      #Run thread pool with the list of files to be \n      results_download = (\n        threadPool.starmap(\n          download_and_delete_ftp_raw,\n          parameter_list\n        )\n      )\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Start Download\", sys._getframe().f_code.co_name)\n\n      threadPool.close()\n      threadPool.join()\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Create DF\", sys._getframe().f_code.co_name)\n\n      results_download_df = spark.createDataFrame(results_download)\n      \n      #Check all files were downloaded correctly\n      downloaded_ok = results_download_df.filter(col(\"download_ok\")==True).count()\n      total_files_to_download = results_download_df.count()\n      \n      if(downloaded_ok < total_files_to_download):\n        ADP_log_warning(process, logger_name, level_action, log_level, \"END Not all files were downloaded correctly\", sys._getframe().f_code.co_name)\n      #end if(downloaded_ok < total_files_to_download):\n      \n      ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n      return results_download_df\n    else:\n      ADP_log_warning(process, logger_name, level_action, log_level, \"END No files found\", sys._getframe().f_code.co_name)\n      return None\n    #endif len(files)=0\n  \n  except Exception as err:\n    if results_download != None:\n      results_download_df = spark.createDataFrame(results_download)\n      \n      #Check all files were downloaded correctly\n      downloaded_ok = results_download_df.filter(col(\"download_ok\")==True).count()\n      total_files_to_download = results_download_df.count()\n      \n      if(downloaded_ok < total_files_to_download):\n        ADP_log_warning(process, logger_name, level_action, log_level, \"END Not all files were downloaded correctly\", sys._getframe().f_code.co_name)\n      #end if(downloaded_ok < total_files_to_download):\n    \n      FMT_GenerateFilesDownloadResultCsvAndUpload(results_donwnload_df)\n    #end if results_download != None:  \n    ADP_log_exception(process, logger_name, level_action, log_level,  \"Download has failed with Error Message:\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n  \n###################################################################################  \n\ndef file_listing_to_row(file):\n  \"\"\"Generates a Dataframe Row Information from a file line in a file listing comming from ftp\n  \n      Parameters:\n        file = string value containing 1 line file listing\n    Return:\n       Return:\n         pyspark.sql.Row \n    Example:\n         #Get Listing of files in ftp\n            files = list_ftp_raw(host,port,user,password)\n        #Convert Listing to pyspark rows\n            files_rows = list(map(lambda file: file_listing_to_row(file),files))\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       12/12/2018     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  try:\n    tokens = file.split(maxsplit = 12)\n    name = tokens[8]\n    size = tokens[4]\n    time_str = tokens[5] + \" \" + tokens[6] + \" \" + tokens[7]\n    time = parser.parse(time_str)\n    row = Row(name=name,size=size,time=time)\n    return row\n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    return None\n  \n###################################################################################  \n\ndef getSize(fileobject):\n  \"\"\"Returns the size of the file defined by fileobject (path to the file)\n  \n      Parameters:\n        fileobject = file handle\n    Return:\n       Return:\n         size\n    Example:\n      with open(path, 'r') as fhandle:\n        source_size=getSize(fhandle)\n    \n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       12/12/2018     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  try:\n    fileobject.seek(0,2) # move the cursor to the end of the file\n    size = fileobject.tell()\n    return size\n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    return 0\n\n###################################################################################  \n  \n@udf\ndef download_and_delete_ftp(host,port,user,password,size,time,file,path):\n  \"\"\"Encapsulates udf call to download_and_delete_ftp_raw\n  \n      Parameters:\n        Please see download_and_delete_ftp_raw\n    Return:\n       Return:\n         Please see download_and_delete_ftp_raw\n    Example:\n         Please see download_and_delete_ftp_raw\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       12/12/2018     Initial version\n  return download_and_delete_ftp_raw(host,port,user,password,size,time,file,path)\n\n###################################################################################  \n\ndef list_ftp_raw(host,port,user,password, ftp_path = \"\"):\n  \"\"\"Lists root directory for the ftp detailed by the below parameters\n  \n      Parameters:\n        host: string containing name of the ftp host\n        port: string containing port of the ftp host\n        user: string containing user to login to the ftp host\n        password: string containing passworkd to login to the ftp host\n        ftp_path: string containing the path in the ftp where the files to be processed are (relative to the root folder of the FTP)\n    Return:\n       Return:\n         List of file strings with ftp listing information\n    Example:\n         ftp_path = '/masterdata'\n         files = list_ftp_raw(host,port,user,password, ftp_path)\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       12/12/2018     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  #Ana Perez           02/05/2019     Included new ftp_path parameter\n\n  try:\n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name) \n    \n    ftps = FTP_TLS()\n    ftps.connect(host, port)\n    ftps.auth()\n    ftps.login(user, password)\n    ftps.set_pasv(True)\n    ftps.prot_p()\n    ftps.cwd(ftp_path)\n    files = []\n    ftps.retrlines('LIST',files.append)\n    ftps.quit()\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name) \n    return files\n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"\", sys._getframe().f_code.co_name,  sys.exc_info())\n    return []\n  \n##################################################################################  \ndef upload_ftp_raw(host,user,password,filename,path,port=21,debug=False):\n  \"\"\"Uploads a file to the root folder of a ftp\n  \n      Parameters:\n        host: string containing name of the ftp host\n        port: string containing port of the ftp host\n        user: string containing user to login to the ftp host\n        password: string containing passworkd to login to the ftp host\n        filename: filename to be uploaded.\n        path: full path of the file to be uploaded\n    Return:\n       Boolean: Whether or not the file has been uploaded\n    Example:\n         uploaded = upload_ftp_raw(host,port,user,password)\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       xx/xx/2018     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  \n  try:\n    #Set up download thread connection\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)  \n    ftp = FTP(host,user,password)\n    \n    #Set up upload file\n    if os.path.isfile(path):\n      with open(path, 'rb') as fhandle:\n        source_size=getSize(fhandle)\n        ADP_log_debug(process, logger_name, level_action, log_level, \"Source Size: \"+str(source_size), sys._getframe().f_code.co_name)\n        ftp.cwd('/')\n        ftp.storbinary( \"STOR \" +filename,open(path, \"rb\"))\n        uploaded_size = ftp.size(filename)\n        ADP_log_debug(process, logger_name, level_action, log_level, \"Uploaded Size: \"+str(uploaded_size), sys._getframe().f_code.co_name)\n        fhandle.close()\n    else:\n        ADP_log_debug(process, logger_name, level_action, log_level, \"Source File does not exist\", sys._getframe().f_code.co_name)\n    #Close upload ftp connection\n    ftp.quit()\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)  \n    return True\n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  \"Upload Resulting Csv has failed with Error Message: \" + filename, sys._getframe().f_code.co_name,  sys.exc_info())\n    ftp.quit()\n    raise Exception(err)\n\n################################################################################## \n\ndef download_and_delete_ftp_raw(host,port,user,password,size,time,file,path, ftp_path=\"\"):\n  \"\"\"Download a single file from ftp path and delete it\n  \n      Parameters:\n        host: string containing name of the ftp host\n        port: string containing port of the ftp host\n        user: string containing user to login to the ftp host\n        password: string containing passworkd to login to the ftp host\n    Return:\n       Return:\n         Row result of download\n    Example:\n         download_row = download_and_delete_ftp_raw(host,port,user,password,size,time,file,path)\n  \"\"\"\n  #Who                 When           What\n  #Victor Salesa       12/12/2018     Initial version\n  #Ana Perez           26/03/2019     Included log managment and exception managment\n  #Victor Salesa       28/03/2019     Corrected \n  #Ana Perez           02/05/2019     Included new ftp_path parameter\n  \n  try:\n    \n    #Create result to append to dataframe with parameters from funciton\n    frame = inspect.currentframe()\n    args, _, _, values = inspect.getargvalues(frame)\n    \n    result = {i:values[i] for i in args}\n    del result['host']\n    del result['port']\n    del result['user']\n    del result['password']\n    \n    result_true = result.copy()\n    result_true[\"download_ok\"] = True\n    result_false = result.copy()\n    result_false[\"download_ok\"] = False\n  \n    #Set up download thread connection\n    \n    ftps = FTP_TLS()\n    ftps.connect(host, port)\n    ftps.auth()\n    ftps.login(user, password)\n    ftps.set_pasv(True)\n    ftps.prot_p()\n    ftps.cwd(ftp_path)\n    \n    downloaded_size = 0\n    \n    #Set up download file\n    with open(path, 'wb') as fhandle:\n      current_size=0\n      ftps.retrbinary('RETR ' + file, fhandle.write)\n      downloaded_size=getSize(fhandle)\n      if(downloaded_size==int(size)):\n        ADP_log_debug(process, logger_name, level_action, log_level, str(file), sys._getframe().f_code.co_name)\n  ######ftps.delete(file)\n      result_true['downloaded_size']= downloaded_size\n    ADP_log_debug(process, logger_name, level_action, log_level, str(result_true), sys._getframe().f_code.co_name)\n    #Close download thread ftp connection\n    ftps.quit()\n    \n    return Row(**result_true)\n  except Exception as err:\n    ADP_log_exception(process, logger_name, level_action, log_level,  file + \" generate an issue but it continue with the next file:\", sys._getframe().f_code.co_name,  sys.exc_info())\n    ftps.quit()\n    result_false['downloaded_size']= downloaded_size\n    return Row(**result_false)\n  \n ####################################################################################################################################################   \n\n  \ndef MDM_SP_FTPTriggerFilesDownload(debug=False):\n  \"\"\"Trigger start download of MDM SP Files\n\n    Return:\n       Dataframe: Dataframe with the download results\n    Example:\n\n  \"\"\"\n  #Who                 When           What\n  #Ana Perez           02/05/2019     First Version\n  try:\n    results_download = None\n    \n    ADP_log_info(process, logger_name, level_action, log_level, \"BEGIN\", sys._getframe().f_code.co_name)\n    \n    ADP_log_debug(process, logger_name, level_action, log_level, \"Get List of Files\", sys._getframe().f_code.co_name)\n    \n    #Get Listing of files in ftp\n    files = list_ftp_raw(__FARMATIC_FTP_HOST__,__FARMATIC_FTP_PORT__,__FARMATIC_FTP_USER__,__FARMATIC_FTP_PASSWD__, ftp_path=__MASTERDATA_FTP_FOLDER__)\n    \n    if len(files)!=0:\n      #Convert Listing to pyspark rows\n      files_rows = list(map(lambda file: file_listing_to_row(file),files))\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Build the destination path\", sys._getframe().f_code.co_name)\n\n      #Build file destination path\n      ftp_files_df = (spark.createDataFrame(files_rows)\n                      .withColumn(\"path\",concat(lit('/dbfs'+__MASTER_DATA_INGESTION_BASE_PATH__),col(\"name\")))\n      )\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Create DF\", sys._getframe().f_code.co_name)\n\n      #Collect Files\n      files = ftp_files_df.collect()\n\n      parameter_list = ((__FARMATIC_FTP_HOST__,__FARMATIC_FTP_PORT__,__FARMATIC_FTP_USER__,__FARMATIC_FTP_PASSWD__,file.size,file.time,file.name,file.path, __MASTERDATA_FTP_FOLDER__) for file in files)\n\n      #Create thread pool to paralelize canonical generation\n      threadPool = ThreadPool(32)\n\n      #Configure spark to be optimized to paralelize\n      spark.conf.set(\"spark.scheduler.mode\",'FAIR')\n\n      #Run thread pool with the list of files to be \n      results_download = (\n        threadPool.starmap(\n          download_and_delete_ftp_raw,\n          parameter_list\n        )\n      )\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Start Download\", sys._getframe().f_code.co_name)\n\n      threadPool.close()\n      threadPool.join()\n\n      ADP_log_debug(process, logger_name, level_action, log_level, \"Create DF\", sys._getframe().f_code.co_name)\n\n      results_download_df = spark.createDataFrame(results_download)\n      \n      #Check all files were downloaded correctly\n      downloaded_ok = results_download_df.filter(col(\"download_ok\")==True).count()\n      total_files_to_download = results_download_df.count()\n      \n      if(downloaded_ok < total_files_to_download):\n        ADP_log_warning(process, logger_name, level_action, log_level, \"END Not all files were downloaded correctly\", sys._getframe().f_code.co_name)\n      #end if(downloaded_ok < total_files_to_download):\n      \n      ADP_log_info(process, logger_name, level_action, log_level, \"END\", sys._getframe().f_code.co_name)\n      return results_download_df\n    else:\n      ADP_log_warning(process, logger_name, level_action, log_level, \"END No files found\", sys._getframe().f_code.co_name)\n      return None\n    #endif len(files)=0\n  \n  except Exception as err:\n    if results_download != None:\n      results_download_df = spark.createDataFrame(results_download)\n      \n      #Check all files were downloaded correctly\n      downloaded_ok = results_download_df.filter(col(\"download_ok\")==True).count()\n      total_files_to_download = results_download_df.count()\n      \n      if(downloaded_ok < total_files_to_download):\n        ADP_log_warning(process, logger_name, level_action, log_level, \"END Not all files were downloaded correctly\", sys._getframe().f_code.co_name)\n      #end if(downloaded_ok < total_files_to_download):\n    \n      FMT_GenerateFilesDownloadResultCsvAndUpload(results_donwnload_df)\n    #end if results_download != None:  \n    ADP_log_exception(process, logger_name, level_action, log_level,  \"Download has failed with Error Message:\", sys._getframe().f_code.co_name,  sys.exc_info())\n    raise Exception(err)\n  \n###################################################################################  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2}],"metadata":{"name":"ADP_FTP","notebookId":2882562916532277},"nbformat":4,"nbformat_minor":0}
